{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LuEKEIY0oBJH"
   },
   "source": [
    "# **Our Project**\n",
    "In this project, I have used the different deep learning-based algorithm, to detect empty inventory in grocery stores.\n",
    "Usually, when we go to a grocery store, and we see a shelf that doesn’t have the product we need,\n",
    "then many customers will leave without asking the store workers if they have that item. Even if\n",
    "the store had that item in their warehouse. This can cause the store to lose out on potential sales\n",
    "for as long as the inventory remains empty. I have used machine learning models to help stores\n",
    "replenish inventory quickly so that they don’t lose customers and sales.\n",
    "\n",
    "\n",
    "### **Installing tensorflow-object-detection-api**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8mVJWlWroLxy",
    "outputId": "71a68145-19a5-409b-f627-a6bba7e43263"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting tensorflow-object-detection-api\n",
      "  Downloading tensorflow_object_detection_api-0.1.1.tar.gz (577 kB)\n",
      "\u001b[K     |████████████████████████████████| 577 kB 13.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: Pillow>=1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (7.1.2)\n",
      "Requirement already satisfied: Matplotlib>=2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.2.2)\n",
      "Requirement already satisfied: Cython>=0.28.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.29.32)\n",
      "Requirement already satisfied: Protobuf in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (3.17.3)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (4.9.1)\n",
      "Collecting jupyter\n",
      "  Downloading jupyter-1.0.0-py2.py3-none-any.whl (2.7 kB)\n",
      "Requirement already satisfied: tensorflow in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (2.9.2)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.5.5)\n",
      "Requirement already satisfied: wheel in /usr/local/lib/python3.7/dist-packages (from tensorflow-object-detection-api) (0.37.1)\n",
      "Collecting twine\n",
      "  Downloading twine-4.0.1-py3-none-any.whl (36 kB)\n",
      "Requirement already satisfied: jupyter-console in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (6.1.0)\n",
      "Collecting qtconsole\n",
      "  Downloading qtconsole-5.3.2-py3-none-any.whl (120 kB)\n",
      "\u001b[K     |████████████████████████████████| 120 kB 64.0 MB/s \n",
      "\u001b[?25hRequirement already satisfied: ipykernel in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.3.4)\n",
      "Requirement already satisfied: nbconvert in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.6.1)\n",
      "Requirement already satisfied: notebook in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (5.5.0)\n",
      "Requirement already satisfied: ipywidgets in /usr/local/lib/python3.7/dist-packages (from jupyter->tensorflow-object-detection-api) (7.7.1)\n",
      "Requirement already satisfied: tornado>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
      "Requirement already satisfied: jupyter-client in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (6.1.12)\n",
      "Requirement already satisfied: ipython>=5.0.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (7.9.0)\n",
      "Requirement already satisfied: traitlets>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from ipykernel->jupyter->tensorflow-object-detection-api) (5.1.1)\n",
      "Collecting jedi>=0.10\n",
      "  Downloading jedi-0.18.1-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.6 MB 54.3 MB/s \n",
      "\u001b[?25hRequirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (2.0.10)\n",
      "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.4.2)\n",
      "Requirement already satisfied: backcall in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
      "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (57.4.0)\n",
      "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (2.6.1)\n",
      "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (4.8.0)\n",
      "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.7.5)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.7/dist-packages (from jedi>=0.10->ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.8.3)\n",
      "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (1.15.0)\n",
      "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython>=5.0.0->ipykernel->jupyter->tensorflow-object-detection-api) (0.2.5)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (0.2.0)\n",
      "Requirement already satisfied: jupyterlab-widgets>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.0.3)\n",
      "Requirement already satisfied: widgetsnbextension~=3.6.0 in /usr/local/lib/python3.7/dist-packages (from ipywidgets->jupyter->tensorflow-object-detection-api) (3.6.1)\n",
      "Requirement already satisfied: pyzmq>=17 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (23.2.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (2.11.3)\n",
      "Requirement already satisfied: Send2Trash in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (1.8.0)\n",
      "Requirement already satisfied: nbformat in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (5.7.0)\n",
      "Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (0.13.3)\n",
      "Requirement already satisfied: jupyter-core>=4.4.0 in /usr/local/lib/python3.7/dist-packages (from notebook->jupyter->tensorflow-object-detection-api) (4.11.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from jupyter-client->ipykernel->jupyter->tensorflow-object-detection-api) (2.8.2)\n",
      "Requirement already satisfied: ptyprocess in /usr/local/lib/python3.7/dist-packages (from terminado>=0.8.1->notebook->jupyter->tensorflow-object-detection-api) (0.7.0)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->notebook->jupyter->tensorflow-object-detection-api) (2.0.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (3.0.9)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.4.4)\n",
      "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from Matplotlib>=2.1->tensorflow-object-detection-api) (1.21.6)\n",
      "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->Matplotlib>=2.1->tensorflow-object-detection-api) (4.1.1)\n",
      "Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.8.4)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (1.5.0)\n",
      "Requirement already satisfied: bleach in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (5.0.1)\n",
      "Requirement already satisfied: entrypoints>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.4)\n",
      "Requirement already satisfied: testpath in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.6.0)\n",
      "Requirement already satisfied: defusedxml in /usr/local/lib/python3.7/dist-packages (from nbconvert->jupyter->tensorflow-object-detection-api) (0.7.1)\n",
      "Requirement already satisfied: importlib-metadata>=3.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (4.13.0)\n",
      "Requirement already satisfied: jsonschema>=2.6 in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (4.3.3)\n",
      "Requirement already satisfied: fastjsonschema in /usr/local/lib/python3.7/dist-packages (from nbformat->notebook->jupyter->tensorflow-object-detection-api) (2.16.2)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=3.6->nbformat->notebook->jupyter->tensorflow-object-detection-api) (3.9.0)\n",
      "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->tensorflow-object-detection-api) (22.1.0)\n",
      "Requirement already satisfied: pyrsistent!=0.17.0,!=0.17.1,!=0.17.2,>=0.14.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->tensorflow-object-detection-api) (0.18.1)\n",
      "Requirement already satisfied: importlib-resources>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from jsonschema>=2.6->nbformat->notebook->jupyter->tensorflow-object-detection-api) (5.10.0)\n",
      "Requirement already satisfied: webencodings in /usr/local/lib/python3.7/dist-packages (from bleach->nbconvert->jupyter->tensorflow-object-detection-api) (0.5.1)\n",
      "Collecting qtpy>=2.0.1\n",
      "  Downloading QtPy-2.2.1-py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 829 kB/s \n",
      "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from qtpy>=2.0.1->qtconsole->jupyter->tensorflow-object-detection-api) (21.3)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.0.1)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.1.0)\n",
      "Requirement already satisfied: keras<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.9.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.2.0)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.4.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (14.0.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.3.0)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.1.2)\n",
      "Requirement already satisfied: flatbuffers<2,>=1.12 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.12)\n",
      "Requirement already satisfied: tensorboard<2.10,>=2.9 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.9.1)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.49.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (1.6.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.10.0,>=2.9.0rc0 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (2.9.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (0.27.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow->tensorflow-object-detection-api) (3.3.0)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow->tensorflow-object-detection-api) (1.5.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (1.0.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (0.4.6)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (2.23.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (0.6.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (1.8.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (3.4.1)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (1.35.0)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (0.4.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (2022.9.24)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (3.0.4)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow->tensorflow-object-detection-api) (3.2.1)\n",
      "Collecting requests-toolbelt!=0.9.0,>=0.8.0\n",
      "  Downloading requests_toolbelt-0.10.0-py2.py3-none-any.whl (54 kB)\n",
      "\u001b[K     |████████████████████████████████| 54 kB 3.2 MB/s \n",
      "\u001b[?25hCollecting readme-renderer>=35.0\n",
      "  Downloading readme_renderer-37.2-py3-none-any.whl (14 kB)\n",
      "Collecting rfc3986>=1.4.0\n",
      "  Downloading rfc3986-2.0.0-py2.py3-none-any.whl (31 kB)\n",
      "Collecting keyring>=15.1\n",
      "  Downloading keyring-23.9.3-py3-none-any.whl (35 kB)\n",
      "Collecting rich>=12.0.0\n",
      "  Downloading rich-12.6.0-py3-none-any.whl (237 kB)\n",
      "\u001b[K     |████████████████████████████████| 237 kB 57.0 MB/s \n",
      "\u001b[?25hCollecting pkginfo>=1.8.1\n",
      "  Downloading pkginfo-1.8.3-py2.py3-none-any.whl (26 kB)\n",
      "Collecting twine\n",
      "  Downloading twine-4.0.0-py3-none-any.whl (36 kB)\n",
      "  Downloading twine-3.8.0-py3-none-any.whl (36 kB)\n",
      "Collecting colorama>=0.4.3\n",
      "  Downloading colorama-0.4.5-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: tqdm>=4.14 in /usr/local/lib/python3.7/dist-packages (from twine->tensorflow-object-detection-api) (4.64.1)\n",
      "Collecting twine\n",
      "  Downloading twine-3.7.1-py3-none-any.whl (35 kB)\n",
      "Collecting SecretStorage>=3.2\n",
      "  Downloading SecretStorage-3.3.3-py3-none-any.whl (15 kB)\n",
      "Collecting jeepney>=0.4.2\n",
      "  Downloading jeepney-0.8.0-py3-none-any.whl (48 kB)\n",
      "\u001b[K     |████████████████████████████████| 48 kB 4.9 MB/s \n",
      "\u001b[?25hCollecting jaraco.classes\n",
      "  Downloading jaraco.classes-3.2.3-py3-none-any.whl (6.0 kB)\n",
      "Requirement already satisfied: docutils>=0.13.1 in /usr/local/lib/python3.7/dist-packages (from readme-renderer>=35.0->twine->tensorflow-object-detection-api) (0.17.1)\n",
      "Collecting cryptography>=2.0\n",
      "  Downloading cryptography-38.0.1-cp36-abi3-manylinux_2_24_x86_64.whl (4.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 4.0 MB 41.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.7/dist-packages (from cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (1.15.1)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.7/dist-packages (from cffi>=1.12->cryptography>=2.0->SecretStorage>=3.2->keyring>=15.1->twine->tensorflow-object-detection-api) (2.21)\n",
      "Requirement already satisfied: more-itertools in /usr/local/lib/python3.7/dist-packages (from jaraco.classes->keyring>=15.1->twine->tensorflow-object-detection-api) (8.14.0)\n",
      "Building wheels for collected packages: tensorflow-object-detection-api\n",
      "  Building wheel for tensorflow-object-detection-api (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for tensorflow-object-detection-api: filename=tensorflow_object_detection_api-0.1.1-py3-none-any.whl size=844512 sha256=45d836d6b3e20b2477b92f13f2dafcfe234bfed645172df8cdbe41229e432a13\n",
      "  Stored in directory: /root/.cache/pip/wheels/71/7e/a2/461ab817fbaef68ec9cc60df16d3669d1285f032e4c98179bf\n",
      "Successfully built tensorflow-object-detection-api\n",
      "Installing collected packages: jedi, jeepney, cryptography, SecretStorage, qtpy, jaraco.classes, rfc3986, requests-toolbelt, readme-renderer, qtconsole, pkginfo, keyring, colorama, twine, jupyter, tensorflow-object-detection-api\n",
      "Successfully installed SecretStorage-3.3.3 colorama-0.4.5 cryptography-38.0.1 jaraco.classes-3.2.3 jedi-0.18.1 jeepney-0.8.0 jupyter-1.0.0 keyring-23.9.3 pkginfo-1.8.3 qtconsole-5.3.2 qtpy-2.2.1 readme-renderer-37.2 requests-toolbelt-0.10.0 rfc3986-2.0.0 tensorflow-object-detection-api-0.1.1 twine-3.7.1\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-object-detection-api #installing tensorflow-object-detection-api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QUANWN3rpfC9"
   },
   "source": [
    "### **DataSet Overview**\n",
    "**SKU-110K** images were collected from thousands of supermarket stores around the world,\n",
    "including locations in the United States, Europe, and East Asia. Dozens of paid associates\n",
    "acquired our images, using their personal cellphone cameras. Images were originally taken at no\n",
    "less than five mega-pixel resolution but were then JPEG compressed at one megapixel.\n",
    "\n",
    "The **SKU110K** dataset provides 11,762 images with more than 1.7 million annotated bounding\n",
    "boxes captured in densely packed scenarios, including 8,233 images for training, 588 images for\n",
    "validation, and 2,941 images for testing. There are around 1,733,678 instances in total. The\n",
    "images are collected from thousands of supermarket stores and are of various scales, viewing\n",
    "angles, lighting conditions, and noise levels. All the images are resized into a resolution of one\n",
    "megapixel. Most of the instances in the dataset are tightly packed and typically of a certain\n",
    "orientation\n",
    "\n",
    "### **Models Methodology Workflow**\n",
    "We selected a collection of detection models and pre-trained them on the SKU-110K dataset such as the EfficientDet D1 640x640, SSD MobileNet V1 FPN 640x640, and SSDResNet50 V1 FPN from TensorFlow 2 Detection Model Zoo and Detecto Module in Pytorch. These models are useful for initialization when training on our new datasets. By comparing\n",
    "the performance of these models, we have concluded that SSD-ResNet50 delivers better\n",
    "performance with respect to real-time detection. We trained our model based upon the SSDResNet50 V1 FPN Architecture. The entire workflow of the SSD-ResNet50 V1 FPN\n",
    "Architecture is illustrated in Figure 3. SSD with the ResNet50 V1 FPN feature extractor in its\n",
    "architecture is an object detection model that has been trained on the COCO 2017 dataset. A\n",
    "Momentum optimizer with a learning rate of 0.04 was used for the region proposal and\n",
    "classification network, and the learning rate was reduced on the plateau. As shown in Figure\n",
    "3, the Feature Pyramid Network (FPN) generates the multi-level features as inputs to the SSDResNet50 Architecture. The FPN is an extractor and provides the extracted feature maps layers\n",
    "to an object detector. When the model localizes any small object, it draws an object boundary ox around it at each location. After training the model, the testing procedure was carried out by\n",
    "providing the surgical videos as input to the trained model. Afterward, we used Tensorboard\n",
    "which is a suitable feature of the TensorFlow Object Detection API. It allowed us to\n",
    "continuously monitor and visualize several different training/evaluation metrics when our\n",
    "model was being trained. As the final step, we obtained the output video containing the\n",
    "labeled surgical instruments and the assessment results along with the log file. The generated\n",
    "log file records the surgical assessment, the bounding box for each laparoscopic instrument, and\n",
    "the center point of each laparoscopic instrument\n",
    "# 0. Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "146BB11JpfDA"
   },
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "42hJEdo_pfDB"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'ssd_mobilenet_v1' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0EzUhzx_WCIW"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME2 = 'ssd_resnet101_v1' \n",
    "PRETRAINED_MODEL_NAME2 = 'ssd_resnet101_v1_fpn_640x640_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL2 = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7qZ3gvfIWDAA"
   },
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME3 = 'ssd_mobilenet_v2_fpnlite' \n",
    "PRETRAINED_MODEL_NAME3 = 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL3 = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hbPhYVy_pfDB"
   },
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('Tensorflow', 'workspace','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME), \n",
    "    'CHECKPOINT_PATH2': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME2), \n",
    "    'CHECKPOINT_PATH3': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME3),\n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'OUTPUT_PATH2': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME2, 'export'), \n",
    "    'OUTPUT_PATH3': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME3, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFJS_PATH2':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME2, 'tfjsexport'), \n",
    "    'TFJS_PATH3':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME3, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'),\n",
    "    'TFLITE_PATH2':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME2, 'tfliteexport'), \n",
    "    'TFLITE_PATH3':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME3, 'tfliteexport'),  \n",
    "    'PROTOC_PATH':os.path.join('Tensorflow','protoc')\n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LwhWZMI0pfDC"
   },
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'PIPELINE_CONFIG2':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME2, 'pipeline.config'),\n",
    "    'PIPELINE_CONFIG3':os.path.join('Tensorflow', 'workspace','models', CUSTOM_MODEL_NAME3, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HR-TfDGrpfDC"
   },
   "outputs": [],
   "source": [
    "for path in paths.values():\n",
    "    if not os.path.exists(path):\n",
    "        if os.name == 'posix':\n",
    "            !mkdir -p {path}\n",
    "        if os.name == 'nt':\n",
    "            !mkdir {path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OLU-rs_ipfDE"
   },
   "source": [
    "# Download TF Models Pretrained Models from Tensorflow Model Zoo and Install TFOD\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "*   we will not be creating a training job from scratch, but rather we will reuse one of the pre-trained models provided by TensorFlow. If you would like to train an entirely new model, you can have a look at TensorFlow’s tutorial.\n",
    "\n",
    "The model we shall be using in our examples is the SSD ResNet50 V1 FPN 640x640 model, since it provides a relatively good trade-off between performance and speed. However, there exist a number of other models you can use, all of which are listed in TensorFlow 2 Detection Model Zoo.\n",
    "\n",
    "\n",
    "*   **Download Pre-Trained Model**\n",
    "To begin with, we need to download the latest pre-trained network for the model we wish to use. This can be done by simply clicking on the name of the desired model in the table found in TensorFlow 2 Detection Model Zoo. Clicking on the name of your model should initiate a download for a *.tar.gz file.\n",
    "\n",
    "Once the *.tar.gz file has been downloaded, open it using a decompression program of your choice (e.g. 7zip, WinZIP, etc.). Next, open the *.tar folder that you see when the compressed folder is opened, and extract its contents inside the folder training_demo/pre-trained-models.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ch3zMsZV5pxn"
   },
   "outputs": [],
   "source": [
    "# https://www.tensorflow.org/install/source_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K-Cmz2edpfDE",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if os.name=='nt':\n",
    "    !pip install wget\n",
    "    import wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iA1DIq5OpfDE",
    "outputId": "8aca2b3e-e119-4f02-ac38-9aeec72d016a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow/models'...\n",
      "remote: Enumerating objects: 78241, done.\u001b[K\n",
      "remote: Counting objects: 100% (44/44), done.\u001b[K\n",
      "remote: Compressing objects: 100% (37/37), done.\u001b[K\n",
      "remote: Total 78241 (delta 19), reused 18 (delta 7), pack-reused 78197\u001b[K\n",
      "Receiving objects: 100% (78241/78241), 593.49 MiB | 26.29 MiB/s, done.\n",
      "Resolving deltas: 100% (55625/55625), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection')):\n",
    "    !git clone https://github.com/tensorflow/models {paths['APIMODEL_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rJjMHbnDs3Tv",
    "outputId": "7b7a1257-d490-42f7-f062-620dc514ee39"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "0 upgraded, 0 newly installed, 0 to remove and 27 not upgraded.\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Processing /content/Tensorflow/models/research\n",
      "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
      "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
      "Collecting avro-python3\n",
      "  Downloading avro-python3-1.10.2.tar.gz (38 kB)\n",
      "Collecting apache-beam\n",
      "  Downloading apache_beam-2.42.0-cp37-cp37m-manylinux2010_x86_64.whl (11.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 11.0 MB 1.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (7.1.2)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (4.9.1)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (3.2.2)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.29.32)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (0.5.5)\n",
      "Collecting tf-slim\n",
      "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
      "\u001b[K     |████████████████████████████████| 352 kB 60.2 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.0.5)\n",
      "Collecting lvis\n",
      "  Downloading lvis-0.5.3-py3-none-any.whl (14 kB)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.7.3)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (1.3.5)\n",
      "Collecting tf-models-official>=2.5.1\n",
      "  Downloading tf_models_official-2.10.0-py2.py3-none-any.whl (2.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.2 MB 58.2 MB/s \n",
      "\u001b[?25hCollecting tensorflow_io\n",
      "  Downloading tensorflow_io-0.27.0-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (25.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 25.0 MB 94.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: keras in /usr/local/lib/python3.7/dist-packages (from object-detection==0.1) (2.9.0)\n",
      "Collecting pyparsing==2.4.7\n",
      "  Downloading pyparsing-2.4.7-py2.py3-none-any.whl (67 kB)\n",
      "\u001b[K     |████████████████████████████████| 67 kB 5.8 MB/s \n",
      "\u001b[?25hCollecting sacrebleu<=2.2.0\n",
      "  Downloading sacrebleu-2.2.0-py3-none-any.whl (116 kB)\n",
      "\u001b[K     |████████████████████████████████| 116 kB 73.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.8.10)\n",
      "Collecting portalocker\n",
      "  Downloading portalocker-2.6.0-py2.py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (0.4.5)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (2022.6.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from sacrebleu<=2.2.0->object-detection==0.1) (1.21.6)\n",
      "Collecting opencv-python-headless==4.5.2.52\n",
      "  Downloading opencv_python_headless-4.5.2.52-cp37-cp37m-manylinux2014_x86_64.whl (38.2 MB)\n",
      "\u001b[K     |████████████████████████████████| 38.2 MB 72 kB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.5.12)\n",
      "Collecting tensorflow-text~=2.10.0\n",
      "  Downloading tensorflow_text-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 52.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.6.0)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (5.4.8)\n",
      "Requirement already satisfied: oauth2client in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (4.1.3)\n",
      "Collecting tensorflow-addons\n",
      "  Downloading tensorflow_addons-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 46.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (1.12.11)\n",
      "Collecting py-cpuinfo>=3.3.0\n",
      "  Downloading py-cpuinfo-8.0.0.tar.gz (99 kB)\n",
      "\u001b[K     |████████████████████████████████| 99 kB 9.8 MB/s \n",
      "\u001b[?25hRequirement already satisfied: gin-config in /usr/local/lib/python3.7/dist-packages (from tf-models-official>=2.5.1->object-detection==0.1) (0.5.0)\n",
      "Collecting immutabledict\n",
      "  Downloading immutabledict-2.2.1-py3-none-any.whl (4.0 kB)\n",
      "Collecting seqeval\n",
      "  Downloading seqeval-1.2.2.tar.gz (43 kB)\n",
      "\u001b[K     |████████████████████████████████| 43 kB 1.9 MB/s \n",
      "\u001b[?25hCollecting pyyaml<6.0,>=5.1\n",
      "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
      "\u001b[K     |████████████████████████████████| 636 kB 51.1 MB/s \n",
      "\u001b[?25hCollecting tensorflow-model-optimization>=0.4.1\n",
      "  Downloading tensorflow_model_optimization-0.7.3-py2.py3-none-any.whl (238 kB)\n",
      "\u001b[K     |████████████████████████████████| 238 kB 72.5 MB/s \n",
      "\u001b[?25hCollecting tensorflow~=2.10.0\n",
      "  Downloading tensorflow-2.10.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 578.0 MB 15 kB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.97-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.3 MB 56.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: google-api-core<3dev,>=1.21.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.31.6)\n",
      "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.17.4)\n",
      "Requirement already satisfied: google-auth<3dev,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.35.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.0.3 in /usr/local/lib/python3.7/dist-packages (from google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.0.4)\n",
      "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (57.4.0)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (21.3)\n",
      "Requirement already satisfied: requests<3.0.0dev,>=2.18.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.23.0)\n",
      "Requirement already satisfied: protobuf<4.0.0dev,>=3.12.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.17.3)\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2022.4)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (1.56.4)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.9)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (4.2.4)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (6.1.2)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (4.64.1)\n",
      "Requirement already satisfied: urllib3 in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.24.3)\n",
      "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2.8.2)\n",
      "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (2022.9.24)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (3.0.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.10)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.1.1)\n",
      "Collecting keras\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.7 MB 58.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (14.0.6)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.14.1)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.49.1)\n",
      "Requirement already satisfied: keras-preprocessing>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.1.2)\n",
      "Collecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.9 MB 50.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (2.0.1)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.27.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Collecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[K     |████████████████████████████████| 438 kB 63.7 MB/s \n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.7/dist-packages (from astunparse>=1.6.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.37.1)\n",
      "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py>=2.9.0->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.8.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.4.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (4.13.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.9.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow~=2.10.0->tf-models-official>=2.5.1->object-detection==0.1) (3.2.1)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official>=2.5.1->object-detection==0.1) (0.1.7)\n",
      "Requirement already satisfied: pyarrow<8.0.0,>=0.15.1 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (6.0.1)\n",
      "Collecting fastavro<2,>=0.23.6\n",
      "  Downloading fastavro-1.6.1-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.4 MB 54.0 MB/s \n",
      "\u001b[?25hCollecting pymongo<4.0.0,>=3.8.0\n",
      "  Downloading pymongo-3.12.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (508 kB)\n",
      "\u001b[K     |████████████████████████████████| 508 kB 71.5 MB/s \n",
      "\u001b[?25hCollecting dill<0.3.2,>=0.3.1.1\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "\u001b[K     |████████████████████████████████| 151 kB 75.0 MB/s \n",
      "\u001b[?25hCollecting hdfs<3.0.0,>=2.1.0\n",
      "  Downloading hdfs-2.7.0-py3-none-any.whl (34 kB)\n",
      "Collecting orjson<4.0\n",
      "  Downloading orjson-3.8.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (270 kB)\n",
      "\u001b[K     |████████████████████████████████| 270 kB 72.8 MB/s \n",
      "\u001b[?25hCollecting proto-plus<2,>=1.7.1\n",
      "  Downloading proto_plus-1.22.1-py3-none-any.whl (47 kB)\n",
      "\u001b[K     |████████████████████████████████| 47 kB 5.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Collecting cloudpickle~=2.1.0\n",
      "  Downloading cloudpickle-2.1.0-py3-none-any.whl (25 kB)\n",
      "Collecting zstandard<1,>=0.18.0\n",
      "  Downloading zstandard-0.18.0-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
      "\u001b[K     |████████████████████████████████| 2.5 MB 47.0 MB/s \n",
      "\u001b[?25hCollecting requests<3.0.0dev,>=2.18.0\n",
      "  Downloading requests-2.28.1-py3-none-any.whl (62 kB)\n",
      "\u001b[K     |████████████████████████████████| 62 kB 1.5 MB/s \n",
      "\u001b[?25hRequirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from apache-beam->object-detection==0.1) (1.3.0)\n",
      "Collecting docopt\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "Collecting protobuf<4.0.0dev,>=3.12.0\n",
      "  Downloading protobuf-3.19.6-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.1 MB 56.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: charset-normalizer<3,>=2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0dev,>=2.18.0->google-api-core<3dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official>=2.5.1->object-detection==0.1) (2.1.1)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (4.6.0.66)\n",
      "Requirement already satisfied: kiwisolver>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (1.4.4)\n",
      "Requirement already satisfied: cycler>=0.10.0 in /usr/local/lib/python3.7/dist-packages (from lvis->object-detection==0.1) (0.11.0)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.7/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official>=2.5.1->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.0.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official>=2.5.1->object-detection==0.1) (1.2.0)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.7/dist-packages (from tensorflow-addons->tf-models-official>=2.5.1->object-detection==0.1) (2.7.1)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: etils[epath] in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.8.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (1.10.0)\n",
      "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (5.10.0)\n",
      "Requirement already satisfied: toml in /usr/local/lib/python3.7/dist-packages (from tensorflow-datasets->tf-models-official>=2.5.1->object-detection==0.1) (0.10.2)\n",
      "Building wheels for collected packages: object-detection, py-cpuinfo, dill, avro-python3, docopt, seqeval\n",
      "  Building wheel for object-detection (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1696560 sha256=e9879a9a57f296e0b03616065c52ad37ea4942e77ad2f02f33b9471971b1935a\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-dggcb27h/wheels/a9/26/bf/1cb2313ed4855917889b97658bf0a19999e3588e47867bdaee\n",
      "  Building wheel for py-cpuinfo (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for py-cpuinfo: filename=py_cpuinfo-8.0.0-py3-none-any.whl size=22257 sha256=8bd231d5c167276fe10de1fa977a9be562344543a25d43b2c04ec6a91d3d3f56\n",
      "  Stored in directory: /root/.cache/pip/wheels/d2/f1/1f/041add21dc9c4220157f1bd2bd6afe1f1a49524c3396b94401\n",
      "  Building wheel for dill (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78544 sha256=37b3ec7f01226ae3f2edd67751dcee29735d08d4916d2917230504f82341833e\n",
      "  Stored in directory: /root/.cache/pip/wheels/a4/61/fd/c57e374e580aa78a45ed78d5859b3a44436af17e22ca53284f\n",
      "  Building wheel for avro-python3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for avro-python3: filename=avro_python3-1.10.2-py3-none-any.whl size=44010 sha256=4221c9cbea205184fd4e17b664b1f6630f278af7f208f622ce0119839daabc92\n",
      "  Stored in directory: /root/.cache/pip/wheels/d6/e5/b1/6b151d9b535ee50aaa6ab27d145a0104b6df02e5636f0376da\n",
      "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13723 sha256=252ca163f6c1f272e85952f31960de63d9f8d0e0626f555cc9b38e22f82bd111\n",
      "  Stored in directory: /root/.cache/pip/wheels/72/b0/3f/1d95f96ff986c7dfffe46ce2be4062f38ebd04b506c77c81b9\n",
      "  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16180 sha256=a17e086ee4bf56a584d1133a7232bade977649892a175d2fff95f92c943bfb27\n",
      "  Stored in directory: /root/.cache/pip/wheels/05/96/ee/7cac4e74f3b19e3158dce26a20a1c86b3533c43ec72a549fd7\n",
      "Successfully built object-detection py-cpuinfo dill avro-python3 docopt seqeval\n",
      "Installing collected packages: requests, pyparsing, protobuf, tensorflow-estimator, tensorboard, keras, flatbuffers, tensorflow, portalocker, docopt, dill, zstandard, tf-slim, tensorflow-text, tensorflow-model-optimization, tensorflow-addons, seqeval, sentencepiece, sacrebleu, pyyaml, pymongo, py-cpuinfo, proto-plus, orjson, opencv-python-headless, immutabledict, hdfs, fastavro, cloudpickle, tf-models-official, tensorflow-io, lvis, avro-python3, apache-beam, object-detection\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.23.0\n",
      "    Uninstalling requests-2.23.0:\n",
      "      Successfully uninstalled requests-2.23.0\n",
      "  Attempting uninstall: pyparsing\n",
      "    Found existing installation: pyparsing 3.0.9\n",
      "    Uninstalling pyparsing-3.0.9:\n",
      "      Successfully uninstalled pyparsing-3.0.9\n",
      "  Attempting uninstall: protobuf\n",
      "    Found existing installation: protobuf 3.17.3\n",
      "    Uninstalling protobuf-3.17.3:\n",
      "      Successfully uninstalled protobuf-3.17.3\n",
      "  Attempting uninstall: tensorflow-estimator\n",
      "    Found existing installation: tensorflow-estimator 2.9.0\n",
      "    Uninstalling tensorflow-estimator-2.9.0:\n",
      "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.9.1\n",
      "    Uninstalling tensorboard-2.9.1:\n",
      "      Successfully uninstalled tensorboard-2.9.1\n",
      "  Attempting uninstall: keras\n",
      "    Found existing installation: keras 2.9.0\n",
      "    Uninstalling keras-2.9.0:\n",
      "      Successfully uninstalled keras-2.9.0\n",
      "  Attempting uninstall: flatbuffers\n",
      "    Found existing installation: flatbuffers 1.12\n",
      "    Uninstalling flatbuffers-1.12:\n",
      "      Successfully uninstalled flatbuffers-1.12\n",
      "  Attempting uninstall: tensorflow\n",
      "    Found existing installation: tensorflow 2.9.2\n",
      "    Uninstalling tensorflow-2.9.2:\n",
      "      Successfully uninstalled tensorflow-2.9.2\n",
      "  Attempting uninstall: dill\n",
      "    Found existing installation: dill 0.3.5.1\n",
      "    Uninstalling dill-0.3.5.1:\n",
      "      Successfully uninstalled dill-0.3.5.1\n",
      "  Attempting uninstall: pyyaml\n",
      "    Found existing installation: PyYAML 6.0\n",
      "    Uninstalling PyYAML-6.0:\n",
      "      Successfully uninstalled PyYAML-6.0\n",
      "  Attempting uninstall: pymongo\n",
      "    Found existing installation: pymongo 4.2.0\n",
      "    Uninstalling pymongo-4.2.0:\n",
      "      Successfully uninstalled pymongo-4.2.0\n",
      "  Attempting uninstall: opencv-python-headless\n",
      "    Found existing installation: opencv-python-headless 4.6.0.66\n",
      "    Uninstalling opencv-python-headless-4.6.0.66:\n",
      "      Successfully uninstalled opencv-python-headless-4.6.0.66\n",
      "  Attempting uninstall: cloudpickle\n",
      "    Found existing installation: cloudpickle 1.5.0\n",
      "    Uninstalling cloudpickle-1.5.0:\n",
      "      Successfully uninstalled cloudpickle-1.5.0\n",
      "Successfully installed apache-beam-2.42.0 avro-python3-1.10.2 cloudpickle-2.1.0 dill-0.3.1.1 docopt-0.6.2 fastavro-1.6.1 flatbuffers-22.9.24 hdfs-2.7.0 immutabledict-2.2.1 keras-2.10.0 lvis-0.5.3 object-detection-0.1 opencv-python-headless-4.5.2.52 orjson-3.8.0 portalocker-2.6.0 proto-plus-1.22.1 protobuf-3.19.6 py-cpuinfo-8.0.0 pymongo-3.12.3 pyparsing-2.4.7 pyyaml-5.4.1 requests-2.28.1 sacrebleu-2.2.0 sentencepiece-0.1.97 seqeval-1.2.2 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-addons-0.18.0 tensorflow-estimator-2.10.0 tensorflow-io-0.27.0 tensorflow-model-optimization-0.7.3 tensorflow-text-2.10.0 tf-models-official-2.10.0 tf-slim-1.1.0 zstandard-0.18.0\n"
     ]
    }
   ],
   "source": [
    "# Install Tensorflow Object Detection \n",
    "if os.name=='posix':  \n",
    "    !apt-get install protobuf-compiler\n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && cp object_detection/packages/tf2/setup.py . && python -m pip install . \n",
    "    \n",
    "if os.name=='nt':\n",
    "    url=\"https://github.com/protocolbuffers/protobuf/releases/download/v3.15.6/protoc-3.15.6-win64.zip\"\n",
    "    wget.download(url)\n",
    "    !move protoc-3.15.6-win64.zip {paths['PROTOC_PATH']}\n",
    "    !cd {paths['PROTOC_PATH']} && tar -xf protoc-3.15.6-win64.zip\n",
    "    os.environ['PATH'] += os.pathsep + os.path.abspath(os.path.join(paths['PROTOC_PATH'], 'bin'))   \n",
    "    !cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=. && copy object_detection\\\\packages\\\\tf2\\\\setup.py setup.py && python setup.py build && python setup.py install\n",
    "    !cd Tensorflow/models/research/slim && pip install -e . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4XWmBJOB5pxy",
    "outputId": "91734627-cac9-4c5b-ea84-a1a542dd3f35",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                         Version\n",
      "------------------------------- ----------------------\n",
      "absl-py                         1.3.0\n",
      "aeppl                           0.0.33\n",
      "aesara                          2.7.9\n",
      "aiohttp                         3.8.3\n",
      "aiosignal                       1.2.0\n",
      "alabaster                       0.7.12\n",
      "albumentations                  1.2.1\n",
      "altair                          4.2.0\n",
      "apache-beam                     2.42.0\n",
      "appdirs                         1.4.4\n",
      "arviz                           0.12.1\n",
      "astor                           0.8.1\n",
      "astropy                         4.3.1\n",
      "astunparse                      1.6.3\n",
      "async-timeout                   4.0.2\n",
      "asynctest                       0.13.0\n",
      "atari-py                        0.2.9\n",
      "atomicwrites                    1.4.1\n",
      "attrs                           22.1.0\n",
      "audioread                       3.0.0\n",
      "autograd                        1.5\n",
      "avro-python3                    1.10.2\n",
      "Babel                           2.10.3\n",
      "backcall                        0.2.0\n",
      "beautifulsoup4                  4.6.3\n",
      "bleach                          5.0.1\n",
      "blis                            0.7.8\n",
      "bokeh                           2.3.3\n",
      "branca                          0.5.0\n",
      "bs4                             0.0.1\n",
      "CacheControl                    0.12.11\n",
      "cached-property                 1.5.2\n",
      "cachetools                      4.2.4\n",
      "catalogue                       2.0.8\n",
      "certifi                         2022.9.24\n",
      "cffi                            1.15.1\n",
      "cftime                          1.6.2\n",
      "chardet                         3.0.4\n",
      "charset-normalizer              2.1.1\n",
      "click                           7.1.2\n",
      "clikit                          0.6.2\n",
      "cloudpickle                     2.1.0\n",
      "cmake                           3.22.6\n",
      "cmdstanpy                       1.0.7\n",
      "colorama                        0.4.5\n",
      "colorcet                        3.0.1\n",
      "colorlover                      0.3.0\n",
      "community                       1.0.0b1\n",
      "confection                      0.0.3\n",
      "cons                            0.4.5\n",
      "contextlib2                     0.5.5\n",
      "convertdate                     2.4.0\n",
      "crashtest                       0.3.1\n",
      "crcmod                          1.7\n",
      "cryptography                    38.0.1\n",
      "cufflinks                       0.17.3\n",
      "cupy-cuda11x                    11.0.0\n",
      "cvxopt                          1.3.0\n",
      "cvxpy                           1.2.1\n",
      "cycler                          0.11.0\n",
      "cymem                           2.0.7\n",
      "Cython                          0.29.32\n",
      "daft                            0.0.4\n",
      "dask                            2022.2.0\n",
      "datascience                     0.17.5\n",
      "debugpy                         1.0.0\n",
      "decorator                       4.4.2\n",
      "defusedxml                      0.7.1\n",
      "descartes                       1.1.0\n",
      "dill                            0.3.1.1\n",
      "distributed                     2022.2.0\n",
      "dlib                            19.24.0\n",
      "dm-tree                         0.1.7\n",
      "docopt                          0.6.2\n",
      "docutils                        0.17.1\n",
      "dopamine-rl                     1.0.5\n",
      "earthengine-api                 0.1.327\n",
      "easydict                        1.10\n",
      "ecos                            2.0.10\n",
      "editdistance                    0.5.3\n",
      "en-core-web-sm                  3.4.1\n",
      "entrypoints                     0.4\n",
      "ephem                           4.1.3\n",
      "et-xmlfile                      1.1.0\n",
      "etils                           0.8.0\n",
      "etuples                         0.3.8\n",
      "fa2                             0.3.5\n",
      "fastai                          2.7.9\n",
      "fastavro                        1.6.1\n",
      "fastcore                        1.5.27\n",
      "fastdownload                    0.0.7\n",
      "fastdtw                         0.3.4\n",
      "fastjsonschema                  2.16.2\n",
      "fastprogress                    1.0.3\n",
      "fastrlock                       0.8\n",
      "feather-format                  0.4.1\n",
      "filelock                        3.8.0\n",
      "firebase-admin                  4.4.0\n",
      "fix-yahoo-finance               0.0.22\n",
      "Flask                           1.1.4\n",
      "flatbuffers                     22.9.24\n",
      "folium                          0.12.1.post1\n",
      "frozenlist                      1.3.1\n",
      "fsspec                          2022.8.2\n",
      "future                          0.16.0\n",
      "gast                            0.4.0\n",
      "GDAL                            2.2.2\n",
      "gdown                           4.4.0\n",
      "gensim                          3.6.0\n",
      "geographiclib                   1.52\n",
      "geopy                           1.17.0\n",
      "gin-config                      0.5.0\n",
      "glob2                           0.7\n",
      "google                          2.0.3\n",
      "google-api-core                 1.31.6\n",
      "google-api-python-client        1.12.11\n",
      "google-auth                     1.35.0\n",
      "google-auth-httplib2            0.0.4\n",
      "google-auth-oauthlib            0.4.6\n",
      "google-cloud-bigquery           1.21.0\n",
      "google-cloud-bigquery-storage   1.1.2\n",
      "google-cloud-core               1.0.3\n",
      "google-cloud-datastore          1.8.0\n",
      "google-cloud-firestore          1.7.0\n",
      "google-cloud-language           1.2.0\n",
      "google-cloud-storage            1.18.1\n",
      "google-cloud-translate          1.5.0\n",
      "google-colab                    1.0.0\n",
      "google-pasta                    0.2.0\n",
      "google-resumable-media          0.4.1\n",
      "googleapis-common-protos        1.56.4\n",
      "googledrivedownloader           0.4\n",
      "graphviz                        0.10.1\n",
      "greenlet                        1.1.3.post0\n",
      "grpcio                          1.49.1\n",
      "gspread                         3.4.2\n",
      "gspread-dataframe               3.0.8\n",
      "gym                             0.25.2\n",
      "gym-notices                     0.0.8\n",
      "h5py                            3.1.0\n",
      "hdfs                            2.7.0\n",
      "HeapDict                        1.0.1\n",
      "hijri-converter                 2.2.4\n",
      "holidays                        0.16\n",
      "holoviews                       1.14.9\n",
      "html5lib                        1.0.1\n",
      "httpimport                      0.5.18\n",
      "httplib2                        0.17.4\n",
      "httplib2shim                    0.0.3\n",
      "httpstan                        4.6.1\n",
      "humanize                        0.5.1\n",
      "hyperopt                        0.1.2\n",
      "idna                            2.10\n",
      "imageio                         2.9.0\n",
      "imagesize                       1.4.1\n",
      "imbalanced-learn                0.8.1\n",
      "imblearn                        0.0\n",
      "imgaug                          0.4.0\n",
      "immutabledict                   2.2.1\n",
      "importlib-metadata              4.13.0\n",
      "importlib-resources             5.10.0\n",
      "imutils                         0.5.4\n",
      "inflect                         2.1.0\n",
      "intel-openmp                    2022.2.0\n",
      "intervaltree                    2.1.0\n",
      "ipykernel                       5.3.4\n",
      "ipython                         7.9.0\n",
      "ipython-genutils                0.2.0\n",
      "ipython-sql                     0.3.9\n",
      "ipywidgets                      7.7.1\n",
      "itsdangerous                    1.1.0\n",
      "jaraco.classes                  3.2.3\n",
      "jax                             0.3.23\n",
      "jaxlib                          0.3.22+cuda11.cudnn805\n",
      "jedi                            0.18.1\n",
      "jeepney                         0.8.0\n",
      "jieba                           0.42.1\n",
      "Jinja2                          2.11.3\n",
      "joblib                          1.2.0\n",
      "jpeg4py                         0.1.4\n",
      "jsonschema                      4.3.3\n",
      "jupyter                         1.0.0\n",
      "jupyter-client                  6.1.12\n",
      "jupyter-console                 6.1.0\n",
      "jupyter-core                    4.11.1\n",
      "jupyterlab-widgets              3.0.3\n",
      "kaggle                          1.5.12\n",
      "kapre                           0.3.7\n",
      "keras                           2.10.0\n",
      "Keras-Preprocessing             1.1.2\n",
      "keras-vis                       0.4.1\n",
      "keyring                         23.9.3\n",
      "kiwisolver                      1.4.4\n",
      "korean-lunar-calendar           0.3.1\n",
      "langcodes                       3.3.0\n",
      "libclang                        14.0.6\n",
      "librosa                         0.8.1\n",
      "lightgbm                        2.2.3\n",
      "llvmlite                        0.39.1\n",
      "lmdb                            0.99\n",
      "locket                          1.0.0\n",
      "logical-unification             0.4.5\n",
      "LunarCalendar                   0.0.9\n",
      "lvis                            0.5.3\n",
      "lxml                            4.9.1\n",
      "Markdown                        3.4.1\n",
      "MarkupSafe                      2.0.1\n",
      "marshmallow                     3.18.0\n",
      "matplotlib                      3.2.2\n",
      "matplotlib-venn                 0.11.7\n",
      "miniKanren                      1.0.3\n",
      "missingno                       0.5.1\n",
      "mistune                         0.8.4\n",
      "mizani                          0.7.3\n",
      "mkl                             2019.0\n",
      "mlxtend                         0.14.0\n",
      "more-itertools                  8.14.0\n",
      "moviepy                         0.2.3.5\n",
      "mpmath                          1.2.1\n",
      "msgpack                         1.0.4\n",
      "multidict                       6.0.2\n",
      "multipledispatch                0.6.0\n",
      "multitasking                    0.0.11\n",
      "murmurhash                      1.0.9\n",
      "music21                         5.5.0\n",
      "natsort                         5.5.0\n",
      "nbconvert                       5.6.1\n",
      "nbformat                        5.7.0\n",
      "netCDF4                         1.6.1\n",
      "networkx                        2.6.3\n",
      "nibabel                         3.0.2\n",
      "nltk                            3.7\n",
      "notebook                        5.5.0\n",
      "numba                           0.56.3\n",
      "numexpr                         2.8.3\n",
      "numpy                           1.21.6\n",
      "oauth2client                    4.1.3\n",
      "oauthlib                        3.2.1\n",
      "object-detection                0.1\n",
      "okgrade                         0.4.3\n",
      "opencv-contrib-python           4.6.0.66\n",
      "opencv-python                   4.6.0.66\n",
      "opencv-python-headless          4.5.2.52\n",
      "openpyxl                        3.0.10\n",
      "opt-einsum                      3.3.0\n",
      "orjson                          3.8.0\n",
      "osqp                            0.6.2.post0\n",
      "packaging                       21.3\n",
      "palettable                      3.3.0\n",
      "pandas                          1.3.5\n",
      "pandas-datareader               0.9.0\n",
      "pandas-gbq                      0.13.3\n",
      "pandas-profiling                1.4.1\n",
      "pandocfilters                   1.5.0\n",
      "panel                           0.12.1\n",
      "param                           1.12.2\n",
      "parso                           0.8.3\n",
      "partd                           1.3.0\n",
      "pastel                          0.2.1\n",
      "pathlib                         1.0.1\n",
      "pathy                           0.6.2\n",
      "patsy                           0.5.3\n",
      "pep517                          0.13.0\n",
      "pexpect                         4.8.0\n",
      "pickleshare                     0.7.5\n",
      "Pillow                          7.1.2\n",
      "pip                             21.1.3\n",
      "pip-tools                       6.2.0\n",
      "pkginfo                         1.8.3\n",
      "plotly                          5.5.0\n",
      "plotnine                        0.8.0\n",
      "pluggy                          0.7.1\n",
      "pooch                           1.6.0\n",
      "portalocker                     2.6.0\n",
      "portpicker                      1.3.9\n",
      "prefetch-generator              1.0.1\n",
      "preshed                         3.0.8\n",
      "prettytable                     3.4.1\n",
      "progressbar2                    3.38.0\n",
      "promise                         2.3\n",
      "prompt-toolkit                  2.0.10\n",
      "prophet                         1.1.1\n",
      "proto-plus                      1.22.1\n",
      "protobuf                        3.19.6\n",
      "psutil                          5.4.8\n",
      "psycopg2                        2.9.4\n",
      "ptyprocess                      0.7.0\n",
      "py                              1.11.0\n",
      "py-cpuinfo                      8.0.0\n",
      "pyarrow                         6.0.1\n",
      "pyasn1                          0.4.8\n",
      "pyasn1-modules                  0.2.8\n",
      "pycocotools                     2.0.5\n",
      "pycparser                       2.21\n",
      "pyct                            0.4.8\n",
      "pydantic                        1.9.2\n",
      "pydata-google-auth              1.4.0\n",
      "pydot                           1.3.0\n",
      "pydot-ng                        2.0.0\n",
      "pydotplus                       2.0.2\n",
      "PyDrive                         1.3.1\n",
      "pyemd                           0.5.1\n",
      "pyerfa                          2.0.0.1\n",
      "Pygments                        2.6.1\n",
      "pygobject                       3.26.1\n",
      "pylev                           1.4.0\n",
      "pymc                            4.1.4\n",
      "PyMeeus                         0.5.11\n",
      "pymongo                         3.12.3\n",
      "pymystem3                       0.2.0\n",
      "PyOpenGL                        3.1.6\n",
      "pyparsing                       2.4.7\n",
      "pyrsistent                      0.18.1\n",
      "pysimdjson                      3.2.0\n",
      "pysndfile                       1.3.8\n",
      "PySocks                         1.7.1\n",
      "pystan                          3.3.0\n",
      "pytest                          3.6.4\n",
      "python-apt                      0.0.0\n",
      "python-chess                    0.23.11\n",
      "python-dateutil                 2.8.2\n",
      "python-louvain                  0.16\n",
      "python-slugify                  6.1.2\n",
      "python-utils                    3.3.3\n",
      "pytz                            2022.4\n",
      "pyviz-comms                     2.2.1\n",
      "PyWavelets                      1.3.0\n",
      "PyYAML                          5.4.1\n",
      "pyzmq                           23.2.1\n",
      "qdldl                           0.1.5.post2\n",
      "qtconsole                       5.3.2\n",
      "QtPy                            2.2.1\n",
      "qudida                          0.0.4\n",
      "readme-renderer                 37.2\n",
      "regex                           2022.6.2\n",
      "requests                        2.28.1\n",
      "requests-oauthlib               1.3.1\n",
      "requests-toolbelt               0.10.0\n",
      "resampy                         0.4.2\n",
      "rfc3986                         2.0.0\n",
      "rpy2                            3.4.5\n",
      "rsa                             4.9\n",
      "sacrebleu                       2.2.0\n",
      "scikit-image                    0.18.3\n",
      "scikit-learn                    1.0.2\n",
      "scipy                           1.7.3\n",
      "screen-resolution-extra         0.0.0\n",
      "scs                             3.2.0\n",
      "seaborn                         0.11.2\n",
      "SecretStorage                   3.3.3\n",
      "Send2Trash                      1.8.0\n",
      "sentencepiece                   0.1.97\n",
      "seqeval                         1.2.2\n",
      "setuptools                      57.4.0\n",
      "setuptools-git                  1.2\n",
      "Shapely                         1.8.5.post1\n",
      "six                             1.15.0\n",
      "sklearn-pandas                  1.8.0\n",
      "smart-open                      5.2.1\n",
      "snowballstemmer                 2.2.0\n",
      "sortedcontainers                2.4.0\n",
      "soundfile                       0.11.0\n",
      "spacy                           3.4.1\n",
      "spacy-legacy                    3.0.10\n",
      "spacy-loggers                   1.0.3\n",
      "Sphinx                          1.8.6\n",
      "sphinxcontrib-serializinghtml   1.1.5\n",
      "sphinxcontrib-websupport        1.2.4\n",
      "SQLAlchemy                      1.4.41\n",
      "sqlparse                        0.4.3\n",
      "srsly                           2.4.4\n",
      "statsmodels                     0.12.2\n",
      "sympy                           1.7.1\n",
      "tables                          3.7.0\n",
      "tabulate                        0.8.10\n",
      "tblib                           1.7.0\n",
      "tenacity                        8.1.0\n",
      "tensorboard                     2.10.1\n",
      "tensorboard-data-server         0.6.1\n",
      "tensorboard-plugin-wit          1.8.1\n",
      "tensorflow                      2.10.0\n",
      "tensorflow-addons               0.18.0\n",
      "tensorflow-datasets             4.6.0\n",
      "tensorflow-estimator            2.10.0\n",
      "tensorflow-gcs-config           2.9.1\n",
      "tensorflow-hub                  0.12.0\n",
      "tensorflow-io                   0.27.0\n",
      "tensorflow-io-gcs-filesystem    0.27.0\n",
      "tensorflow-metadata             1.10.0\n",
      "tensorflow-model-optimization   0.7.3\n",
      "tensorflow-object-detection-api 0.1.1\n",
      "tensorflow-probability          0.16.0\n",
      "tensorflow-text                 2.10.0\n",
      "termcolor                       2.0.1\n",
      "terminado                       0.13.3\n",
      "testpath                        0.6.0\n",
      "text-unidecode                  1.3\n",
      "textblob                        0.15.3\n",
      "tf-models-official              2.10.0\n",
      "tf-slim                         1.1.0\n",
      "thinc                           8.1.4\n",
      "threadpoolctl                   3.1.0\n",
      "tifffile                        2021.11.2\n",
      "toml                            0.10.2\n",
      "tomli                           2.0.1\n",
      "toolz                           0.12.0\n",
      "torch                           1.12.1+cu113\n",
      "torchaudio                      0.12.1+cu113\n",
      "torchsummary                    1.5.1\n",
      "torchtext                       0.13.1\n",
      "torchvision                     0.13.1+cu113\n",
      "tornado                         5.1.1\n",
      "tqdm                            4.64.1\n",
      "traitlets                       5.1.1\n",
      "tweepy                          3.10.0\n",
      "twine                           3.7.1\n",
      "typeguard                       2.7.1\n",
      "typer                           0.4.2\n",
      "typing-extensions               4.1.1\n",
      "tzlocal                         1.5.1\n",
      "ujson                           5.5.0\n",
      "uritemplate                     3.0.1\n",
      "urllib3                         1.24.3\n",
      "vega-datasets                   0.9.0\n",
      "wasabi                          0.10.1\n",
      "wcwidth                         0.2.5\n",
      "webargs                         8.2.0\n",
      "webencodings                    0.5.1\n",
      "Werkzeug                        1.0.1\n",
      "wheel                           0.37.1\n",
      "widgetsnbextension              3.6.1\n",
      "wordcloud                       1.8.2.2\n",
      "wrapt                           1.14.1\n",
      "xarray                          0.20.2\n",
      "xarray-einstats                 0.2.2\n",
      "xgboost                         0.90\n",
      "xkit                            0.0.0\n",
      "xlrd                            1.1.0\n",
      "xlwt                            1.3.0\n",
      "yarl                            1.8.1\n",
      "yellowbrick                     1.5\n",
      "zict                            2.2.0\n",
      "zipp                            3.9.0\n",
      "zstandard                       0.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_DUgad8SqXRA"
   },
   "source": [
    "Verification script for the installation verification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ubPyqZTj5pxz",
    "outputId": "a39754c2-2212-472b-fe4f-37a9ea944730",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 13:05:20.594956: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 13:05:21.688679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 13:05:21.688914: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 13:05:21.688937: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Running tests under Python 3.7.15: /usr/bin/python3\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "2022-10-22 13:05:25.448235: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "W1022 13:05:25.815008 140171267708800 model_builder.py:1109] Building experimental DeepMAC meta-arch. Some features may be omitted.\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.6s\n",
      "I1022 13:05:26.100098 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_deepmac): 1.6s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_deepmac\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.54s\n",
      "I1022 13:05:26.637552 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)): 0.54s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model0 (customize_head_params=True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
      "I1022 13:05:26.894291 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)): 0.26s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model1 (customize_head_params=False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
      "I1022 13:05:27.247210 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_from_keypoints): 0.35s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_from_keypoints\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.93s\n",
      "I1022 13:05:29.179542 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_center_net_model_mobilenet): 1.93s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_center_net_model_mobilenet\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "I1022 13:05:29.185572 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_experimental_model): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_experimental_model\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "I1022 13:05:29.210199 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature0 (True)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "I1022 13:05:29.225592 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)): 0.01s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_from_config_with_crop_feature1 (False)\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "I1022 13:05:29.241262 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner): 0.02s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_model_from_config_with_example_miner\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "I1022 13:05:29.333478 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul): 0.09s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
      "I1022 13:05:29.437408 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_faster_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
      "I1022 13:05:29.534689 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_with_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
      "I1022 13:05:29.631435 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul): 0.1s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_faster_rcnn_models_from_config_mask_rcnn_without_matmul\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.21s\n",
      "I1022 13:05:29.842083 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_rfcn_model_from_config): 0.21s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_rfcn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "I1022 13:05:29.888386 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config): 0.05s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_fpn_model_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "I1022 13:05:30.186089 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I1022 13:05:30.186297 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 64\n",
      "I1022 13:05:30.186408 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 3\n",
      "I1022 13:05:30.189784 140171267708800 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1022 13:05:30.231360 140171267708800 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1022 13:05:30.231522 140171267708800 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1022 13:05:30.349045 140171267708800 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1022 13:05:30.349238 140171267708800 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1022 13:05:30.672279 140171267708800 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1022 13:05:30.672492 140171267708800 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1022 13:05:31.315770 140171267708800 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1022 13:05:31.321671 140171267708800 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1022 13:05:32.263452 140171267708800 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1022 13:05:32.263679 140171267708800 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1022 13:05:33.531908 140171267708800 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1022 13:05:33.532914 140171267708800 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1022 13:05:34.750185 140171267708800 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1022 13:05:34.750547 140171267708800 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1022 13:05:35.079621 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1022 13:05:35.190311 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:05:35.376646 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b1\n",
      "I1022 13:05:35.377914 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 88\n",
      "I1022 13:05:35.378026 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 4\n",
      "I1022 13:05:35.386815 140171267708800 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1022 13:05:35.437492 140171267708800 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1022 13:05:35.437643 140171267708800 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1022 13:05:36.014590 140171267708800 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1022 13:05:36.022101 140171267708800 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1022 13:05:37.257986 140171267708800 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1022 13:05:37.261803 140171267708800 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1022 13:05:38.184516 140171267708800 efficientnet_model.py:143] round_filter input=40 output=40\n",
      "I1022 13:05:38.184739 140171267708800 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1022 13:05:39.426510 140171267708800 efficientnet_model.py:143] round_filter input=80 output=80\n",
      "I1022 13:05:39.428242 140171267708800 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1022 13:05:40.620887 140171267708800 efficientnet_model.py:143] round_filter input=112 output=112\n",
      "I1022 13:05:40.621126 140171267708800 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1022 13:05:42.226993 140171267708800 efficientnet_model.py:143] round_filter input=192 output=192\n",
      "I1022 13:05:42.227209 140171267708800 efficientnet_model.py:143] round_filter input=320 output=320\n",
      "I1022 13:05:42.791928 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=1280\n",
      "I1022 13:05:42.843137 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.1, resolution=240, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:05:42.987412 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b2\n",
      "I1022 13:05:42.997797 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 112\n",
      "I1022 13:05:42.997961 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 5\n",
      "I1022 13:05:43.000517 140171267708800 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1022 13:05:43.030355 140171267708800 efficientnet_model.py:143] round_filter input=32 output=32\n",
      "I1022 13:05:43.030548 140171267708800 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1022 13:05:43.293219 140171267708800 efficientnet_model.py:143] round_filter input=16 output=16\n",
      "I1022 13:05:43.293429 140171267708800 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1022 13:05:43.915967 140171267708800 efficientnet_model.py:143] round_filter input=24 output=24\n",
      "I1022 13:05:43.916163 140171267708800 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1022 13:05:44.650078 140171267708800 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1022 13:05:44.650319 140171267708800 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1022 13:05:45.353831 140171267708800 efficientnet_model.py:143] round_filter input=80 output=88\n",
      "I1022 13:05:45.354048 140171267708800 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1022 13:05:46.047439 140171267708800 efficientnet_model.py:143] round_filter input=112 output=120\n",
      "I1022 13:05:46.047691 140171267708800 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1022 13:05:46.839373 140171267708800 efficientnet_model.py:143] round_filter input=192 output=208\n",
      "I1022 13:05:46.839587 140171267708800 efficientnet_model.py:143] round_filter input=320 output=352\n",
      "I1022 13:05:47.182832 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=1408\n",
      "I1022 13:05:47.275254 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.1, depth_coefficient=1.2, resolution=260, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:05:47.500313 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b3\n",
      "I1022 13:05:47.500530 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 160\n",
      "I1022 13:05:47.500616 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 6\n",
      "I1022 13:05:47.503392 140171267708800 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1022 13:05:47.552235 140171267708800 efficientnet_model.py:143] round_filter input=32 output=40\n",
      "I1022 13:05:47.552410 140171267708800 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1022 13:05:47.830249 140171267708800 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1022 13:05:47.830465 140171267708800 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1022 13:05:48.376808 140171267708800 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1022 13:05:48.377026 140171267708800 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1022 13:05:49.161965 140171267708800 efficientnet_model.py:143] round_filter input=40 output=48\n",
      "I1022 13:05:49.162206 140171267708800 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1022 13:05:50.139662 140171267708800 efficientnet_model.py:143] round_filter input=80 output=96\n",
      "I1022 13:05:50.139899 140171267708800 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1022 13:05:51.328795 140171267708800 efficientnet_model.py:143] round_filter input=112 output=136\n",
      "I1022 13:05:51.334763 140171267708800 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1022 13:05:52.486835 140171267708800 efficientnet_model.py:143] round_filter input=192 output=232\n",
      "I1022 13:05:52.487081 140171267708800 efficientnet_model.py:143] round_filter input=320 output=384\n",
      "I1022 13:05:53.029103 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=1536\n",
      "I1022 13:05:53.088741 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.2, depth_coefficient=1.4, resolution=300, dropout_rate=0.3, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:05:53.207647 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b4\n",
      "I1022 13:05:53.207877 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 224\n",
      "I1022 13:05:53.207977 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
      "I1022 13:05:53.210431 140171267708800 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1022 13:05:53.239423 140171267708800 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1022 13:05:53.239601 140171267708800 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1022 13:05:53.570562 140171267708800 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1022 13:05:53.570759 140171267708800 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1022 13:05:53.917072 140171267708800 efficientnet_model.py:143] round_filter input=24 output=32\n",
      "I1022 13:05:53.917248 140171267708800 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1022 13:05:54.281583 140171267708800 efficientnet_model.py:143] round_filter input=40 output=56\n",
      "I1022 13:05:54.281781 140171267708800 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1022 13:05:54.817797 140171267708800 efficientnet_model.py:143] round_filter input=80 output=112\n",
      "I1022 13:05:54.817963 140171267708800 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1022 13:05:55.365173 140171267708800 efficientnet_model.py:143] round_filter input=112 output=160\n",
      "I1022 13:05:55.365439 140171267708800 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1022 13:05:56.087500 140171267708800 efficientnet_model.py:143] round_filter input=192 output=272\n",
      "I1022 13:05:56.087690 140171267708800 efficientnet_model.py:143] round_filter input=320 output=448\n",
      "I1022 13:05:56.276348 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=1792\n",
      "I1022 13:05:56.317178 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.4, depth_coefficient=1.8, resolution=380, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:05:56.389096 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b5\n",
      "I1022 13:05:56.389258 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 288\n",
      "I1022 13:05:56.389336 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 7\n",
      "I1022 13:05:56.390896 140171267708800 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1022 13:05:56.409529 140171267708800 efficientnet_model.py:143] round_filter input=32 output=48\n",
      "I1022 13:05:56.409648 140171267708800 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1022 13:05:56.634036 140171267708800 efficientnet_model.py:143] round_filter input=16 output=24\n",
      "I1022 13:05:56.634210 140171267708800 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1022 13:05:57.070012 140171267708800 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1022 13:05:57.070188 140171267708800 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1022 13:05:57.542007 140171267708800 efficientnet_model.py:143] round_filter input=40 output=64\n",
      "I1022 13:05:57.542183 140171267708800 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1022 13:05:58.411527 140171267708800 efficientnet_model.py:143] round_filter input=80 output=128\n",
      "I1022 13:05:58.411765 140171267708800 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1022 13:05:59.061208 140171267708800 efficientnet_model.py:143] round_filter input=112 output=176\n",
      "I1022 13:05:59.061396 140171267708800 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1022 13:05:59.894794 140171267708800 efficientnet_model.py:143] round_filter input=192 output=304\n",
      "I1022 13:05:59.894980 140171267708800 efficientnet_model.py:143] round_filter input=320 output=512\n",
      "I1022 13:06:00.170370 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=2048\n",
      "I1022 13:06:00.208472 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.6, depth_coefficient=2.2, resolution=456, dropout_rate=0.4, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:06:00.293001 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b6\n",
      "I1022 13:06:00.293174 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 384\n",
      "I1022 13:06:00.293250 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
      "I1022 13:06:00.294788 140171267708800 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1022 13:06:00.315005 140171267708800 efficientnet_model.py:143] round_filter input=32 output=56\n",
      "I1022 13:06:00.315175 140171267708800 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1022 13:06:00.548431 140171267708800 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1022 13:06:00.548611 140171267708800 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1022 13:06:01.093845 140171267708800 efficientnet_model.py:143] round_filter input=24 output=40\n",
      "I1022 13:06:01.094021 140171267708800 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1022 13:06:01.652525 140171267708800 efficientnet_model.py:143] round_filter input=40 output=72\n",
      "I1022 13:06:01.652728 140171267708800 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1022 13:06:02.379097 140171267708800 efficientnet_model.py:143] round_filter input=80 output=144\n",
      "I1022 13:06:02.379296 140171267708800 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1022 13:06:03.102002 140171267708800 efficientnet_model.py:143] round_filter input=112 output=200\n",
      "I1022 13:06:03.102188 140171267708800 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1022 13:06:04.093955 140171267708800 efficientnet_model.py:143] round_filter input=192 output=344\n",
      "I1022 13:06:04.094131 140171267708800 efficientnet_model.py:143] round_filter input=320 output=576\n",
      "I1022 13:06:04.371623 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=2304\n",
      "I1022 13:06:04.408350 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=1.8, depth_coefficient=2.6, resolution=528, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "I1022 13:06:04.507040 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:150] EfficientDet EfficientNet backbone version: efficientnet-b7\n",
      "I1022 13:06:04.507228 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:151] EfficientDet BiFPN num filters: 384\n",
      "I1022 13:06:04.507302 140171267708800 ssd_efficientnet_bifpn_feature_extractor.py:153] EfficientDet BiFPN num iterations: 8\n",
      "I1022 13:06:04.508928 140171267708800 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1022 13:06:04.530064 140171267708800 efficientnet_model.py:143] round_filter input=32 output=64\n",
      "I1022 13:06:04.530254 140171267708800 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1022 13:06:04.842014 140171267708800 efficientnet_model.py:143] round_filter input=16 output=32\n",
      "I1022 13:06:04.842214 140171267708800 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1022 13:06:05.725231 140171267708800 efficientnet_model.py:143] round_filter input=24 output=48\n",
      "I1022 13:06:05.725413 140171267708800 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1022 13:06:06.354369 140171267708800 efficientnet_model.py:143] round_filter input=40 output=80\n",
      "I1022 13:06:06.354544 140171267708800 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1022 13:06:07.288249 140171267708800 efficientnet_model.py:143] round_filter input=80 output=160\n",
      "I1022 13:06:07.288431 140171267708800 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1022 13:06:08.213111 140171267708800 efficientnet_model.py:143] round_filter input=112 output=224\n",
      "I1022 13:06:08.213303 140171267708800 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1022 13:06:09.388737 140171267708800 efficientnet_model.py:143] round_filter input=192 output=384\n",
      "I1022 13:06:09.388911 140171267708800 efficientnet_model.py:143] round_filter input=320 output=640\n",
      "I1022 13:06:09.781718 140171267708800 efficientnet_model.py:143] round_filter input=1280 output=2560\n",
      "I1022 13:06:09.830326 140171267708800 efficientnet_model.py:453] Building model efficientnet with params ModelConfig(width_coefficient=2.0, depth_coefficient=3.1, resolution=600, dropout_rate=0.5, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.06s\n",
      "I1022 13:06:09.948180 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_create_ssd_models_from_config): 40.06s\n",
      "[       OK ] ModelBuilderTF2Test.test_create_ssd_models_from_config\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "I1022 13:06:09.976500 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_faster_rcnn_batchnorm_update\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "I1022 13:06:09.978418 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_first_stage_nms_iou_threshold\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "I1022 13:06:09.979027 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_model_config_proto): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_model_config_proto\n",
      "[ RUN      ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "I1022 13:06:09.980589 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_invalid_second_stage_batch_size): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_invalid_second_stage_batch_size\n",
      "[ RUN      ] ModelBuilderTF2Test.test_session\n",
      "[  SKIPPED ] ModelBuilderTF2Test.test_session\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "I1022 13:06:09.981914 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_faster_rcnn_feature_extractor\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "I1022 13:06:09.982362 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_meta_architecture): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_meta_architecture\n",
      "[ RUN      ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "INFO:tensorflow:time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "I1022 13:06:09.983437 140171267708800 test_util.py:2461] time(__main__.ModelBuilderTF2Test.test_unknown_ssd_feature_extractor): 0.0s\n",
      "[       OK ] ModelBuilderTF2Test.test_unknown_ssd_feature_extractor\n",
      "----------------------------------------------------------------------\n",
      "Ran 24 tests in 45.483s\n",
      "\n",
      "OK (skipped=1)\n"
     ]
    }
   ],
   "source": [
    "VERIFICATION_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'builders', 'model_builder_tf2_test.py')\n",
    "# Verify Installation\n",
    "!python {VERIFICATION_SCRIPT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DMCZp4jJ5px2"
   },
   "outputs": [],
   "source": [
    "import object_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "csofht2npfDE",
    "outputId": "ab01b270-a717-41b8-94df-500b2880a108"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-10-22 13:06:11--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 90453990 (86M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v1_fp 100%[===================>]  86.26M  48.3MB/s    in 1.8s    \n",
      "\n",
      "2022-10-22 13:06:13 (48.3 MB/s) - ‘ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [90453990/90453990]\n",
      "\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n",
      "--2022-10-22 13:06:15--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 386527459 (369M) [application/x-tar]\n",
      "Saving to: ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_resnet101_v1_fp 100%[===================>] 368.62M   113MB/s    in 3.3s    \n",
      "\n",
      "2022-10-22 13:06:18 (113 MB/s) - ‘ssd_resnet101_v1_fpn_640x640_coco17_tpu-8.tar.gz’ saved [386527459/386527459]\n",
      "\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/pipeline.config\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/assets/\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/saved_model/variables/variables.index\n",
      "--2022-10-22 13:06:24--  http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz\n",
      "Resolving download.tensorflow.org (download.tensorflow.org)... 108.177.119.128, 2a00:1450:4013:c00::80\n",
      "Connecting to download.tensorflow.org (download.tensorflow.org)|108.177.119.128|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 20518283 (20M) [application/x-tar]\n",
      "Saving to: ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’\n",
      "\n",
      "ssd_mobilenet_v2_fp 100%[===================>]  19.57M  96.0MB/s    in 0.2s    \n",
      "\n",
      "2022-10-22 13:06:25 (96.0 MB/s) - ‘ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz’ saved [20518283/20518283]\n",
      "\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/checkpoint\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0.index\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/pipeline.config\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/saved_model.pb\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.data-00000-of-00001\n",
      "ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/saved_model/variables/variables.index\n"
     ]
    }
   ],
   "source": [
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL}\n",
    "    !mv {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}\n",
    "\n",
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL2}\n",
    "    !mv {PRETRAINED_MODEL_NAME2+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME2+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL2)\n",
    "    !move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME2+'.tar.gz'}\n",
    "\n",
    "if os.name =='posix':\n",
    "    !wget {PRETRAINED_MODEL_URL3}\n",
    "    !mv {PRETRAINED_MODEL_NAME3+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME3+'.tar.gz'}\n",
    "if os.name == 'nt':\n",
    "    wget.download(PRETRAINED_MODEL_URL3)\n",
    "    !move {PRETRAINED_MODEL_NAME3+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}\n",
    "    !cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME3+'.tar.gz'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M5KJTnkfpfDC"
   },
   "source": [
    "# 2. Create Label Map\n",
    "creating a lapmap.txt file which will help us for labling during testing and training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "p1BVDWo7pfDC"
   },
   "outputs": [],
   "source": [
    "labels = [{'name':'object', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C88zyVELpfDC"
   },
   "source": [
    "# 3. Create TF records\n",
    "\n",
    "Converting the images ato tfrecord (binary formate) by using csv annoations file. # 3. Create TF records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HvnVNQF6KKvV",
    "outputId": "3f14aea1-b275-4a4b-b0dc-4dd6e0d4475f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kvf5WccwrFGq",
    "outputId": "7cbd1ca3-dc2c-45bb-af6d-b05eaa2341f6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/inventory_images.zip\n",
      "   creating: inventory_images/\n",
      "  inflating: __MACOSX/._inventory_images  \n",
      "  inflating: inventory_images/.DS_Store  \n",
      "  inflating: __MACOSX/inventory_images/._.DS_Store  \n",
      "   creating: inventory_images/test/\n",
      "  inflating: __MACOSX/inventory_images/._test  \n",
      "  inflating: inventory_images/Untitled.ipynb  \n",
      "  inflating: __MACOSX/inventory_images/._Untitled.ipynb  \n",
      "  inflating: inventory_images/train_ant.csv  \n",
      "  inflating: __MACOSX/inventory_images/._train_ant.csv  \n",
      "   creating: inventory_images/annotations/\n",
      "  inflating: __MACOSX/inventory_images/._annotations  \n",
      "   creating: inventory_images/train/\n",
      "  inflating: __MACOSX/inventory_images/._train  \n",
      "   creating: inventory_images/val/\n",
      "  inflating: __MACOSX/inventory_images/._val  \n",
      "  inflating: inventory_images/test/test_14.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_14.jpg  \n",
      "  inflating: inventory_images/test/test_28.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_28.jpg  \n",
      "  inflating: inventory_images/test/test_29.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_29.jpg  \n",
      "  inflating: inventory_images/test/test_15.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_15.jpg  \n",
      "  inflating: inventory_images/test/test_9.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_9.jpg  \n",
      "  inflating: inventory_images/test/test_17.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_17.jpg  \n",
      "  inflating: inventory_images/test/test_16.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_16.jpg  \n",
      "  inflating: inventory_images/test/test_8.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_8.jpg  \n",
      "  inflating: inventory_images/test/test_12.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_12.jpg  \n",
      "  inflating: inventory_images/test/test_13.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_13.jpg  \n",
      "  inflating: inventory_images/test/test_11.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_11.jpg  \n",
      "  inflating: inventory_images/test/test_10.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_10.jpg  \n",
      "  inflating: inventory_images/test/test_3.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_3.jpg  \n",
      "  inflating: inventory_images/test/test_21.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_21.jpg  \n",
      "  inflating: inventory_images/test/test_35.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_35.jpg  \n",
      "  inflating: inventory_images/test/test_34.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_34.jpg  \n",
      "  inflating: inventory_images/test/test_20.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_20.jpg  \n",
      "  inflating: inventory_images/test/test_2.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_2.jpg  \n",
      "  inflating: inventory_images/test/test_0.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_0.jpg  \n",
      "  inflating: inventory_images/test/test_22.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_22.jpg  \n",
      "  inflating: inventory_images/test/test_23.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_23.jpg  \n",
      "  inflating: inventory_images/test/test_1.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_1.jpg  \n",
      "  inflating: inventory_images/test/test_5.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_5.jpg  \n",
      "  inflating: inventory_images/test/test_33.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_33.jpg  \n",
      "  inflating: inventory_images/test/test_27.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_27.jpg  \n",
      "  inflating: inventory_images/test/test_26.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_26.jpg  \n",
      "  inflating: inventory_images/test/test_32.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_32.jpg  \n",
      "  inflating: inventory_images/test/test_4.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_4.jpg  \n",
      "  inflating: inventory_images/test/test_6.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_6.jpg  \n",
      "  inflating: inventory_images/test/test_18.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_18.jpg  \n",
      "  inflating: inventory_images/test/test_24.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_24.jpg  \n",
      "  inflating: inventory_images/test/test_30.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_30.jpg  \n",
      "  inflating: inventory_images/test/test_31.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_31.jpg  \n",
      "  inflating: inventory_images/test/test_25.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_25.jpg  \n",
      "  inflating: inventory_images/test/test_19.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_19.jpg  \n",
      "  inflating: inventory_images/test/test_7.jpg  \n",
      "  inflating: __MACOSX/inventory_images/test/._test_7.jpg  \n",
      "  inflating: inventory_images/annotations/test_annotations.csv  \n",
      "  inflating: __MACOSX/inventory_images/annotations/._test_annotations.csv  \n",
      "  inflating: inventory_images/annotations/val_annotations.csv  \n",
      "  inflating: __MACOSX/inventory_images/annotations/._val_annotations.csv  \n",
      "  inflating: inventory_images/annotations/train_labels.csv  \n",
      "  inflating: inventory_images/annotations/train_annotations.csv  \n",
      "  inflating: __MACOSX/inventory_images/annotations/._train_annotations.csv  \n",
      "  inflating: inventory_images/train/train_199.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_199.jpg  \n",
      "  inflating: inventory_images/train/train_166.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_166.jpg  \n",
      "  inflating: inventory_images/train/train_172.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_172.jpg  \n",
      "  inflating: inventory_images/train/train_22.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_22.jpg  \n",
      "  inflating: inventory_images/train/train_36.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_36.jpg  \n",
      "  inflating: inventory_images/train/train_37.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_37.jpg  \n",
      "  inflating: inventory_images/train/train_23.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_23.jpg  \n",
      "  inflating: inventory_images/train/train_173.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_173.jpg  \n",
      "  inflating: inventory_images/train/train_167.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_167.jpg  \n",
      "  inflating: inventory_images/train/train_198.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_198.jpg  \n",
      "  inflating: inventory_images/train/train_171.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_171.jpg  \n",
      "  inflating: inventory_images/train/train_165.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_165.jpg  \n",
      "  inflating: inventory_images/train/train_159.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_159.jpg  \n",
      "  inflating: inventory_images/train/train_35.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_35.jpg  \n",
      "  inflating: inventory_images/train/train_20.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_20.jpg  \n",
      "  inflating: inventory_images/train/train_34.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_34.jpg  \n",
      "  inflating: inventory_images/train/train_158.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_158.jpg  \n",
      "  inflating: inventory_images/train/train_164.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_164.jpg  \n",
      "  inflating: inventory_images/train/train_170.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_170.jpg  \n",
      "  inflating: inventory_images/train/train_148.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_148.jpg  \n",
      "  inflating: inventory_images/train/train_174.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_174.jpg  \n",
      "  inflating: inventory_images/train/train_160.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_160.jpg  \n",
      "  inflating: inventory_images/train/train_9.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_9.jpg  \n",
      "  inflating: inventory_images/train/train_30.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_30.jpg  \n",
      "  inflating: inventory_images/train/.DS_Store  \n",
      "  inflating: __MACOSX/inventory_images/train/._.DS_Store  \n",
      "  inflating: inventory_images/train/train_24.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_24.jpg  \n",
      "  inflating: inventory_images/train/train_18.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_18.jpg  \n",
      "  inflating: inventory_images/train/train_19.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_19.jpg  \n",
      "  inflating: inventory_images/train/train_25.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_25.jpg  \n",
      "  inflating: inventory_images/train/train_31.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_31.jpg  \n",
      "  inflating: inventory_images/train/train_8.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_8.jpg  \n",
      "  inflating: inventory_images/train/train_161.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_161.jpg  \n",
      "  inflating: inventory_images/train/train_175.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_175.jpg  \n",
      "  inflating: inventory_images/train/train_149.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_149.jpg  \n",
      "  inflating: inventory_images/train/train_188.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_188.jpg  \n",
      "  inflating: inventory_images/train/train_163.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_163.jpg  \n",
      "  inflating: inventory_images/train/train_177.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_177.jpg  \n",
      "  inflating: inventory_images/train/train_27.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_27.jpg  \n",
      "  inflating: inventory_images/train/train_33.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_33.jpg  \n",
      "  inflating: inventory_images/train/train_200.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_200.jpg  \n",
      "  inflating: inventory_images/train/train_32.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_32.jpg  \n",
      "  inflating: inventory_images/train/train_26.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_26.jpg  \n",
      "  inflating: inventory_images/train/train_176.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_176.jpg  \n",
      "  inflating: inventory_images/train/train_162.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_162.jpg  \n",
      "  inflating: inventory_images/train/train_189.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_189.jpg  \n",
      "  inflating: inventory_images/train/train_105.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_105.jpg  \n",
      "  inflating: inventory_images/train/train_111.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_111.jpg  \n",
      "  inflating: inventory_images/train/train_139.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_139.jpg  \n",
      "  inflating: inventory_images/train/train_69.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_69.jpg  \n",
      "  inflating: inventory_images/train/train_41.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_41.jpg  \n",
      "  inflating: inventory_images/train/train_55.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_55.jpg  \n",
      "  inflating: inventory_images/train/train_54.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_54.jpg  \n",
      "  inflating: inventory_images/train/train_68.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_68.jpg  \n",
      "  inflating: inventory_images/train/train_138.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_138.jpg  \n",
      "  inflating: inventory_images/train/train_110.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_110.jpg  \n",
      "  inflating: inventory_images/train/train_104.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_104.jpg  \n",
      "  inflating: inventory_images/train/train_112.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_112.jpg  \n",
      "  inflating: inventory_images/train/train_106.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_106.jpg  \n",
      "  inflating: inventory_images/train/train_56.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_56.jpg  \n",
      "  inflating: inventory_images/train/train_42.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_42.jpg  \n",
      "  inflating: inventory_images/train/train_43.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_43.jpg  \n",
      "  inflating: inventory_images/train/train_57.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_57.jpg  \n",
      "  inflating: inventory_images/train/train_107.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_107.jpg  \n",
      "  inflating: inventory_images/train/train_113.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_113.jpg  \n",
      "  inflating: inventory_images/train/train_117.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_117.jpg  \n",
      "  inflating: inventory_images/train/train_103.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_103.jpg  \n",
      "  inflating: inventory_images/train/train_53.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_53.jpg  \n",
      "  inflating: inventory_images/train/train_47.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_47.jpg  \n",
      "  inflating: inventory_images/train/train_46.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_46.jpg  \n",
      "  inflating: inventory_images/train/train_52.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_52.jpg  \n",
      "  inflating: inventory_images/train/train_102.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_102.jpg  \n",
      "  inflating: inventory_images/train/train_116.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_116.jpg  \n",
      "  inflating: inventory_images/train/train_128.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_128.jpg  \n",
      "  inflating: inventory_images/train/train_100.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_100.jpg  \n",
      "  inflating: inventory_images/train/train_114.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_114.jpg  \n",
      "  inflating: inventory_images/train/train_44.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_44.jpg  \n",
      "  inflating: inventory_images/train/train_50.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_50.jpg  \n",
      "  inflating: inventory_images/train/train_51.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_51.jpg  \n",
      "  inflating: inventory_images/train/train_45.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_45.jpg  \n",
      "  inflating: inventory_images/train/train_115.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_115.jpg  \n",
      "  inflating: inventory_images/train/train_101.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_101.jpg  \n",
      "  inflating: inventory_images/train/train_129.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_129.jpg  \n",
      "  inflating: inventory_images/train/train_124.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_124.jpg  \n",
      "  inflating: inventory_images/train/train_130.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_130.jpg  \n",
      "  inflating: inventory_images/train/train_118.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_118.jpg  \n",
      "  inflating: inventory_images/train/train_48.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_48.jpg  \n",
      "  inflating: inventory_images/train/train_60.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_60.jpg  \n",
      "  inflating: inventory_images/train/train_74.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_74.jpg  \n",
      "  inflating: inventory_images/train/train_61.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_61.jpg  \n",
      "  inflating: inventory_images/train/train_49.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_49.jpg  \n",
      "  inflating: inventory_images/train/train_119.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_119.jpg  \n",
      "  inflating: inventory_images/train/train_131.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_131.jpg  \n",
      "  inflating: inventory_images/train/train_125.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_125.jpg  \n",
      "  inflating: inventory_images/train/train_133.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_133.jpg  \n",
      "  inflating: inventory_images/train/train_127.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_127.jpg  \n",
      "  inflating: inventory_images/train/train_63.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_63.jpg  \n",
      "  inflating: inventory_images/train/train_62.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_62.jpg  \n",
      "  inflating: inventory_images/train/train_126.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_126.jpg  \n",
      "  inflating: inventory_images/train/train_132.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_132.jpg  \n",
      "  inflating: inventory_images/train/train_136.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_136.jpg  \n",
      "  inflating: inventory_images/train/train_122.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_122.jpg  \n",
      "  inflating: inventory_images/train/train_72.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_72.jpg  \n",
      "  inflating: inventory_images/train/train_66.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_66.jpg  \n",
      "  inflating: inventory_images/train/train_67.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_67.jpg  \n",
      "  inflating: inventory_images/train/train_73.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_73.jpg  \n",
      "  inflating: inventory_images/train/train_123.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_123.jpg  \n",
      "  inflating: inventory_images/train/train_137.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_137.jpg  \n",
      "  inflating: inventory_images/train/train_109.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_109.jpg  \n",
      "  inflating: inventory_images/train/train_121.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_121.jpg  \n",
      "  inflating: inventory_images/train/train_135.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_135.jpg  \n",
      "  inflating: inventory_images/train/train_65.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_65.jpg  \n",
      "  inflating: inventory_images/train/train_71.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_71.jpg  \n",
      "  inflating: inventory_images/train/train_59.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_59.jpg  \n",
      "  inflating: inventory_images/train/train_58.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_58.jpg  \n",
      "  inflating: inventory_images/train/train_70.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_70.jpg  \n",
      "  inflating: inventory_images/train/train_64.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_64.jpg  \n",
      "  inflating: inventory_images/train/train_134.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_134.jpg  \n",
      "  inflating: inventory_images/train/train_120.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_120.jpg  \n",
      "  inflating: inventory_images/train/train_108.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_108.jpg  \n",
      "  inflating: inventory_images/train/train_184.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_184.jpg  \n",
      "  inflating: inventory_images/train/train_190.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_190.jpg  \n",
      "  inflating: inventory_images/train/train_147.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_147.jpg  \n",
      "  inflating: inventory_images/train/train_153.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_153.jpg  \n",
      "  inflating: inventory_images/train/train_6.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_6.jpg  \n",
      "  inflating: inventory_images/train/train_17.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_17.jpg  \n",
      "  inflating: inventory_images/train/train_16.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_16.jpg  \n",
      "  inflating: inventory_images/train/train_7.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_7.jpg  \n",
      "  inflating: inventory_images/train/train_152.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_152.jpg  \n",
      "  inflating: inventory_images/train/train_146.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_146.jpg  \n",
      "  inflating: inventory_images/train/train_191.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_191.jpg  \n",
      "  inflating: inventory_images/train/train_185.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_185.jpg  \n",
      "  inflating: inventory_images/train/train_193.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_193.jpg  \n",
      "  inflating: inventory_images/train/train_187.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_187.jpg  \n",
      "  inflating: inventory_images/train/train_150.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_150.jpg  \n",
      "  inflating: inventory_images/train/train_144.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_144.jpg  \n",
      "  inflating: inventory_images/train/train_178.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_178.jpg  \n",
      "  inflating: inventory_images/train/train_5.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_5.jpg  \n",
      "  inflating: inventory_images/train/train_28.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_28.jpg  \n",
      "  inflating: inventory_images/train/train_14.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_14.jpg  \n",
      "  inflating: inventory_images/train/train_15.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_15.jpg  \n",
      "  inflating: inventory_images/train/train_29.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_29.jpg  \n",
      "  inflating: inventory_images/train/train_4.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_4.jpg  \n",
      "  inflating: inventory_images/train/train_179.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_179.jpg  \n",
      "  inflating: inventory_images/train/train_145.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_145.jpg  \n",
      "  inflating: inventory_images/train/train_151.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_151.jpg  \n",
      "  inflating: inventory_images/train/train_186.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_186.jpg  \n",
      "  inflating: inventory_images/train/train_192.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_192.jpg  \n",
      "  inflating: inventory_images/train/train_196.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_196.jpg  \n",
      "  inflating: inventory_images/train/train_182.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_182.jpg  \n",
      "  inflating: inventory_images/train/train_169.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_169.jpg  \n",
      "  inflating: inventory_images/train/train_155.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_155.jpg  \n",
      "  inflating: inventory_images/train/train_141.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_141.jpg  \n",
      "  inflating: inventory_images/train/train_0.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_0.jpg  \n",
      "  inflating: inventory_images/train/train_11.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_11.jpg  \n",
      "  inflating: inventory_images/train/train_39.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_39.jpg  \n",
      "  inflating: inventory_images/train/train_38.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_38.jpg  \n",
      "  inflating: inventory_images/train/train_10.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_10.jpg  \n",
      "  inflating: inventory_images/train/train_1.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_1.jpg  \n",
      "  inflating: inventory_images/train/train_140.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_140.jpg  \n",
      "  inflating: inventory_images/train/train_154.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_154.jpg  \n",
      "  inflating: inventory_images/train/train_168.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_168.jpg  \n",
      "  inflating: inventory_images/train/train_183.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_183.jpg  \n",
      "  inflating: inventory_images/train/train_197.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_197.jpg  \n",
      "  inflating: inventory_images/train/train_181.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_181.jpg  \n",
      "  inflating: inventory_images/train/train_195.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_195.jpg  \n",
      "  inflating: inventory_images/train/train_142.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_142.jpg  \n",
      "  inflating: inventory_images/train/train_156.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_156.jpg  \n",
      "  inflating: inventory_images/train/train_3.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_3.jpg  \n",
      "  inflating: inventory_images/train/train_12.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_12.jpg  \n",
      "  inflating: inventory_images/train/train_13.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_13.jpg  \n",
      "  inflating: inventory_images/train/train_2.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_2.jpg  \n",
      "  inflating: inventory_images/train/train_157.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_157.jpg  \n",
      "  inflating: inventory_images/train/train_143.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_143.jpg  \n",
      "  inflating: inventory_images/train/train_194.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_194.jpg  \n",
      "  inflating: inventory_images/train/train_180.jpg  \n",
      "  inflating: __MACOSX/inventory_images/train/._train_180.jpg  \n",
      "  inflating: inventory_images/val/val_13.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_13.jpg  \n",
      "  inflating: inventory_images/val/val_9.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_9.jpg  \n",
      "  inflating: inventory_images/val/val_8.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_8.jpg  \n",
      "  inflating: inventory_images/val/val_12.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_12.jpg  \n",
      "  inflating: inventory_images/val/val_10.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_10.jpg  \n",
      "  inflating: inventory_images/val/val_38.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_38.jpg  \n",
      "  inflating: inventory_images/val/val_39.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_39.jpg  \n",
      "  inflating: inventory_images/val/val_11.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_11.jpg  \n",
      "  inflating: inventory_images/val/val_29.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_29.jpg  \n",
      "  inflating: inventory_images/val/val_15.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_15.jpg  \n",
      "  inflating: inventory_images/val/val_14.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_14.jpg  \n",
      "  inflating: inventory_images/val/val_28.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_28.jpg  \n",
      "  inflating: inventory_images/val/val_16.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_16.jpg  \n",
      "  inflating: inventory_images/val/val_17.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_17.jpg  \n",
      "  inflating: inventory_images/val/val_70.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_70.jpg  \n",
      "  inflating: inventory_images/val/val_64.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_64.jpg  \n",
      "  inflating: inventory_images/val/val_58.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_58.jpg  \n",
      "  inflating: inventory_images/val/val_59.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_59.jpg  \n",
      "  inflating: inventory_images/val/val_65.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_65.jpg  \n",
      "  inflating: inventory_images/val/val_71.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_71.jpg  \n",
      "  inflating: inventory_images/val/val_67.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_67.jpg  \n",
      "  inflating: inventory_images/val/val_73.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_73.jpg  \n",
      "  inflating: inventory_images/val/val_72.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_72.jpg  \n",
      "  inflating: inventory_images/val/val_66.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_66.jpg  \n",
      "  inflating: inventory_images/val/val_62.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_62.jpg  \n",
      "  inflating: inventory_images/val/val_63.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_63.jpg  \n",
      "  inflating: inventory_images/val/val_49.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_49.jpg  \n",
      "  inflating: inventory_images/val/val_75.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_75.jpg  \n",
      "  inflating: inventory_images/val/val_61.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_61.jpg  \n",
      "  inflating: inventory_images/val/val_60.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_60.jpg  \n",
      "  inflating: inventory_images/val/val_74.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_74.jpg  \n",
      "  inflating: inventory_images/val/val_48.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_48.jpg  \n",
      "  inflating: inventory_images/val/val_51.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_51.jpg  \n",
      "  inflating: inventory_images/val/val_45.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_45.jpg  \n",
      "  inflating: inventory_images/val/val_44.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_44.jpg  \n",
      "  inflating: inventory_images/val/val_50.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_50.jpg  \n",
      "  inflating: inventory_images/val/val_46.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_46.jpg  \n",
      "  inflating: inventory_images/val/val_52.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_52.jpg  \n",
      "  inflating: inventory_images/val/val_53.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_53.jpg  \n",
      "  inflating: inventory_images/val/val_47.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_47.jpg  \n",
      "  inflating: inventory_images/val/val_43.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_43.jpg  \n",
      "  inflating: inventory_images/val/val_57.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_57.jpg  \n",
      "  inflating: inventory_images/val/val_56.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_56.jpg  \n",
      "  inflating: inventory_images/val/val_42.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_42.jpg  \n",
      "  inflating: inventory_images/val/val_68.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_68.jpg  \n",
      "  inflating: inventory_images/val/val_54.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_54.jpg  \n",
      "  inflating: inventory_images/val/val_40.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_40.jpg  \n",
      "  inflating: inventory_images/val/val_41.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_41.jpg  \n",
      "  inflating: inventory_images/val/val_55.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_55.jpg  \n",
      "  inflating: inventory_images/val/val_69.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_69.jpg  \n",
      "  inflating: inventory_images/val/val_32.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_32.jpg  \n",
      "  inflating: inventory_images/val/val_26.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_26.jpg  \n",
      "  inflating: inventory_images/val/val_1.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_1.jpg  \n",
      "  inflating: inventory_images/val/val_27.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_27.jpg  \n",
      "  inflating: inventory_images/val/val_33.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_33.jpg  \n",
      "  inflating: inventory_images/val/val_25.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_25.jpg  \n",
      "  inflating: inventory_images/val/val_31.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_31.jpg  \n",
      "  inflating: inventory_images/val/val_19.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_19.jpg  \n",
      "  inflating: inventory_images/val/val_3.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_3.jpg  \n",
      "  inflating: inventory_images/val/val_2.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_2.jpg  \n",
      "  inflating: inventory_images/val/val_18.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_18.jpg  \n",
      "  inflating: inventory_images/val/val_30.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_30.jpg  \n",
      "  inflating: inventory_images/val/val_24.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_24.jpg  \n",
      "  inflating: inventory_images/val/val_20.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_20.jpg  \n",
      "  inflating: inventory_images/val/val_34.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_34.jpg  \n",
      "  inflating: inventory_images/val/val_6.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_6.jpg  \n",
      "  inflating: inventory_images/val/val_7.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_7.jpg  \n",
      "  inflating: inventory_images/val/val_35.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_35.jpg  \n",
      "  inflating: inventory_images/val/val_21.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_21.jpg  \n",
      "  inflating: inventory_images/val/val_37.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_37.jpg  \n",
      "  inflating: inventory_images/val/val_23.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_23.jpg  \n",
      "  inflating: inventory_images/val/val_5.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_5.jpg  \n",
      "  inflating: inventory_images/val/val_4.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_4.jpg  \n",
      "  inflating: inventory_images/val/val_22.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_22.jpg  \n",
      "  inflating: inventory_images/val/val_36.jpg  \n",
      "  inflating: __MACOSX/inventory_images/val/._val_36.jpg  \n"
     ]
    }
   ],
   "source": [
    "# OPTIONAL IF RUNNING ON COLAB\n",
    "!unzip \"/content/drive/MyDrive/inventory_images.zip\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0r1L9xuBZOIj",
    "outputId": "e2b6f26c-b9bf-4aa9-f37b-65d770d4eee4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'Tensorflow/scripts'...\n",
      "remote: Enumerating objects: 3, done.\u001b[K\n",
      "remote: Counting objects: 100% (3/3), done.\u001b[K\n",
      "remote: Compressing objects: 100% (2/2), done.\u001b[K\n",
      "remote: Total 3 (delta 0), reused 3 (delta 0), pack-reused 0\u001b[K\n",
      "Unpacking objects: 100% (3/3), done.\n"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(files['TF_RECORD_SCRIPT']):\n",
    "    !git clone https://github.com/dilshad-geol/TF {paths['SCRIPTS_PATH']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rl7retgQ4oh2",
    "outputId": "a61c71cd-43c2-45c6-f769-a226d1b25c1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 13:07:07.898580: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 13:07:08.636133: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 13:07:08.636262: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 13:07:08.636305: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Successfully created the TFRecords: /content/Tensorflow/workspace/annotations/train.record\n"
     ]
    }
   ],
   "source": [
    "!python /content/Tensorflow/scripts/generate_tfrecord.py --csv_input=/content/inventory_images/annotations/train_annotations.csv  --output_path=/content/Tensorflow/workspace/annotations/train.record --image_dir=/content/inventory_images/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yv9Zesa0Leyk",
    "outputId": "55c209a6-ee99-4e65-ee31-1598fbbe23a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 13:07:15.947578: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 13:07:16.658679: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 13:07:16.658797: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 13:07:16.658819: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "Successfully created the TFRecords: /content/Tensorflow/workspace/annotations/test.record\n"
     ]
    }
   ],
   "source": [
    "!python /content/Tensorflow/scripts/generate_tfrecord.py --csv_input=/content/inventory_images/annotations/test_annotations.csv  --output_path=/content/Tensorflow/workspace/annotations/test.record --image_dir=/content/inventory_images/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wwFjeLN45px5",
    "outputId": "dbc19768-7714-4259-bd27-6a429060c601"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (2022.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install pytz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qT4QU7pLpfDE"
   },
   "source": [
    "# Copy Model Config to Training Folder\n",
    "\n",
    "\n",
    "*   Now that we have downloaded and extracted our pre-trained model, let’s create a directory for our training job. Under the training_demo/models create a new directory named my_ssd_resnet50_v1_fpn and copy the training_demo/pre-trained-models/ssd_resnet50_v1_fpn_640x640_coco17_tpu-8/pipeline.config file inside the newly created directory. Our training_demo/models directory should now look like this:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cOjuTFbwpfDF"
   },
   "outputs": [],
   "source": [
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH'])}\n",
    "\n",
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME2, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH2'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME2, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH2'])}\n",
    "\n",
    "if os.name =='posix':\n",
    "    !cp {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME3, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH3'])}\n",
    "if os.name == 'nt':\n",
    "    !copy {os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME3, 'pipeline.config')} {os.path.join(paths['CHECKPOINT_PATH3'])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ga8gpNslpfDF"
   },
   "source": [
    "# Update Config For Transfer Learning\n",
    "Here are  updateing our config according to our requirement. (Update batch number, place the training and testing tfrecord address, epochs for Model training.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z9hRrO_ppfDF"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "c2A0mn4ipfDF"
   },
   "outputs": [],
   "source": [
    "config = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "config2 = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG2'])\n",
    "config3 = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uQA13-afpfDF",
    "outputId": "13a61c33-c269-4aef-d1da-10e1aa23dd76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': ssd {\n",
      "  num_classes: 90\n",
      "  image_resizer {\n",
      "    fixed_shape_resizer {\n",
      "      height: 640\n",
      "      width: 640\n",
      "    }\n",
      "  }\n",
      "  feature_extractor {\n",
      "    type: \"ssd_mobilenet_v1_fpn_keras\"\n",
      "    depth_multiplier: 1.0\n",
      "    min_depth: 16\n",
      "    conv_hyperparams {\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 3.9999998989515007e-05\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        random_normal_initializer {\n",
      "          mean: 0.0\n",
      "          stddev: 0.009999999776482582\n",
      "        }\n",
      "      }\n",
      "      activation: RELU_6\n",
      "      batch_norm {\n",
      "        decay: 0.996999979019165\n",
      "        scale: true\n",
      "        epsilon: 0.0010000000474974513\n",
      "      }\n",
      "    }\n",
      "    override_base_feature_extractor_hyperparams: true\n",
      "    fpn {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "    }\n",
      "  }\n",
      "  box_coder {\n",
      "    faster_rcnn_box_coder {\n",
      "      y_scale: 10.0\n",
      "      x_scale: 10.0\n",
      "      height_scale: 5.0\n",
      "      width_scale: 5.0\n",
      "    }\n",
      "  }\n",
      "  matcher {\n",
      "    argmax_matcher {\n",
      "      matched_threshold: 0.5\n",
      "      unmatched_threshold: 0.5\n",
      "      ignore_thresholds: false\n",
      "      negatives_lower_than_unmatched: true\n",
      "      force_match_for_each_row: true\n",
      "      use_matmul_gather: true\n",
      "    }\n",
      "  }\n",
      "  similarity_calculator {\n",
      "    iou_similarity {\n",
      "    }\n",
      "  }\n",
      "  box_predictor {\n",
      "    weight_shared_convolutional_box_predictor {\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 3.9999998989515007e-05\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.009999999776482582\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.996999979019165\n",
      "          scale: true\n",
      "          epsilon: 0.0010000000474974513\n",
      "        }\n",
      "      }\n",
      "      depth: 256\n",
      "      num_layers_before_predictor: 4\n",
      "      kernel_size: 3\n",
      "      class_prediction_bias_init: -4.599999904632568\n",
      "    }\n",
      "  }\n",
      "  anchor_generator {\n",
      "    multiscale_anchor_generator {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "      anchor_scale: 4.0\n",
      "      aspect_ratios: 1.0\n",
      "      aspect_ratios: 2.0\n",
      "      aspect_ratios: 0.5\n",
      "      scales_per_octave: 2\n",
      "    }\n",
      "  }\n",
      "  post_processing {\n",
      "    batch_non_max_suppression {\n",
      "      score_threshold: 9.99999993922529e-09\n",
      "      iou_threshold: 0.6000000238418579\n",
      "      max_detections_per_class: 100\n",
      "      max_total_detections: 100\n",
      "      use_static_shapes: false\n",
      "    }\n",
      "    score_converter: SIGMOID\n",
      "  }\n",
      "  normalize_loss_by_num_matches: true\n",
      "  loss {\n",
      "    localization_loss {\n",
      "      weighted_smooth_l1 {\n",
      "      }\n",
      "    }\n",
      "    classification_loss {\n",
      "      weighted_sigmoid_focal {\n",
      "        gamma: 2.0\n",
      "        alpha: 0.25\n",
      "      }\n",
      "    }\n",
      "    classification_weight: 1.0\n",
      "    localization_weight: 1.0\n",
      "  }\n",
      "  encode_background_as_zeros: true\n",
      "  normalize_loc_loss_by_codesize: true\n",
      "  inplace_batchnorm_update: true\n",
      "  freeze_batchnorm: false\n",
      "}\n",
      ", 'train_config': batch_size: 64\n",
      "data_augmentation_options {\n",
      "  random_horizontal_flip {\n",
      "  }\n",
      "}\n",
      "data_augmentation_options {\n",
      "  random_crop_image {\n",
      "    min_object_covered: 0.0\n",
      "    min_aspect_ratio: 0.75\n",
      "    max_aspect_ratio: 3.0\n",
      "    min_area: 0.75\n",
      "    max_area: 1.0\n",
      "    overlap_thresh: 0.0\n",
      "  }\n",
      "}\n",
      "sync_replicas: true\n",
      "optimizer {\n",
      "  momentum_optimizer {\n",
      "    learning_rate {\n",
      "      cosine_decay_learning_rate {\n",
      "        learning_rate_base: 0.03999999910593033\n",
      "        total_steps: 25000\n",
      "        warmup_learning_rate: 0.013333000242710114\n",
      "        warmup_steps: 2000\n",
      "      }\n",
      "    }\n",
      "    momentum_optimizer_value: 0.8999999761581421\n",
      "  }\n",
      "  use_moving_average: false\n",
      "}\n",
      "fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
      "num_steps: 25000\n",
      "startup_delay_steps: 0.0\n",
      "replicas_to_aggregate: 8\n",
      "max_number_of_boxes: 100\n",
      "unpad_groundtruth_tensors: false\n",
      "fine_tune_checkpoint_type: \"classification\"\n",
      "fine_tune_checkpoint_version: V2\n",
      ", 'train_input_config': tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      ", 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
      "use_moving_averages: false\n",
      "batch_size: 1\n",
      ", 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "}\n",
      "{'model': ssd {\n",
      "  num_classes: 90\n",
      "  image_resizer {\n",
      "    fixed_shape_resizer {\n",
      "      height: 640\n",
      "      width: 640\n",
      "    }\n",
      "  }\n",
      "  feature_extractor {\n",
      "    type: \"ssd_resnet101_v1_fpn_keras\"\n",
      "    depth_multiplier: 1.0\n",
      "    min_depth: 16\n",
      "    conv_hyperparams {\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 0.00039999998989515007\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        truncated_normal_initializer {\n",
      "          mean: 0.0\n",
      "          stddev: 0.029999999329447746\n",
      "        }\n",
      "      }\n",
      "      activation: RELU_6\n",
      "      batch_norm {\n",
      "        decay: 0.996999979019165\n",
      "        scale: true\n",
      "        epsilon: 0.0010000000474974513\n",
      "      }\n",
      "    }\n",
      "    override_base_feature_extractor_hyperparams: true\n",
      "    fpn {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "    }\n",
      "  }\n",
      "  box_coder {\n",
      "    faster_rcnn_box_coder {\n",
      "      y_scale: 10.0\n",
      "      x_scale: 10.0\n",
      "      height_scale: 5.0\n",
      "      width_scale: 5.0\n",
      "    }\n",
      "  }\n",
      "  matcher {\n",
      "    argmax_matcher {\n",
      "      matched_threshold: 0.5\n",
      "      unmatched_threshold: 0.5\n",
      "      ignore_thresholds: false\n",
      "      negatives_lower_than_unmatched: true\n",
      "      force_match_for_each_row: true\n",
      "      use_matmul_gather: true\n",
      "    }\n",
      "  }\n",
      "  similarity_calculator {\n",
      "    iou_similarity {\n",
      "    }\n",
      "  }\n",
      "  box_predictor {\n",
      "    weight_shared_convolutional_box_predictor {\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.00039999998989515007\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.009999999776482582\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.996999979019165\n",
      "          scale: true\n",
      "          epsilon: 0.0010000000474974513\n",
      "        }\n",
      "      }\n",
      "      depth: 256\n",
      "      num_layers_before_predictor: 4\n",
      "      kernel_size: 3\n",
      "      class_prediction_bias_init: -4.599999904632568\n",
      "    }\n",
      "  }\n",
      "  anchor_generator {\n",
      "    multiscale_anchor_generator {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "      anchor_scale: 4.0\n",
      "      aspect_ratios: 1.0\n",
      "      aspect_ratios: 2.0\n",
      "      aspect_ratios: 0.5\n",
      "      scales_per_octave: 2\n",
      "    }\n",
      "  }\n",
      "  post_processing {\n",
      "    batch_non_max_suppression {\n",
      "      score_threshold: 9.99999993922529e-09\n",
      "      iou_threshold: 0.6000000238418579\n",
      "      max_detections_per_class: 100\n",
      "      max_total_detections: 100\n",
      "      use_static_shapes: false\n",
      "    }\n",
      "    score_converter: SIGMOID\n",
      "  }\n",
      "  normalize_loss_by_num_matches: true\n",
      "  loss {\n",
      "    localization_loss {\n",
      "      weighted_smooth_l1 {\n",
      "      }\n",
      "    }\n",
      "    classification_loss {\n",
      "      weighted_sigmoid_focal {\n",
      "        gamma: 2.0\n",
      "        alpha: 0.25\n",
      "      }\n",
      "    }\n",
      "    classification_weight: 1.0\n",
      "    localization_weight: 1.0\n",
      "  }\n",
      "  encode_background_as_zeros: true\n",
      "  normalize_loc_loss_by_codesize: true\n",
      "  inplace_batchnorm_update: true\n",
      "  freeze_batchnorm: false\n",
      "}\n",
      ", 'train_config': batch_size: 64\n",
      "data_augmentation_options {\n",
      "  random_horizontal_flip {\n",
      "  }\n",
      "}\n",
      "data_augmentation_options {\n",
      "  random_crop_image {\n",
      "    min_object_covered: 0.0\n",
      "    min_aspect_ratio: 0.75\n",
      "    max_aspect_ratio: 3.0\n",
      "    min_area: 0.75\n",
      "    max_area: 1.0\n",
      "    overlap_thresh: 0.0\n",
      "  }\n",
      "}\n",
      "sync_replicas: true\n",
      "optimizer {\n",
      "  momentum_optimizer {\n",
      "    learning_rate {\n",
      "      cosine_decay_learning_rate {\n",
      "        learning_rate_base: 0.03999999910593033\n",
      "        total_steps: 25000\n",
      "        warmup_learning_rate: 0.013333000242710114\n",
      "        warmup_steps: 2000\n",
      "      }\n",
      "    }\n",
      "    momentum_optimizer_value: 0.8999999761581421\n",
      "  }\n",
      "  use_moving_average: false\n",
      "}\n",
      "fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
      "num_steps: 25000\n",
      "startup_delay_steps: 0.0\n",
      "replicas_to_aggregate: 8\n",
      "max_number_of_boxes: 100\n",
      "unpad_groundtruth_tensors: false\n",
      "fine_tune_checkpoint_type: \"classification\"\n",
      "use_bfloat16: true\n",
      "fine_tune_checkpoint_version: V2\n",
      ", 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      ", 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
      "use_moving_averages: false\n",
      ", 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "}\n",
      "{'model': ssd {\n",
      "  num_classes: 90\n",
      "  image_resizer {\n",
      "    fixed_shape_resizer {\n",
      "      height: 640\n",
      "      width: 640\n",
      "    }\n",
      "  }\n",
      "  feature_extractor {\n",
      "    type: \"ssd_mobilenet_v2_fpn_keras\"\n",
      "    depth_multiplier: 1.0\n",
      "    min_depth: 16\n",
      "    conv_hyperparams {\n",
      "      regularizer {\n",
      "        l2_regularizer {\n",
      "          weight: 3.9999998989515007e-05\n",
      "        }\n",
      "      }\n",
      "      initializer {\n",
      "        random_normal_initializer {\n",
      "          mean: 0.0\n",
      "          stddev: 0.009999999776482582\n",
      "        }\n",
      "      }\n",
      "      activation: RELU_6\n",
      "      batch_norm {\n",
      "        decay: 0.996999979019165\n",
      "        scale: true\n",
      "        epsilon: 0.0010000000474974513\n",
      "      }\n",
      "    }\n",
      "    use_depthwise: true\n",
      "    override_base_feature_extractor_hyperparams: true\n",
      "    fpn {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "      additional_layer_depth: 128\n",
      "    }\n",
      "  }\n",
      "  box_coder {\n",
      "    faster_rcnn_box_coder {\n",
      "      y_scale: 10.0\n",
      "      x_scale: 10.0\n",
      "      height_scale: 5.0\n",
      "      width_scale: 5.0\n",
      "    }\n",
      "  }\n",
      "  matcher {\n",
      "    argmax_matcher {\n",
      "      matched_threshold: 0.5\n",
      "      unmatched_threshold: 0.5\n",
      "      ignore_thresholds: false\n",
      "      negatives_lower_than_unmatched: true\n",
      "      force_match_for_each_row: true\n",
      "      use_matmul_gather: true\n",
      "    }\n",
      "  }\n",
      "  similarity_calculator {\n",
      "    iou_similarity {\n",
      "    }\n",
      "  }\n",
      "  box_predictor {\n",
      "    weight_shared_convolutional_box_predictor {\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 3.9999998989515007e-05\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.009999999776482582\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.996999979019165\n",
      "          scale: true\n",
      "          epsilon: 0.0010000000474974513\n",
      "        }\n",
      "      }\n",
      "      depth: 128\n",
      "      num_layers_before_predictor: 4\n",
      "      kernel_size: 3\n",
      "      class_prediction_bias_init: -4.599999904632568\n",
      "      share_prediction_tower: true\n",
      "      use_depthwise: true\n",
      "    }\n",
      "  }\n",
      "  anchor_generator {\n",
      "    multiscale_anchor_generator {\n",
      "      min_level: 3\n",
      "      max_level: 7\n",
      "      anchor_scale: 4.0\n",
      "      aspect_ratios: 1.0\n",
      "      aspect_ratios: 2.0\n",
      "      aspect_ratios: 0.5\n",
      "      scales_per_octave: 2\n",
      "    }\n",
      "  }\n",
      "  post_processing {\n",
      "    batch_non_max_suppression {\n",
      "      score_threshold: 9.99999993922529e-09\n",
      "      iou_threshold: 0.6000000238418579\n",
      "      max_detections_per_class: 100\n",
      "      max_total_detections: 100\n",
      "      use_static_shapes: false\n",
      "    }\n",
      "    score_converter: SIGMOID\n",
      "  }\n",
      "  normalize_loss_by_num_matches: true\n",
      "  loss {\n",
      "    localization_loss {\n",
      "      weighted_smooth_l1 {\n",
      "      }\n",
      "    }\n",
      "    classification_loss {\n",
      "      weighted_sigmoid_focal {\n",
      "        gamma: 2.0\n",
      "        alpha: 0.25\n",
      "      }\n",
      "    }\n",
      "    classification_weight: 1.0\n",
      "    localization_weight: 1.0\n",
      "  }\n",
      "  encode_background_as_zeros: true\n",
      "  normalize_loc_loss_by_codesize: true\n",
      "  inplace_batchnorm_update: true\n",
      "  freeze_batchnorm: false\n",
      "}\n",
      ", 'train_config': batch_size: 128\n",
      "data_augmentation_options {\n",
      "  random_horizontal_flip {\n",
      "  }\n",
      "}\n",
      "data_augmentation_options {\n",
      "  random_crop_image {\n",
      "    min_object_covered: 0.0\n",
      "    min_aspect_ratio: 0.75\n",
      "    max_aspect_ratio: 3.0\n",
      "    min_area: 0.75\n",
      "    max_area: 1.0\n",
      "    overlap_thresh: 0.0\n",
      "  }\n",
      "}\n",
      "sync_replicas: true\n",
      "optimizer {\n",
      "  momentum_optimizer {\n",
      "    learning_rate {\n",
      "      cosine_decay_learning_rate {\n",
      "        learning_rate_base: 0.07999999821186066\n",
      "        total_steps: 50000\n",
      "        warmup_learning_rate: 0.026666000485420227\n",
      "        warmup_steps: 1000\n",
      "      }\n",
      "    }\n",
      "    momentum_optimizer_value: 0.8999999761581421\n",
      "  }\n",
      "  use_moving_average: false\n",
      "}\n",
      "fine_tune_checkpoint: \"PATH_TO_BE_CONFIGURED\"\n",
      "num_steps: 50000\n",
      "startup_delay_steps: 0.0\n",
      "replicas_to_aggregate: 8\n",
      "max_number_of_boxes: 100\n",
      "unpad_groundtruth_tensors: false\n",
      "fine_tune_checkpoint_type: \"classification\"\n",
      "fine_tune_checkpoint_version: V2\n",
      ", 'train_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      ", 'eval_config': metrics_set: \"coco_detection_metrics\"\n",
      "use_moving_averages: false\n",
      ", 'eval_input_configs': [label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "], 'eval_input_config': label_map_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "shuffle: false\n",
      "num_epochs: 1\n",
      "tf_record_input_reader {\n",
      "  input_path: \"PATH_TO_BE_CONFIGURED\"\n",
      "}\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(config)\n",
    "print(config2)\n",
    "print(config3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9vK5lotDpfDF"
   },
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config) \n",
    "\n",
    "pipeline_config2 = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG2'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config2)\n",
    "\n",
    "pipeline_config3 = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG3'], \"r\") as f:                                                                                                                                                                                                                     \n",
    "    proto_str = f.read()                                                                                                                                                                                                                                          \n",
    "    text_format.Merge(proto_str, pipeline_config3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rP43Ph0JpfDG"
   },
   "outputs": [],
   "source": [
    "pipeline_config.model.ssd.num_classes = 1\n",
    "pipeline_config.train_config.batch_size = 4\n",
    "pipeline_config.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QFYKVivlcIht"
   },
   "outputs": [],
   "source": [
    "pipeline_config2.model.ssd.num_classes = 1\n",
    "pipeline_config2.train_config.batch_size = 4\n",
    "pipeline_config2.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME2, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config2.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config2.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config2.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config2.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config2.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pqHjYnI9cRn1"
   },
   "outputs": [],
   "source": [
    "pipeline_config3.model.ssd.num_classes = 1\n",
    "pipeline_config3.train_config.batch_size = 4\n",
    "pipeline_config3.train_config.fine_tune_checkpoint = os.path.join(paths['PRETRAINED_MODEL_PATH'], PRETRAINED_MODEL_NAME3, 'checkpoint', 'ckpt-0')\n",
    "pipeline_config3.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config3.train_input_reader.label_map_path= files['LABELMAP']\n",
    "pipeline_config3.train_input_reader.tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'train.record')]\n",
    "pipeline_config3.eval_input_reader[0].label_map_path = files['LABELMAP']\n",
    "pipeline_config3.eval_input_reader[0].tf_record_input_reader.input_path[:] = [os.path.join(paths['ANNOTATION_PATH'], 'test.record')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oJvfgwWqpfDG"
   },
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text)  \n",
    "\n",
    "config_text2 = text_format.MessageToString(pipeline_config2)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG2'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text2)  \n",
    "\n",
    "config_text3 = text_format.MessageToString(pipeline_config3)                                                                                                                                                                                                        \n",
    "with tf.io.gfile.GFile(files['PIPELINE_CONFIG3'], \"wb\") as f:                                                                                                                                                                                                                     \n",
    "    f.write(config_text3)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0DA052bTB4wh",
    "outputId": "fb50c8ab-7c76-4352-a5f5-e6017cd8c52e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model {\n",
      "  ssd {\n",
      "    num_classes: 1\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 640\n",
      "        width: 640\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: \"ssd_mobilenet_v1_fpn_keras\"\n",
      "      depth_multiplier: 1.0\n",
      "      min_depth: 16\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 4e-05\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.01\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.997\n",
      "          scale: true\n",
      "          epsilon: 0.001\n",
      "        }\n",
      "      }\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "      fpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "      }\n",
      "    }\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        conv_hyperparams {\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 4e-05\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              mean: 0.0\n",
      "              stddev: 0.01\n",
      "            }\n",
      "          }\n",
      "          activation: RELU_6\n",
      "          batch_norm {\n",
      "            decay: 0.997\n",
      "            scale: true\n",
      "            epsilon: 0.001\n",
      "          }\n",
      "        }\n",
      "        depth: 256\n",
      "        num_layers_before_predictor: 4\n",
      "        kernel_size: 3\n",
      "        class_prediction_bias_init: -4.6\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        scales_per_octave: 2\n",
      "      }\n",
      "    }\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-08\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "        use_static_shapes: false\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    loss {\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          gamma: 2.0\n",
      "          alpha: 0.25\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "  }\n",
      "}\n",
      "train_config {\n",
      "  batch_size: 4\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_object_covered: 0.0\n",
      "      min_aspect_ratio: 0.75\n",
      "      max_aspect_ratio: 3.0\n",
      "      min_area: 0.75\n",
      "      max_area: 1.0\n",
      "      overlap_thresh: 0.0\n",
      "    }\n",
      "  }\n",
      "  sync_replicas: true\n",
      "  optimizer {\n",
      "    momentum_optimizer {\n",
      "      learning_rate {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 0.04\n",
      "          total_steps: 25000\n",
      "          warmup_learning_rate: 0.013333\n",
      "          warmup_steps: 2000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
      "  num_steps: 25000\n",
      "  startup_delay_steps: 0.0\n",
      "  replicas_to_aggregate: 8\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  fine_tune_checkpoint_version: V2\n",
      "}\n",
      "train_input_reader {\n",
      "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
      "  }\n",
      "}\n",
      "eval_config {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "  batch_size: 1\n",
      "}\n",
      "eval_input_reader {\n",
      "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
      "  }\n",
      "}\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    num_classes: 1\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 640\n",
      "        width: 640\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: \"ssd_resnet101_v1_fpn_keras\"\n",
      "      depth_multiplier: 1.0\n",
      "      min_depth: 16\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 0.0004\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          truncated_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.03\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.997\n",
      "          scale: true\n",
      "          epsilon: 0.001\n",
      "        }\n",
      "      }\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "      fpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "      }\n",
      "    }\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        conv_hyperparams {\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 0.0004\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              mean: 0.0\n",
      "              stddev: 0.01\n",
      "            }\n",
      "          }\n",
      "          activation: RELU_6\n",
      "          batch_norm {\n",
      "            decay: 0.997\n",
      "            scale: true\n",
      "            epsilon: 0.001\n",
      "          }\n",
      "        }\n",
      "        depth: 256\n",
      "        num_layers_before_predictor: 4\n",
      "        kernel_size: 3\n",
      "        class_prediction_bias_init: -4.6\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        scales_per_octave: 2\n",
      "      }\n",
      "    }\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-08\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "        use_static_shapes: false\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    loss {\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          gamma: 2.0\n",
      "          alpha: 0.25\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "  }\n",
      "}\n",
      "train_config {\n",
      "  batch_size: 4\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_object_covered: 0.0\n",
      "      min_aspect_ratio: 0.75\n",
      "      max_aspect_ratio: 3.0\n",
      "      min_area: 0.75\n",
      "      max_area: 1.0\n",
      "      overlap_thresh: 0.0\n",
      "    }\n",
      "  }\n",
      "  sync_replicas: true\n",
      "  optimizer {\n",
      "    momentum_optimizer {\n",
      "      learning_rate {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 0.04\n",
      "          total_steps: 25000\n",
      "          warmup_learning_rate: 0.013333\n",
      "          warmup_steps: 2000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_resnet101_v1_fpn_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
      "  num_steps: 25000\n",
      "  startup_delay_steps: 0.0\n",
      "  replicas_to_aggregate: 8\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  use_bfloat16: true\n",
      "  fine_tune_checkpoint_version: V2\n",
      "}\n",
      "train_input_reader {\n",
      "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
      "  }\n",
      "}\n",
      "eval_config {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "}\n",
      "eval_input_reader {\n",
      "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
      "  }\n",
      "}\n",
      "\n",
      "model {\n",
      "  ssd {\n",
      "    num_classes: 1\n",
      "    image_resizer {\n",
      "      fixed_shape_resizer {\n",
      "        height: 640\n",
      "        width: 640\n",
      "      }\n",
      "    }\n",
      "    feature_extractor {\n",
      "      type: \"ssd_mobilenet_v2_fpn_keras\"\n",
      "      depth_multiplier: 1.0\n",
      "      min_depth: 16\n",
      "      conv_hyperparams {\n",
      "        regularizer {\n",
      "          l2_regularizer {\n",
      "            weight: 4e-05\n",
      "          }\n",
      "        }\n",
      "        initializer {\n",
      "          random_normal_initializer {\n",
      "            mean: 0.0\n",
      "            stddev: 0.01\n",
      "          }\n",
      "        }\n",
      "        activation: RELU_6\n",
      "        batch_norm {\n",
      "          decay: 0.997\n",
      "          scale: true\n",
      "          epsilon: 0.001\n",
      "        }\n",
      "      }\n",
      "      use_depthwise: true\n",
      "      override_base_feature_extractor_hyperparams: true\n",
      "      fpn {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        additional_layer_depth: 128\n",
      "      }\n",
      "    }\n",
      "    box_coder {\n",
      "      faster_rcnn_box_coder {\n",
      "        y_scale: 10.0\n",
      "        x_scale: 10.0\n",
      "        height_scale: 5.0\n",
      "        width_scale: 5.0\n",
      "      }\n",
      "    }\n",
      "    matcher {\n",
      "      argmax_matcher {\n",
      "        matched_threshold: 0.5\n",
      "        unmatched_threshold: 0.5\n",
      "        ignore_thresholds: false\n",
      "        negatives_lower_than_unmatched: true\n",
      "        force_match_for_each_row: true\n",
      "        use_matmul_gather: true\n",
      "      }\n",
      "    }\n",
      "    similarity_calculator {\n",
      "      iou_similarity {\n",
      "      }\n",
      "    }\n",
      "    box_predictor {\n",
      "      weight_shared_convolutional_box_predictor {\n",
      "        conv_hyperparams {\n",
      "          regularizer {\n",
      "            l2_regularizer {\n",
      "              weight: 4e-05\n",
      "            }\n",
      "          }\n",
      "          initializer {\n",
      "            random_normal_initializer {\n",
      "              mean: 0.0\n",
      "              stddev: 0.01\n",
      "            }\n",
      "          }\n",
      "          activation: RELU_6\n",
      "          batch_norm {\n",
      "            decay: 0.997\n",
      "            scale: true\n",
      "            epsilon: 0.001\n",
      "          }\n",
      "        }\n",
      "        depth: 128\n",
      "        num_layers_before_predictor: 4\n",
      "        kernel_size: 3\n",
      "        class_prediction_bias_init: -4.6\n",
      "        share_prediction_tower: true\n",
      "        use_depthwise: true\n",
      "      }\n",
      "    }\n",
      "    anchor_generator {\n",
      "      multiscale_anchor_generator {\n",
      "        min_level: 3\n",
      "        max_level: 7\n",
      "        anchor_scale: 4.0\n",
      "        aspect_ratios: 1.0\n",
      "        aspect_ratios: 2.0\n",
      "        aspect_ratios: 0.5\n",
      "        scales_per_octave: 2\n",
      "      }\n",
      "    }\n",
      "    post_processing {\n",
      "      batch_non_max_suppression {\n",
      "        score_threshold: 1e-08\n",
      "        iou_threshold: 0.6\n",
      "        max_detections_per_class: 100\n",
      "        max_total_detections: 100\n",
      "        use_static_shapes: false\n",
      "      }\n",
      "      score_converter: SIGMOID\n",
      "    }\n",
      "    normalize_loss_by_num_matches: true\n",
      "    loss {\n",
      "      localization_loss {\n",
      "        weighted_smooth_l1 {\n",
      "        }\n",
      "      }\n",
      "      classification_loss {\n",
      "        weighted_sigmoid_focal {\n",
      "          gamma: 2.0\n",
      "          alpha: 0.25\n",
      "        }\n",
      "      }\n",
      "      classification_weight: 1.0\n",
      "      localization_weight: 1.0\n",
      "    }\n",
      "    encode_background_as_zeros: true\n",
      "    normalize_loc_loss_by_codesize: true\n",
      "    inplace_batchnorm_update: true\n",
      "    freeze_batchnorm: false\n",
      "  }\n",
      "}\n",
      "train_config {\n",
      "  batch_size: 4\n",
      "  data_augmentation_options {\n",
      "    random_horizontal_flip {\n",
      "    }\n",
      "  }\n",
      "  data_augmentation_options {\n",
      "    random_crop_image {\n",
      "      min_object_covered: 0.0\n",
      "      min_aspect_ratio: 0.75\n",
      "      max_aspect_ratio: 3.0\n",
      "      min_area: 0.75\n",
      "      max_area: 1.0\n",
      "      overlap_thresh: 0.0\n",
      "    }\n",
      "  }\n",
      "  sync_replicas: true\n",
      "  optimizer {\n",
      "    momentum_optimizer {\n",
      "      learning_rate {\n",
      "        cosine_decay_learning_rate {\n",
      "          learning_rate_base: 0.08\n",
      "          total_steps: 50000\n",
      "          warmup_learning_rate: 0.026666\n",
      "          warmup_steps: 1000\n",
      "        }\n",
      "      }\n",
      "      momentum_optimizer_value: 0.9\n",
      "    }\n",
      "    use_moving_average: false\n",
      "  }\n",
      "  fine_tune_checkpoint: \"Tensorflow/workspace/pre-trained-models/ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8/checkpoint/ckpt-0\"\n",
      "  num_steps: 50000\n",
      "  startup_delay_steps: 0.0\n",
      "  replicas_to_aggregate: 8\n",
      "  max_number_of_boxes: 100\n",
      "  unpad_groundtruth_tensors: false\n",
      "  fine_tune_checkpoint_type: \"detection\"\n",
      "  fine_tune_checkpoint_version: V2\n",
      "}\n",
      "train_input_reader {\n",
      "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow/workspace/annotations/train.record\"\n",
      "  }\n",
      "}\n",
      "eval_config {\n",
      "  metrics_set: \"coco_detection_metrics\"\n",
      "  use_moving_averages: false\n",
      "}\n",
      "eval_input_reader {\n",
      "  label_map_path: \"Tensorflow/workspace/annotations/label_map.pbtxt\"\n",
      "  shuffle: false\n",
      "  num_epochs: 1\n",
      "  tf_record_input_reader {\n",
      "    input_path: \"Tensorflow/workspace/annotations/test.record\"\n",
      "  }\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(config_text)\n",
    "print(config_text2)\n",
    "print(config_text3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zr3ON7xMpfDG"
   },
   "source": [
    "# Train the model\n",
    "Before we begin training our model, let’s go and copy the TensorFlow/models/research/object_detection/model_main_tf2.py script and paste it straight into our training_demo folder. We will need this script in order to train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "B-Y2UQmQpfDG"
   },
   "outputs": [],
   "source": [
    "TRAINING_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'model_main_tf2.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jMP2XDfQpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'])\n",
    "\n",
    "command2 = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH2'],files['PIPELINE_CONFIG2'])\n",
    "\n",
    "command3 = \"python {} --model_dir={} --pipeline_config_path={} --num_train_steps=5000\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH3'],files['PIPELINE_CONFIG3'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A4OXXi-ApfDH",
    "outputId": "acb45539-b217-4439-9529-b41ef8b9be03"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet_v1 --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet_v1/pipeline.config --num_train_steps=5000\n",
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_resnet101_v1 --pipeline_config_path=Tensorflow/workspace/models/ssd_resnet101_v1/pipeline.config --num_train_steps=5000\n",
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/pipeline.config --num_train_steps=5000\n"
     ]
    }
   ],
   "source": [
    "print(command)\n",
    "print(command2)\n",
    "print(command3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FGfahCn-Ogmj",
    "outputId": "cca65375-6c1b-4b2c-a973-d6312a401354"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following packages will be REMOVED:\n",
      "  libcudnn8-dev\n",
      "The following held packages will be changed:\n",
      "  libcudnn8\n",
      "The following packages will be DOWNGRADED:\n",
      "  libcudnn8\n",
      "0 upgraded, 0 newly installed, 1 downgraded, 1 to remove and 25 not upgraded.\n",
      "Need to get 430 MB of archives.\n",
      "After this operation, 1,392 MB disk space will be freed.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.1.0.77-1+cuda11.2 [430 MB]\n",
      "Fetched 430 MB in 7s (61.9 MB/s)\n",
      "(Reading database ... 123942 files and directories currently installed.)\n",
      "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
      "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
      "\u001b[1mdpkg:\u001b[0m \u001b[1;33mwarning:\u001b[0m downgrading libcudnn8 from 8.1.1.33-1+cuda11.2 to 8.1.0.77-1+cuda11.2\n",
      "(Reading database ... 123919 files and directories currently installed.)\n",
      "Preparing to unpack .../libcudnn8_8.1.0.77-1+cuda11.2_amd64.deb ...\n",
      "Unpacking libcudnn8 (8.1.0.77-1+cuda11.2) over (8.1.1.33-1+cuda11.2) ...\n",
      "Setting up libcudnn8 (8.1.0.77-1+cuda11.2) ...\n"
     ]
    }
   ],
   "source": [
    "!apt install --allow-change-held-packages libcudnn8=8.1.0.77-1+cuda11.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "i3ZsJR-qpfDH",
    "outputId": "029ed535-5b1d-4746-cf16-d55945812ccd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 06:24:32.629870: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 06:24:33.433338: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 06:24:33.433508: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 06:24:33.433529: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-22 06:24:37.193464: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I1022 06:24:37.342535 139983244863360 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
      "I1022 06:24:37.348289 139983244863360 config_util.py:552] Maybe overwriting train_steps: 5000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 06:24:37.348471 139983244863360 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1022 06:24:37.383493 139983244863360 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 06:24:37.403078 139983244863360 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 06:24:37.407122 139983244863360 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 06:24:37.407246 139983244863360 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 06:24:37.407319 139983244863360 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 06:24:37.433511 139983244863360 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 06:24:37.466846 139983244863360 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 06:24:44.242761 139983244863360 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1022 06:24:47.047674 139983244863360 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 06:24:48.603366 139983244863360 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "2022-10-22 06:24:53.478460: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n",
      "2022-10-22 06:24:53.478664: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 29153280 exceeds 10% of free system memory.\n",
      "2022-10-22 06:24:53.537490: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n",
      "2022-10-22 06:24:53.564822: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 23970816 exceeds 10% of free system memory.\n",
      "2022-10-22 06:24:53.618798: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 38340864 exceeds 10% of free system memory.\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.124801 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.127695 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.130281 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.131281 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.134683 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.135781 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.138321 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.139286 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.142559 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 06:25:24.143599 139983244863360 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W1022 06:25:25.162433 139978797467392 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 100 per-step time 0.810s\n",
      "I1022 06:26:45.892790 139983244863360 model_lib_v2.py:707] Step 100 per-step time 0.810s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.30057523,\n",
      " 'Loss/localization_loss': 0.2725774,\n",
      " 'Loss/regularization_loss': 0.7740204,\n",
      " 'Loss/total_loss': 1.347173,\n",
      " 'learning_rate': 0.014666351}\n",
      "I1022 06:26:45.893249 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.30057523,\n",
      " 'Loss/localization_loss': 0.2725774,\n",
      " 'Loss/regularization_loss': 0.7740204,\n",
      " 'Loss/total_loss': 1.347173,\n",
      " 'learning_rate': 0.014666351}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 200 per-step time 0.471s\n",
      "I1022 06:27:33.011031 139983244863360 model_lib_v2.py:707] Step 200 per-step time 0.471s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2646864,\n",
      " 'Loss/localization_loss': 0.26638535,\n",
      " 'Loss/regularization_loss': 0.7731561,\n",
      " 'Loss/total_loss': 1.3042278,\n",
      " 'learning_rate': 0.0159997}\n",
      "I1022 06:27:33.011467 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.2646864,\n",
      " 'Loss/localization_loss': 0.26638535,\n",
      " 'Loss/regularization_loss': 0.7731561,\n",
      " 'Loss/total_loss': 1.3042278,\n",
      " 'learning_rate': 0.0159997}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 300 per-step time 0.448s\n",
      "I1022 06:28:17.849338 139983244863360 model_lib_v2.py:707] Step 300 per-step time 0.448s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.268364,\n",
      " 'Loss/localization_loss': 0.25088456,\n",
      " 'Loss/regularization_loss': 0.77219737,\n",
      " 'Loss/total_loss': 1.291446,\n",
      " 'learning_rate': 0.01733305}\n",
      "I1022 06:28:17.849758 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.268364,\n",
      " 'Loss/localization_loss': 0.25088456,\n",
      " 'Loss/regularization_loss': 0.77219737,\n",
      " 'Loss/total_loss': 1.291446,\n",
      " 'learning_rate': 0.01733305}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 400 per-step time 0.514s\n",
      "I1022 06:29:09.283489 139983244863360 model_lib_v2.py:707] Step 400 per-step time 0.514s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.25289258,\n",
      " 'Loss/localization_loss': 0.15439151,\n",
      " 'Loss/regularization_loss': 0.7711736,\n",
      " 'Loss/total_loss': 1.1784577,\n",
      " 'learning_rate': 0.0186664}\n",
      "I1022 06:29:09.284005 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.25289258,\n",
      " 'Loss/localization_loss': 0.15439151,\n",
      " 'Loss/regularization_loss': 0.7711736,\n",
      " 'Loss/total_loss': 1.1784577,\n",
      " 'learning_rate': 0.0186664}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 500 per-step time 0.494s\n",
      "I1022 06:29:58.690702 139983244863360 model_lib_v2.py:707] Step 500 per-step time 0.494s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21512061,\n",
      " 'Loss/localization_loss': 0.15732116,\n",
      " 'Loss/regularization_loss': 0.7700761,\n",
      " 'Loss/total_loss': 1.1425178,\n",
      " 'learning_rate': 0.01999975}\n",
      "I1022 06:29:58.691074 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.21512061,\n",
      " 'Loss/localization_loss': 0.15732116,\n",
      " 'Loss/regularization_loss': 0.7700761,\n",
      " 'Loss/total_loss': 1.1425178,\n",
      " 'learning_rate': 0.01999975}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 600 per-step time 0.458s\n",
      "I1022 06:30:44.536005 139983244863360 model_lib_v2.py:707] Step 600 per-step time 0.458s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.24914977,\n",
      " 'Loss/localization_loss': 0.18645193,\n",
      " 'Loss/regularization_loss': 0.76889944,\n",
      " 'Loss/total_loss': 1.2045012,\n",
      " 'learning_rate': 0.0213331}\n",
      "I1022 06:30:44.536397 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.24914977,\n",
      " 'Loss/localization_loss': 0.18645193,\n",
      " 'Loss/regularization_loss': 0.76889944,\n",
      " 'Loss/total_loss': 1.2045012,\n",
      " 'learning_rate': 0.0213331}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 700 per-step time 0.469s\n",
      "I1022 06:31:31.454004 139983244863360 model_lib_v2.py:707] Step 700 per-step time 0.469s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22543749,\n",
      " 'Loss/localization_loss': 0.13388939,\n",
      " 'Loss/regularization_loss': 0.76766175,\n",
      " 'Loss/total_loss': 1.1269886,\n",
      " 'learning_rate': 0.02266645}\n",
      "I1022 06:31:31.454389 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.22543749,\n",
      " 'Loss/localization_loss': 0.13388939,\n",
      " 'Loss/regularization_loss': 0.76766175,\n",
      " 'Loss/total_loss': 1.1269886,\n",
      " 'learning_rate': 0.02266645}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 800 per-step time 0.448s\n",
      "I1022 06:32:16.264830 139983244863360 model_lib_v2.py:707] Step 800 per-step time 0.448s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19838576,\n",
      " 'Loss/localization_loss': 0.1537438,\n",
      " 'Loss/regularization_loss': 0.7663388,\n",
      " 'Loss/total_loss': 1.1184684,\n",
      " 'learning_rate': 0.023999799}\n",
      "I1022 06:32:16.265249 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.19838576,\n",
      " 'Loss/localization_loss': 0.1537438,\n",
      " 'Loss/regularization_loss': 0.7663388,\n",
      " 'Loss/total_loss': 1.1184684,\n",
      " 'learning_rate': 0.023999799}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 900 per-step time 0.426s\n",
      "I1022 06:32:58.852374 139983244863360 model_lib_v2.py:707] Step 900 per-step time 0.426s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21417464,\n",
      " 'Loss/localization_loss': 0.13476981,\n",
      " 'Loss/regularization_loss': 0.7649609,\n",
      " 'Loss/total_loss': 1.1139053,\n",
      " 'learning_rate': 0.025333151}\n",
      "I1022 06:32:58.852743 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.21417464,\n",
      " 'Loss/localization_loss': 0.13476981,\n",
      " 'Loss/regularization_loss': 0.7649609,\n",
      " 'Loss/total_loss': 1.1139053,\n",
      " 'learning_rate': 0.025333151}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1000 per-step time 0.475s\n",
      "I1022 06:33:46.348976 139983244863360 model_lib_v2.py:707] Step 1000 per-step time 0.475s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20125318,\n",
      " 'Loss/localization_loss': 0.1586676,\n",
      " 'Loss/regularization_loss': 0.7634925,\n",
      " 'Loss/total_loss': 1.1234133,\n",
      " 'learning_rate': 0.0266665}\n",
      "I1022 06:33:46.349357 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.20125318,\n",
      " 'Loss/localization_loss': 0.1586676,\n",
      " 'Loss/regularization_loss': 0.7634925,\n",
      " 'Loss/total_loss': 1.1234133,\n",
      " 'learning_rate': 0.0266665}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1100 per-step time 0.434s\n",
      "I1022 06:34:29.808237 139983244863360 model_lib_v2.py:707] Step 1100 per-step time 0.434s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16276582,\n",
      " 'Loss/localization_loss': 0.14533728,\n",
      " 'Loss/regularization_loss': 0.76196104,\n",
      " 'Loss/total_loss': 1.0700641,\n",
      " 'learning_rate': 0.02799985}\n",
      "I1022 06:34:29.808641 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.16276582,\n",
      " 'Loss/localization_loss': 0.14533728,\n",
      " 'Loss/regularization_loss': 0.76196104,\n",
      " 'Loss/total_loss': 1.0700641,\n",
      " 'learning_rate': 0.02799985}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1200 per-step time 0.430s\n",
      "I1022 06:35:12.795194 139983244863360 model_lib_v2.py:707] Step 1200 per-step time 0.430s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15176283,\n",
      " 'Loss/localization_loss': 0.09070753,\n",
      " 'Loss/regularization_loss': 0.7603698,\n",
      " 'Loss/total_loss': 1.0028402,\n",
      " 'learning_rate': 0.0293332}\n",
      "I1022 06:35:12.795558 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.15176283,\n",
      " 'Loss/localization_loss': 0.09070753,\n",
      " 'Loss/regularization_loss': 0.7603698,\n",
      " 'Loss/total_loss': 1.0028402,\n",
      " 'learning_rate': 0.0293332}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1300 per-step time 0.472s\n",
      "I1022 06:36:00.001249 139983244863360 model_lib_v2.py:707] Step 1300 per-step time 0.472s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14497367,\n",
      " 'Loss/localization_loss': 0.10458946,\n",
      " 'Loss/regularization_loss': 0.75871265,\n",
      " 'Loss/total_loss': 1.0082757,\n",
      " 'learning_rate': 0.03066655}\n",
      "I1022 06:36:00.001642 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.14497367,\n",
      " 'Loss/localization_loss': 0.10458946,\n",
      " 'Loss/regularization_loss': 0.75871265,\n",
      " 'Loss/total_loss': 1.0082757,\n",
      " 'learning_rate': 0.03066655}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1400 per-step time 0.428s\n",
      "I1022 06:36:42.838780 139983244863360 model_lib_v2.py:707] Step 1400 per-step time 0.428s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1584994,\n",
      " 'Loss/localization_loss': 0.11934401,\n",
      " 'Loss/regularization_loss': 0.75697535,\n",
      " 'Loss/total_loss': 1.0348188,\n",
      " 'learning_rate': 0.0319999}\n",
      "I1022 06:36:42.839371 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.1584994,\n",
      " 'Loss/localization_loss': 0.11934401,\n",
      " 'Loss/regularization_loss': 0.75697535,\n",
      " 'Loss/total_loss': 1.0348188,\n",
      " 'learning_rate': 0.0319999}\n",
      "INFO:tensorflow:Step 1500 per-step time 0.423s\n",
      "I1022 06:37:25.130238 139983244863360 model_lib_v2.py:707] Step 1500 per-step time 0.423s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1793848,\n",
      " 'Loss/localization_loss': 0.104649425,\n",
      " 'Loss/regularization_loss': 0.7551695,\n",
      " 'Loss/total_loss': 1.0392038,\n",
      " 'learning_rate': 0.03333325}\n",
      "I1022 06:37:25.130620 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.1793848,\n",
      " 'Loss/localization_loss': 0.104649425,\n",
      " 'Loss/regularization_loss': 0.7551695,\n",
      " 'Loss/total_loss': 1.0392038,\n",
      " 'learning_rate': 0.03333325}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1600 per-step time 0.486s\n",
      "I1022 06:38:13.689241 139983244863360 model_lib_v2.py:707] Step 1600 per-step time 0.486s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16839702,\n",
      " 'Loss/localization_loss': 0.10930214,\n",
      " 'Loss/regularization_loss': 0.75332004,\n",
      " 'Loss/total_loss': 1.0310192,\n",
      " 'learning_rate': 0.034666598}\n",
      "I1022 06:38:13.689643 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.16839702,\n",
      " 'Loss/localization_loss': 0.10930214,\n",
      " 'Loss/regularization_loss': 0.75332004,\n",
      " 'Loss/total_loss': 1.0310192,\n",
      " 'learning_rate': 0.034666598}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1700 per-step time 0.431s\n",
      "I1022 06:38:56.811244 139983244863360 model_lib_v2.py:707] Step 1700 per-step time 0.431s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15905431,\n",
      " 'Loss/localization_loss': 0.121479675,\n",
      " 'Loss/regularization_loss': 0.75141996,\n",
      " 'Loss/total_loss': 1.0319539,\n",
      " 'learning_rate': 0.03599995}\n",
      "I1022 06:38:56.811614 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.15905431,\n",
      " 'Loss/localization_loss': 0.121479675,\n",
      " 'Loss/regularization_loss': 0.75141996,\n",
      " 'Loss/total_loss': 1.0319539,\n",
      " 'learning_rate': 0.03599995}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1800 per-step time 0.429s\n",
      "I1022 06:39:39.745138 139983244863360 model_lib_v2.py:707] Step 1800 per-step time 0.429s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14537309,\n",
      " 'Loss/localization_loss': 0.09904315,\n",
      " 'Loss/regularization_loss': 0.74940014,\n",
      " 'Loss/total_loss': 0.9938164,\n",
      " 'learning_rate': 0.037333302}\n",
      "I1022 06:39:39.745619 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.14537309,\n",
      " 'Loss/localization_loss': 0.09904315,\n",
      " 'Loss/regularization_loss': 0.74940014,\n",
      " 'Loss/total_loss': 0.9938164,\n",
      " 'learning_rate': 0.037333302}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1900 per-step time 0.486s\n",
      "I1022 06:40:28.411999 139983244863360 model_lib_v2.py:707] Step 1900 per-step time 0.486s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13884847,\n",
      " 'Loss/localization_loss': 0.083029695,\n",
      " 'Loss/regularization_loss': 0.7473349,\n",
      " 'Loss/total_loss': 0.96921307,\n",
      " 'learning_rate': 0.03866665}\n",
      "I1022 06:40:28.412399 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.13884847,\n",
      " 'Loss/localization_loss': 0.083029695,\n",
      " 'Loss/regularization_loss': 0.7473349,\n",
      " 'Loss/total_loss': 0.96921307,\n",
      " 'learning_rate': 0.03866665}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2000 per-step time 0.435s\n",
      "I1022 06:41:11.930493 139983244863360 model_lib_v2.py:707] Step 2000 per-step time 0.435s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1522773,\n",
      " 'Loss/localization_loss': 0.12129066,\n",
      " 'Loss/regularization_loss': 0.7452603,\n",
      " 'Loss/total_loss': 1.0188283,\n",
      " 'learning_rate': 0.04}\n",
      "I1022 06:41:11.930925 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.1522773,\n",
      " 'Loss/localization_loss': 0.12129066,\n",
      " 'Loss/regularization_loss': 0.7452603,\n",
      " 'Loss/total_loss': 1.0188283,\n",
      " 'learning_rate': 0.04}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2100 per-step time 0.469s\n",
      "I1022 06:41:58.879983 139983244863360 model_lib_v2.py:707] Step 2100 per-step time 0.469s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13670292,\n",
      " 'Loss/localization_loss': 0.07557889,\n",
      " 'Loss/regularization_loss': 0.7430951,\n",
      " 'Loss/total_loss': 0.9553769,\n",
      " 'learning_rate': 0.039998136}\n",
      "I1022 06:41:58.880411 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.13670292,\n",
      " 'Loss/localization_loss': 0.07557889,\n",
      " 'Loss/regularization_loss': 0.7430951,\n",
      " 'Loss/total_loss': 0.9553769,\n",
      " 'learning_rate': 0.039998136}\n",
      "INFO:tensorflow:Step 2200 per-step time 0.446s\n",
      "I1022 06:42:43.420612 139983244863360 model_lib_v2.py:707] Step 2200 per-step time 0.446s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14172058,\n",
      " 'Loss/localization_loss': 0.11927483,\n",
      " 'Loss/regularization_loss': 0.74091345,\n",
      " 'Loss/total_loss': 1.0019089,\n",
      " 'learning_rate': 0.039992537}\n",
      "I1022 06:42:43.421042 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.14172058,\n",
      " 'Loss/localization_loss': 0.11927483,\n",
      " 'Loss/regularization_loss': 0.74091345,\n",
      " 'Loss/total_loss': 1.0019089,\n",
      " 'learning_rate': 0.039992537}\n",
      "INFO:tensorflow:Step 2300 per-step time 0.445s\n",
      "I1022 06:43:27.929881 139983244863360 model_lib_v2.py:707] Step 2300 per-step time 0.445s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14164193,\n",
      " 'Loss/localization_loss': 0.08659148,\n",
      " 'Loss/regularization_loss': 0.7387465,\n",
      " 'Loss/total_loss': 0.9669799,\n",
      " 'learning_rate': 0.03998321}\n",
      "I1022 06:43:27.930318 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.14164193,\n",
      " 'Loss/localization_loss': 0.08659148,\n",
      " 'Loss/regularization_loss': 0.7387465,\n",
      " 'Loss/total_loss': 0.9669799,\n",
      " 'learning_rate': 0.03998321}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2400 per-step time 0.470s\n",
      "I1022 06:44:14.881204 139983244863360 model_lib_v2.py:707] Step 2400 per-step time 0.470s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12687756,\n",
      " 'Loss/localization_loss': 0.08377945,\n",
      " 'Loss/regularization_loss': 0.736587,\n",
      " 'Loss/total_loss': 0.947244,\n",
      " 'learning_rate': 0.039970152}\n",
      "I1022 06:44:14.881672 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.12687756,\n",
      " 'Loss/localization_loss': 0.08377945,\n",
      " 'Loss/regularization_loss': 0.736587,\n",
      " 'Loss/total_loss': 0.947244,\n",
      " 'learning_rate': 0.039970152}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2500 per-step time 0.440s\n",
      "I1022 06:44:58.900156 139983244863360 model_lib_v2.py:707] Step 2500 per-step time 0.440s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13478914,\n",
      " 'Loss/localization_loss': 0.08290454,\n",
      " 'Loss/regularization_loss': 0.7344188,\n",
      " 'Loss/total_loss': 0.9521125,\n",
      " 'learning_rate': 0.039953373}\n",
      "I1022 06:44:58.900544 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.13478914,\n",
      " 'Loss/localization_loss': 0.08290454,\n",
      " 'Loss/regularization_loss': 0.7344188,\n",
      " 'Loss/total_loss': 0.9521125,\n",
      " 'learning_rate': 0.039953373}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2600 per-step time 0.446s\n",
      "I1022 06:45:43.467185 139983244863360 model_lib_v2.py:707] Step 2600 per-step time 0.446s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.120550595,\n",
      " 'Loss/localization_loss': 0.059776545,\n",
      " 'Loss/regularization_loss': 0.7322546,\n",
      " 'Loss/total_loss': 0.9125818,\n",
      " 'learning_rate': 0.03993287}\n",
      "I1022 06:45:43.467561 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.120550595,\n",
      " 'Loss/localization_loss': 0.059776545,\n",
      " 'Loss/regularization_loss': 0.7322546,\n",
      " 'Loss/total_loss': 0.9125818,\n",
      " 'learning_rate': 0.03993287}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2700 per-step time 0.466s\n",
      "I1022 06:46:30.045598 139983244863360 model_lib_v2.py:707] Step 2700 per-step time 0.466s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12852073,\n",
      " 'Loss/localization_loss': 0.06829482,\n",
      " 'Loss/regularization_loss': 0.73012453,\n",
      " 'Loss/total_loss': 0.9269401,\n",
      " 'learning_rate': 0.039908648}\n",
      "I1022 06:46:30.045990 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.12852073,\n",
      " 'Loss/localization_loss': 0.06829482,\n",
      " 'Loss/regularization_loss': 0.73012453,\n",
      " 'Loss/total_loss': 0.9269401,\n",
      " 'learning_rate': 0.039908648}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2800 per-step time 0.448s\n",
      "I1022 06:47:14.880281 139983244863360 model_lib_v2.py:707] Step 2800 per-step time 0.448s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09725833,\n",
      " 'Loss/localization_loss': 0.05355456,\n",
      " 'Loss/regularization_loss': 0.72797996,\n",
      " 'Loss/total_loss': 0.8787929,\n",
      " 'learning_rate': 0.039880715}\n",
      "I1022 06:47:14.883991 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.09725833,\n",
      " 'Loss/localization_loss': 0.05355456,\n",
      " 'Loss/regularization_loss': 0.72797996,\n",
      " 'Loss/total_loss': 0.8787929,\n",
      " 'learning_rate': 0.039880715}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2900 per-step time 0.434s\n",
      "I1022 06:47:58.274571 139983244863360 model_lib_v2.py:707] Step 2900 per-step time 0.434s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.116147414,\n",
      " 'Loss/localization_loss': 0.07315055,\n",
      " 'Loss/regularization_loss': 0.72583556,\n",
      " 'Loss/total_loss': 0.91513354,\n",
      " 'learning_rate': 0.039849065}\n",
      "I1022 06:47:58.275031 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.116147414,\n",
      " 'Loss/localization_loss': 0.07315055,\n",
      " 'Loss/regularization_loss': 0.72583556,\n",
      " 'Loss/total_loss': 0.91513354,\n",
      " 'learning_rate': 0.039849065}\n",
      "INFO:tensorflow:Step 3000 per-step time 0.487s\n",
      "I1022 06:48:46.972093 139983244863360 model_lib_v2.py:707] Step 3000 per-step time 0.487s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.116282046,\n",
      " 'Loss/localization_loss': 0.07361136,\n",
      " 'Loss/regularization_loss': 0.7237084,\n",
      " 'Loss/total_loss': 0.91360176,\n",
      " 'learning_rate': 0.03981372}\n",
      "I1022 06:48:46.972539 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.116282046,\n",
      " 'Loss/localization_loss': 0.07361136,\n",
      " 'Loss/regularization_loss': 0.7237084,\n",
      " 'Loss/total_loss': 0.91360176,\n",
      " 'learning_rate': 0.03981372}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3100 per-step time 0.429s\n",
      "I1022 06:49:29.905863 139983244863360 model_lib_v2.py:707] Step 3100 per-step time 0.429s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12863551,\n",
      " 'Loss/localization_loss': 0.07450701,\n",
      " 'Loss/regularization_loss': 0.721611,\n",
      " 'Loss/total_loss': 0.92475355,\n",
      " 'learning_rate': 0.03977467}\n",
      "I1022 06:49:29.906370 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.12863551,\n",
      " 'Loss/localization_loss': 0.07450701,\n",
      " 'Loss/regularization_loss': 0.721611,\n",
      " 'Loss/total_loss': 0.92475355,\n",
      " 'learning_rate': 0.03977467}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3200 per-step time 0.438s\n",
      "I1022 06:50:13.752479 139983244863360 model_lib_v2.py:707] Step 3200 per-step time 0.438s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10783537,\n",
      " 'Loss/localization_loss': 0.06788144,\n",
      " 'Loss/regularization_loss': 0.7194789,\n",
      " 'Loss/total_loss': 0.8951957,\n",
      " 'learning_rate': 0.03973194}\n",
      "I1022 06:50:13.752980 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.10783537,\n",
      " 'Loss/localization_loss': 0.06788144,\n",
      " 'Loss/regularization_loss': 0.7194789,\n",
      " 'Loss/total_loss': 0.8951957,\n",
      " 'learning_rate': 0.03973194}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3300 per-step time 0.476s\n",
      "I1022 06:51:01.337773 139983244863360 model_lib_v2.py:707] Step 3300 per-step time 0.476s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08763507,\n",
      " 'Loss/localization_loss': 0.047675833,\n",
      " 'Loss/regularization_loss': 0.7173634,\n",
      " 'Loss/total_loss': 0.8526743,\n",
      " 'learning_rate': 0.03968552}\n",
      "I1022 06:51:01.338141 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.08763507,\n",
      " 'Loss/localization_loss': 0.047675833,\n",
      " 'Loss/regularization_loss': 0.7173634,\n",
      " 'Loss/total_loss': 0.8526743,\n",
      " 'learning_rate': 0.03968552}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3400 per-step time 0.432s\n",
      "I1022 06:51:44.527204 139983244863360 model_lib_v2.py:707] Step 3400 per-step time 0.432s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15553851,\n",
      " 'Loss/localization_loss': 0.0994157,\n",
      " 'Loss/regularization_loss': 0.7152392,\n",
      " 'Loss/total_loss': 0.97019345,\n",
      " 'learning_rate': 0.039635435}\n",
      "I1022 06:51:44.527571 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.15553851,\n",
      " 'Loss/localization_loss': 0.0994157,\n",
      " 'Loss/regularization_loss': 0.7152392,\n",
      " 'Loss/total_loss': 0.97019345,\n",
      " 'learning_rate': 0.039635435}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3500 per-step time 0.426s\n",
      "I1022 06:52:27.177964 139983244863360 model_lib_v2.py:707] Step 3500 per-step time 0.426s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10493549,\n",
      " 'Loss/localization_loss': 0.045261204,\n",
      " 'Loss/regularization_loss': 0.71311337,\n",
      " 'Loss/total_loss': 0.8633101,\n",
      " 'learning_rate': 0.03958168}\n",
      "I1022 06:52:27.178364 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.10493549,\n",
      " 'Loss/localization_loss': 0.045261204,\n",
      " 'Loss/regularization_loss': 0.71311337,\n",
      " 'Loss/total_loss': 0.8633101,\n",
      " 'learning_rate': 0.03958168}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3600 per-step time 0.490s\n",
      "I1022 06:53:16.167447 139983244863360 model_lib_v2.py:707] Step 3600 per-step time 0.490s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1273449,\n",
      " 'Loss/localization_loss': 0.06699954,\n",
      " 'Loss/regularization_loss': 0.7110204,\n",
      " 'Loss/total_loss': 0.9053649,\n",
      " 'learning_rate': 0.039524276}\n",
      "I1022 06:53:16.167791 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.1273449,\n",
      " 'Loss/localization_loss': 0.06699954,\n",
      " 'Loss/regularization_loss': 0.7110204,\n",
      " 'Loss/total_loss': 0.9053649,\n",
      " 'learning_rate': 0.039524276}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3700 per-step time 0.426s\n",
      "I1022 06:53:58.783817 139983244863360 model_lib_v2.py:707] Step 3700 per-step time 0.426s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1205756,\n",
      " 'Loss/localization_loss': 0.07273918,\n",
      " 'Loss/regularization_loss': 0.7089273,\n",
      " 'Loss/total_loss': 0.90224206,\n",
      " 'learning_rate': 0.03946323}\n",
      "I1022 06:53:58.784204 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.1205756,\n",
      " 'Loss/localization_loss': 0.07273918,\n",
      " 'Loss/regularization_loss': 0.7089273,\n",
      " 'Loss/total_loss': 0.90224206,\n",
      " 'learning_rate': 0.03946323}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3800 per-step time 0.454s\n",
      "I1022 06:54:44.172081 139983244863360 model_lib_v2.py:707] Step 3800 per-step time 0.454s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11082064,\n",
      " 'Loss/localization_loss': 0.05475621,\n",
      " 'Loss/regularization_loss': 0.7068544,\n",
      " 'Loss/total_loss': 0.8724313,\n",
      " 'learning_rate': 0.039398547}\n",
      "I1022 06:54:44.172489 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.11082064,\n",
      " 'Loss/localization_loss': 0.05475621,\n",
      " 'Loss/regularization_loss': 0.7068544,\n",
      " 'Loss/total_loss': 0.8724313,\n",
      " 'learning_rate': 0.039398547}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3900 per-step time 0.458s\n",
      "I1022 06:55:29.951050 139983244863360 model_lib_v2.py:707] Step 3900 per-step time 0.458s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.116561666,\n",
      " 'Loss/localization_loss': 0.049366444,\n",
      " 'Loss/regularization_loss': 0.7047878,\n",
      " 'Loss/total_loss': 0.8707159,\n",
      " 'learning_rate': 0.039330248}\n",
      "I1022 06:55:29.951517 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.116561666,\n",
      " 'Loss/localization_loss': 0.049366444,\n",
      " 'Loss/regularization_loss': 0.7047878,\n",
      " 'Loss/total_loss': 0.8707159,\n",
      " 'learning_rate': 0.039330248}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4000 per-step time 0.430s\n",
      "I1022 06:56:12.946711 139983244863360 model_lib_v2.py:707] Step 4000 per-step time 0.430s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10756644,\n",
      " 'Loss/localization_loss': 0.07001631,\n",
      " 'Loss/regularization_loss': 0.7027153,\n",
      " 'Loss/total_loss': 0.880298,\n",
      " 'learning_rate': 0.039258346}\n",
      "I1022 06:56:12.947188 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.10756644,\n",
      " 'Loss/localization_loss': 0.07001631,\n",
      " 'Loss/regularization_loss': 0.7027153,\n",
      " 'Loss/total_loss': 0.880298,\n",
      " 'learning_rate': 0.039258346}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4100 per-step time 0.494s\n",
      "I1022 06:57:02.398619 139983244863360 model_lib_v2.py:707] Step 4100 per-step time 0.494s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.100549646,\n",
      " 'Loss/localization_loss': 0.059607156,\n",
      " 'Loss/regularization_loss': 0.70064926,\n",
      " 'Loss/total_loss': 0.86080605,\n",
      " 'learning_rate': 0.03918285}\n",
      "I1022 06:57:02.398985 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.100549646,\n",
      " 'Loss/localization_loss': 0.059607156,\n",
      " 'Loss/regularization_loss': 0.70064926,\n",
      " 'Loss/total_loss': 0.86080605,\n",
      " 'learning_rate': 0.03918285}\n",
      "INFO:tensorflow:Step 4200 per-step time 0.434s\n",
      "I1022 06:57:45.747141 139983244863360 model_lib_v2.py:707] Step 4200 per-step time 0.434s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09146054,\n",
      " 'Loss/localization_loss': 0.05623886,\n",
      " 'Loss/regularization_loss': 0.6985878,\n",
      " 'Loss/total_loss': 0.8462872,\n",
      " 'learning_rate': 0.03910377}\n",
      "I1022 06:57:45.747494 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.09146054,\n",
      " 'Loss/localization_loss': 0.05623886,\n",
      " 'Loss/regularization_loss': 0.6985878,\n",
      " 'Loss/total_loss': 0.8462872,\n",
      " 'learning_rate': 0.03910377}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4300 per-step time 0.436s\n",
      "I1022 06:58:29.392238 139983244863360 model_lib_v2.py:707] Step 4300 per-step time 0.436s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11608726,\n",
      " 'Loss/localization_loss': 0.06350406,\n",
      " 'Loss/regularization_loss': 0.69655186,\n",
      " 'Loss/total_loss': 0.8761432,\n",
      " 'learning_rate': 0.039021127}\n",
      "I1022 06:58:29.392648 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.11608726,\n",
      " 'Loss/localization_loss': 0.06350406,\n",
      " 'Loss/regularization_loss': 0.69655186,\n",
      " 'Loss/total_loss': 0.8761432,\n",
      " 'learning_rate': 0.039021127}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4400 per-step time 0.471s\n",
      "I1022 06:59:16.488514 139983244863360 model_lib_v2.py:707] Step 4400 per-step time 0.471s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10190118,\n",
      " 'Loss/localization_loss': 0.057971317,\n",
      " 'Loss/regularization_loss': 0.69451994,\n",
      " 'Loss/total_loss': 0.8543924,\n",
      " 'learning_rate': 0.03893494}\n",
      "I1022 06:59:16.488843 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.10190118,\n",
      " 'Loss/localization_loss': 0.057971317,\n",
      " 'Loss/regularization_loss': 0.69451994,\n",
      " 'Loss/total_loss': 0.8543924,\n",
      " 'learning_rate': 0.03893494}\n",
      "INFO:tensorflow:Step 4500 per-step time 0.441s\n",
      "I1022 07:00:00.557350 139983244863360 model_lib_v2.py:707] Step 4500 per-step time 0.441s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.086393125,\n",
      " 'Loss/localization_loss': 0.04026761,\n",
      " 'Loss/regularization_loss': 0.69250077,\n",
      " 'Loss/total_loss': 0.81916153,\n",
      " 'learning_rate': 0.03884522}\n",
      "I1022 07:00:00.557847 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.086393125,\n",
      " 'Loss/localization_loss': 0.04026761,\n",
      " 'Loss/regularization_loss': 0.69250077,\n",
      " 'Loss/total_loss': 0.81916153,\n",
      " 'learning_rate': 0.03884522}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4600 per-step time 0.426s\n",
      "I1022 07:00:43.123352 139983244863360 model_lib_v2.py:707] Step 4600 per-step time 0.426s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09288203,\n",
      " 'Loss/localization_loss': 0.040780406,\n",
      " 'Loss/regularization_loss': 0.69048077,\n",
      " 'Loss/total_loss': 0.8241432,\n",
      " 'learning_rate': 0.03875198}\n",
      "I1022 07:00:43.123769 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.09288203,\n",
      " 'Loss/localization_loss': 0.040780406,\n",
      " 'Loss/regularization_loss': 0.69048077,\n",
      " 'Loss/total_loss': 0.8241432,\n",
      " 'learning_rate': 0.03875198}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4700 per-step time 0.470s\n",
      "I1022 07:01:30.081151 139983244863360 model_lib_v2.py:707] Step 4700 per-step time 0.470s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.095925935,\n",
      " 'Loss/localization_loss': 0.04789356,\n",
      " 'Loss/regularization_loss': 0.6884787,\n",
      " 'Loss/total_loss': 0.8322982,\n",
      " 'learning_rate': 0.038655244}\n",
      "I1022 07:01:30.081559 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.095925935,\n",
      " 'Loss/localization_loss': 0.04789356,\n",
      " 'Loss/regularization_loss': 0.6884787,\n",
      " 'Loss/total_loss': 0.8322982,\n",
      " 'learning_rate': 0.038655244}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4800 per-step time 0.428s\n",
      "I1022 07:02:12.903995 139983244863360 model_lib_v2.py:707] Step 4800 per-step time 0.428s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.089835934,\n",
      " 'Loss/localization_loss': 0.04991635,\n",
      " 'Loss/regularization_loss': 0.68648946,\n",
      " 'Loss/total_loss': 0.82624173,\n",
      " 'learning_rate': 0.038555026}\n",
      "I1022 07:02:12.904500 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.089835934,\n",
      " 'Loss/localization_loss': 0.04991635,\n",
      " 'Loss/regularization_loss': 0.68648946,\n",
      " 'Loss/total_loss': 0.82624173,\n",
      " 'learning_rate': 0.038555026}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4900 per-step time 0.438s\n",
      "I1022 07:02:56.749983 139983244863360 model_lib_v2.py:707] Step 4900 per-step time 0.438s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08984785,\n",
      " 'Loss/localization_loss': 0.046125717,\n",
      " 'Loss/regularization_loss': 0.6844983,\n",
      " 'Loss/total_loss': 0.8204719,\n",
      " 'learning_rate': 0.038451348}\n",
      "I1022 07:02:56.750356 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.08984785,\n",
      " 'Loss/localization_loss': 0.046125717,\n",
      " 'Loss/regularization_loss': 0.6844983,\n",
      " 'Loss/total_loss': 0.8204719,\n",
      " 'learning_rate': 0.038451348}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 5000 per-step time 0.485s\n",
      "I1022 07:03:45.252465 139983244863360 model_lib_v2.py:707] Step 5000 per-step time 0.485s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08142167,\n",
      " 'Loss/localization_loss': 0.040387154,\n",
      " 'Loss/regularization_loss': 0.6825257,\n",
      " 'Loss/total_loss': 0.8043345,\n",
      " 'learning_rate': 0.038344227}\n",
      "I1022 07:03:45.252819 139983244863360 model_lib_v2.py:708] {'Loss/classification_loss': 0.08142167,\n",
      " 'Loss/localization_loss': 0.040387154,\n",
      " 'Loss/regularization_loss': 0.6825257,\n",
      " 'Loss/total_loss': 0.8043345,\n",
      " 'learning_rate': 0.038344227}\n"
     ]
    }
   ],
   "source": [
    "!{command} #training model ssd_mobilenet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tMkWBBBSdvhL",
    "outputId": "93cb1ef0-8a2f-468b-a9b1-f7f52cadaf97"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 07:04:17.332253: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 07:04:18.263851: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 07:04:18.264008: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 07:04:18.264029: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-22 07:04:23.982585: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I1022 07:04:24.025751 139879681050496 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
      "I1022 07:04:24.033072 139879681050496 config_util.py:552] Maybe overwriting train_steps: 5000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 07:04:24.033248 139879681050496 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1022 07:04:24.061027 139879681050496 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 07:04:24.067933 139879681050496 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 07:04:24.068121 139879681050496 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 07:04:24.068212 139879681050496 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 07:04:24.068280 139879681050496 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 07:04:24.074250 139879681050496 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 07:04:24.089864 139879681050496 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 07:04:30.967114 139879681050496 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1022 07:04:33.890393 139879681050496 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 07:04:35.545909 139879681050496 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.196359 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.199472 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.202341 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.203470 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.206205 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.207223 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.210849 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.211868 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.213502 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 07:05:14.214611 139879681050496 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W1022 07:05:16.211919 139875231704832 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 100 per-step time 1.385s\n",
      "I1022 07:07:34.471890 139879681050496 model_lib_v2.py:707] Step 100 per-step time 1.385s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3157732,\n",
      " 'Loss/localization_loss': 0.30135825,\n",
      " 'Loss/regularization_loss': 0.27805358,\n",
      " 'Loss/total_loss': 0.89518505,\n",
      " 'learning_rate': 0.014666351}\n",
      "I1022 07:07:34.472407 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.3157732,\n",
      " 'Loss/localization_loss': 0.30135825,\n",
      " 'Loss/regularization_loss': 0.27805358,\n",
      " 'Loss/total_loss': 0.89518505,\n",
      " 'learning_rate': 0.014666351}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 200 per-step time 0.833s\n",
      "I1022 07:08:57.659145 139879681050496 model_lib_v2.py:707] Step 200 per-step time 0.833s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2087822,\n",
      " 'Loss/localization_loss': 0.20839468,\n",
      " 'Loss/regularization_loss': 0.27701524,\n",
      " 'Loss/total_loss': 0.6941921,\n",
      " 'learning_rate': 0.0159997}\n",
      "I1022 07:08:57.659488 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.2087822,\n",
      " 'Loss/localization_loss': 0.20839468,\n",
      " 'Loss/regularization_loss': 0.27701524,\n",
      " 'Loss/total_loss': 0.6941921,\n",
      " 'learning_rate': 0.0159997}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 300 per-step time 0.829s\n",
      "I1022 07:10:20.599451 139879681050496 model_lib_v2.py:707] Step 300 per-step time 0.829s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.28806937,\n",
      " 'Loss/localization_loss': 0.22236058,\n",
      " 'Loss/regularization_loss': 0.27536762,\n",
      " 'Loss/total_loss': 0.7857976,\n",
      " 'learning_rate': 0.01733305}\n",
      "I1022 07:10:20.599795 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.28806937,\n",
      " 'Loss/localization_loss': 0.22236058,\n",
      " 'Loss/regularization_loss': 0.27536762,\n",
      " 'Loss/total_loss': 0.7857976,\n",
      " 'learning_rate': 0.01733305}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 400 per-step time 0.831s\n",
      "I1022 07:11:43.759492 139879681050496 model_lib_v2.py:707] Step 400 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17753309,\n",
      " 'Loss/localization_loss': 0.14328834,\n",
      " 'Loss/regularization_loss': 0.27344555,\n",
      " 'Loss/total_loss': 0.594267,\n",
      " 'learning_rate': 0.0186664}\n",
      "I1022 07:11:43.759928 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.17753309,\n",
      " 'Loss/localization_loss': 0.14328834,\n",
      " 'Loss/regularization_loss': 0.27344555,\n",
      " 'Loss/total_loss': 0.594267,\n",
      " 'learning_rate': 0.0186664}\n",
      "INFO:tensorflow:Step 500 per-step time 0.832s\n",
      "I1022 07:13:06.954212 139879681050496 model_lib_v2.py:707] Step 500 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21625274,\n",
      " 'Loss/localization_loss': 0.1832614,\n",
      " 'Loss/regularization_loss': 0.27383748,\n",
      " 'Loss/total_loss': 0.67335165,\n",
      " 'learning_rate': 0.01999975}\n",
      "I1022 07:13:06.954608 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.21625274,\n",
      " 'Loss/localization_loss': 0.1832614,\n",
      " 'Loss/regularization_loss': 0.27383748,\n",
      " 'Loss/total_loss': 0.67335165,\n",
      " 'learning_rate': 0.01999975}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 600 per-step time 0.830s\n",
      "I1022 07:14:29.979844 139879681050496 model_lib_v2.py:707] Step 600 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16618262,\n",
      " 'Loss/localization_loss': 0.13664268,\n",
      " 'Loss/regularization_loss': 0.27192494,\n",
      " 'Loss/total_loss': 0.57475024,\n",
      " 'learning_rate': 0.0213331}\n",
      "I1022 07:14:29.980180 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.16618262,\n",
      " 'Loss/localization_loss': 0.13664268,\n",
      " 'Loss/regularization_loss': 0.27192494,\n",
      " 'Loss/total_loss': 0.57475024,\n",
      " 'learning_rate': 0.0213331}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 700 per-step time 0.832s\n",
      "I1022 07:15:53.139160 139879681050496 model_lib_v2.py:707] Step 700 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18129674,\n",
      " 'Loss/localization_loss': 0.1371799,\n",
      " 'Loss/regularization_loss': 0.26978797,\n",
      " 'Loss/total_loss': 0.5882646,\n",
      " 'learning_rate': 0.02266645}\n",
      "I1022 07:15:53.139486 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.18129674,\n",
      " 'Loss/localization_loss': 0.1371799,\n",
      " 'Loss/regularization_loss': 0.26978797,\n",
      " 'Loss/total_loss': 0.5882646,\n",
      " 'learning_rate': 0.02266645}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 800 per-step time 0.830s\n",
      "I1022 07:17:16.182771 139879681050496 model_lib_v2.py:707] Step 800 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19324842,\n",
      " 'Loss/localization_loss': 0.15791191,\n",
      " 'Loss/regularization_loss': 0.268052,\n",
      " 'Loss/total_loss': 0.6192124,\n",
      " 'learning_rate': 0.023999799}\n",
      "I1022 07:17:16.183095 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.19324842,\n",
      " 'Loss/localization_loss': 0.15791191,\n",
      " 'Loss/regularization_loss': 0.268052,\n",
      " 'Loss/total_loss': 0.6192124,\n",
      " 'learning_rate': 0.023999799}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 900 per-step time 0.831s\n",
      "I1022 07:18:39.303314 139879681050496 model_lib_v2.py:707] Step 900 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23939312,\n",
      " 'Loss/localization_loss': 0.23121594,\n",
      " 'Loss/regularization_loss': 0.2676042,\n",
      " 'Loss/total_loss': 0.7382133,\n",
      " 'learning_rate': 0.025333151}\n",
      "I1022 07:18:39.303737 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.23939312,\n",
      " 'Loss/localization_loss': 0.23121594,\n",
      " 'Loss/regularization_loss': 0.2676042,\n",
      " 'Loss/total_loss': 0.7382133,\n",
      " 'learning_rate': 0.025333151}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1000 per-step time 0.830s\n",
      "I1022 07:20:02.344655 139879681050496 model_lib_v2.py:707] Step 1000 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2004517,\n",
      " 'Loss/localization_loss': 0.11527681,\n",
      " 'Loss/regularization_loss': 0.26793253,\n",
      " 'Loss/total_loss': 0.5836611,\n",
      " 'learning_rate': 0.0266665}\n",
      "I1022 07:20:02.344973 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.2004517,\n",
      " 'Loss/localization_loss': 0.11527681,\n",
      " 'Loss/regularization_loss': 0.26793253,\n",
      " 'Loss/total_loss': 0.5836611,\n",
      " 'learning_rate': 0.0266665}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1100 per-step time 0.862s\n",
      "I1022 07:21:28.520849 139879681050496 model_lib_v2.py:707] Step 1100 per-step time 0.862s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15959395,\n",
      " 'Loss/localization_loss': 0.16027746,\n",
      " 'Loss/regularization_loss': 0.26739478,\n",
      " 'Loss/total_loss': 0.5872662,\n",
      " 'learning_rate': 0.02799985}\n",
      "I1022 07:21:28.521202 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.15959395,\n",
      " 'Loss/localization_loss': 0.16027746,\n",
      " 'Loss/regularization_loss': 0.26739478,\n",
      " 'Loss/total_loss': 0.5872662,\n",
      " 'learning_rate': 0.02799985}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1200 per-step time 0.829s\n",
      "I1022 07:22:51.447167 139879681050496 model_lib_v2.py:707] Step 1200 per-step time 0.829s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1549485,\n",
      " 'Loss/localization_loss': 0.13036534,\n",
      " 'Loss/regularization_loss': 0.26605624,\n",
      " 'Loss/total_loss': 0.5513701,\n",
      " 'learning_rate': 0.0293332}\n",
      "I1022 07:22:51.447513 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.1549485,\n",
      " 'Loss/localization_loss': 0.13036534,\n",
      " 'Loss/regularization_loss': 0.26605624,\n",
      " 'Loss/total_loss': 0.5513701,\n",
      " 'learning_rate': 0.0293332}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1300 per-step time 0.831s\n",
      "I1022 07:24:14.556977 139879681050496 model_lib_v2.py:707] Step 1300 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16347705,\n",
      " 'Loss/localization_loss': 0.10908871,\n",
      " 'Loss/regularization_loss': 0.26429966,\n",
      " 'Loss/total_loss': 0.5368654,\n",
      " 'learning_rate': 0.03066655}\n",
      "I1022 07:24:14.557298 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.16347705,\n",
      " 'Loss/localization_loss': 0.10908871,\n",
      " 'Loss/regularization_loss': 0.26429966,\n",
      " 'Loss/total_loss': 0.5368654,\n",
      " 'learning_rate': 0.03066655}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1400 per-step time 0.831s\n",
      "I1022 07:25:37.666053 139879681050496 model_lib_v2.py:707] Step 1400 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16279468,\n",
      " 'Loss/localization_loss': 0.096227005,\n",
      " 'Loss/regularization_loss': 0.26341712,\n",
      " 'Loss/total_loss': 0.5224388,\n",
      " 'learning_rate': 0.0319999}\n",
      "I1022 07:25:37.666362 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.16279468,\n",
      " 'Loss/localization_loss': 0.096227005,\n",
      " 'Loss/regularization_loss': 0.26341712,\n",
      " 'Loss/total_loss': 0.5224388,\n",
      " 'learning_rate': 0.0319999}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1500 per-step time 0.831s\n",
      "I1022 07:27:00.753805 139879681050496 model_lib_v2.py:707] Step 1500 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1716927,\n",
      " 'Loss/localization_loss': 0.14015995,\n",
      " 'Loss/regularization_loss': 0.26658726,\n",
      " 'Loss/total_loss': 0.5784399,\n",
      " 'learning_rate': 0.03333325}\n",
      "I1022 07:27:00.754864 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.1716927,\n",
      " 'Loss/localization_loss': 0.14015995,\n",
      " 'Loss/regularization_loss': 0.26658726,\n",
      " 'Loss/total_loss': 0.5784399,\n",
      " 'learning_rate': 0.03333325}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1600 per-step time 0.832s\n",
      "I1022 07:28:23.896856 139879681050496 model_lib_v2.py:707] Step 1600 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2698514,\n",
      " 'Loss/localization_loss': 0.26072007,\n",
      " 'Loss/regularization_loss': 0.26700962,\n",
      " 'Loss/total_loss': 0.7975811,\n",
      " 'learning_rate': 0.034666598}\n",
      "I1022 07:28:23.897217 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.2698514,\n",
      " 'Loss/localization_loss': 0.26072007,\n",
      " 'Loss/regularization_loss': 0.26700962,\n",
      " 'Loss/total_loss': 0.7975811,\n",
      " 'learning_rate': 0.034666598}\n",
      "INFO:tensorflow:Step 1700 per-step time 0.831s\n",
      "I1022 07:29:46.979102 139879681050496 model_lib_v2.py:707] Step 1700 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2224734,\n",
      " 'Loss/localization_loss': 0.17889918,\n",
      " 'Loss/regularization_loss': 0.2745276,\n",
      " 'Loss/total_loss': 0.6759002,\n",
      " 'learning_rate': 0.03599995}\n",
      "I1022 07:29:46.979444 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.2224734,\n",
      " 'Loss/localization_loss': 0.17889918,\n",
      " 'Loss/regularization_loss': 0.2745276,\n",
      " 'Loss/total_loss': 0.6759002,\n",
      " 'learning_rate': 0.03599995}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1800 per-step time 0.829s\n",
      "I1022 07:31:09.913247 139879681050496 model_lib_v2.py:707] Step 1800 per-step time 0.829s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17841947,\n",
      " 'Loss/localization_loss': 0.1304848,\n",
      " 'Loss/regularization_loss': 0.27717006,\n",
      " 'Loss/total_loss': 0.58607435,\n",
      " 'learning_rate': 0.037333302}\n",
      "I1022 07:31:09.913605 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.17841947,\n",
      " 'Loss/localization_loss': 0.1304848,\n",
      " 'Loss/regularization_loss': 0.27717006,\n",
      " 'Loss/total_loss': 0.58607435,\n",
      " 'learning_rate': 0.037333302}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1900 per-step time 0.831s\n",
      "I1022 07:32:32.980927 139879681050496 model_lib_v2.py:707] Step 1900 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1605377,\n",
      " 'Loss/localization_loss': 0.10349086,\n",
      " 'Loss/regularization_loss': 0.27544236,\n",
      " 'Loss/total_loss': 0.5394709,\n",
      " 'learning_rate': 0.03866665}\n",
      "I1022 07:32:32.981257 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.1605377,\n",
      " 'Loss/localization_loss': 0.10349086,\n",
      " 'Loss/regularization_loss': 0.27544236,\n",
      " 'Loss/total_loss': 0.5394709,\n",
      " 'learning_rate': 0.03866665}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2000 per-step time 0.831s\n",
      "I1022 07:33:56.050264 139879681050496 model_lib_v2.py:707] Step 2000 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1504905,\n",
      " 'Loss/localization_loss': 0.114831515,\n",
      " 'Loss/regularization_loss': 0.27189884,\n",
      " 'Loss/total_loss': 0.53722084,\n",
      " 'learning_rate': 0.04}\n",
      "I1022 07:33:56.050655 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.1504905,\n",
      " 'Loss/localization_loss': 0.114831515,\n",
      " 'Loss/regularization_loss': 0.27189884,\n",
      " 'Loss/total_loss': 0.53722084,\n",
      " 'learning_rate': 0.04}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2100 per-step time 0.862s\n",
      "I1022 07:35:22.291359 139879681050496 model_lib_v2.py:707] Step 2100 per-step time 0.862s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12632363,\n",
      " 'Loss/localization_loss': 0.08182167,\n",
      " 'Loss/regularization_loss': 0.26994088,\n",
      " 'Loss/total_loss': 0.47808617,\n",
      " 'learning_rate': 0.039998136}\n",
      "I1022 07:35:22.291698 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.12632363,\n",
      " 'Loss/localization_loss': 0.08182167,\n",
      " 'Loss/regularization_loss': 0.26994088,\n",
      " 'Loss/total_loss': 0.47808617,\n",
      " 'learning_rate': 0.039998136}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2200 per-step time 0.829s\n",
      "I1022 07:36:45.178072 139879681050496 model_lib_v2.py:707] Step 2200 per-step time 0.829s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16678591,\n",
      " 'Loss/localization_loss': 0.123520724,\n",
      " 'Loss/regularization_loss': 0.26679808,\n",
      " 'Loss/total_loss': 0.5571047,\n",
      " 'learning_rate': 0.039992537}\n",
      "I1022 07:36:45.178420 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.16678591,\n",
      " 'Loss/localization_loss': 0.123520724,\n",
      " 'Loss/regularization_loss': 0.26679808,\n",
      " 'Loss/total_loss': 0.5571047,\n",
      " 'learning_rate': 0.039992537}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2300 per-step time 0.832s\n",
      "I1022 07:38:08.371856 139879681050496 model_lib_v2.py:707] Step 2300 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16662152,\n",
      " 'Loss/localization_loss': 0.11734111,\n",
      " 'Loss/regularization_loss': 0.2662069,\n",
      " 'Loss/total_loss': 0.5501695,\n",
      " 'learning_rate': 0.03998321}\n",
      "I1022 07:38:08.372262 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.16662152,\n",
      " 'Loss/localization_loss': 0.11734111,\n",
      " 'Loss/regularization_loss': 0.2662069,\n",
      " 'Loss/total_loss': 0.5501695,\n",
      " 'learning_rate': 0.03998321}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2400 per-step time 0.834s\n",
      "I1022 07:39:31.712033 139879681050496 model_lib_v2.py:707] Step 2400 per-step time 0.834s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14260265,\n",
      " 'Loss/localization_loss': 0.07625416,\n",
      " 'Loss/regularization_loss': 0.26332912,\n",
      " 'Loss/total_loss': 0.48218593,\n",
      " 'learning_rate': 0.039970152}\n",
      "I1022 07:39:31.712369 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.14260265,\n",
      " 'Loss/localization_loss': 0.07625416,\n",
      " 'Loss/regularization_loss': 0.26332912,\n",
      " 'Loss/total_loss': 0.48218593,\n",
      " 'learning_rate': 0.039970152}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2500 per-step time 0.832s\n",
      "I1022 07:40:54.917631 139879681050496 model_lib_v2.py:707] Step 2500 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1439301,\n",
      " 'Loss/localization_loss': 0.098952666,\n",
      " 'Loss/regularization_loss': 0.25969967,\n",
      " 'Loss/total_loss': 0.50258243,\n",
      " 'learning_rate': 0.039953373}\n",
      "I1022 07:40:54.917981 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.1439301,\n",
      " 'Loss/localization_loss': 0.098952666,\n",
      " 'Loss/regularization_loss': 0.25969967,\n",
      " 'Loss/total_loss': 0.50258243,\n",
      " 'learning_rate': 0.039953373}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2600 per-step time 0.832s\n",
      "I1022 07:42:18.159490 139879681050496 model_lib_v2.py:707] Step 2600 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12661192,\n",
      " 'Loss/localization_loss': 0.085133135,\n",
      " 'Loss/regularization_loss': 0.25703755,\n",
      " 'Loss/total_loss': 0.4687826,\n",
      " 'learning_rate': 0.03993287}\n",
      "I1022 07:42:18.159823 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.12661192,\n",
      " 'Loss/localization_loss': 0.085133135,\n",
      " 'Loss/regularization_loss': 0.25703755,\n",
      " 'Loss/total_loss': 0.4687826,\n",
      " 'learning_rate': 0.03993287}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2700 per-step time 0.832s\n",
      "I1022 07:43:41.310896 139879681050496 model_lib_v2.py:707] Step 2700 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11423855,\n",
      " 'Loss/localization_loss': 0.07662379,\n",
      " 'Loss/regularization_loss': 0.25340843,\n",
      " 'Loss/total_loss': 0.4442708,\n",
      " 'learning_rate': 0.039908648}\n",
      "I1022 07:43:41.311211 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.11423855,\n",
      " 'Loss/localization_loss': 0.07662379,\n",
      " 'Loss/regularization_loss': 0.25340843,\n",
      " 'Loss/total_loss': 0.4442708,\n",
      " 'learning_rate': 0.039908648}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2800 per-step time 0.833s\n",
      "I1022 07:45:04.613364 139879681050496 model_lib_v2.py:707] Step 2800 per-step time 0.833s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13516282,\n",
      " 'Loss/localization_loss': 0.07641197,\n",
      " 'Loss/regularization_loss': 0.25060192,\n",
      " 'Loss/total_loss': 0.4621767,\n",
      " 'learning_rate': 0.039880715}\n",
      "I1022 07:45:04.613721 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.13516282,\n",
      " 'Loss/localization_loss': 0.07641197,\n",
      " 'Loss/regularization_loss': 0.25060192,\n",
      " 'Loss/total_loss': 0.4621767,\n",
      " 'learning_rate': 0.039880715}\n",
      "INFO:tensorflow:Step 2900 per-step time 0.831s\n",
      "I1022 07:46:27.664805 139879681050496 model_lib_v2.py:707] Step 2900 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12650973,\n",
      " 'Loss/localization_loss': 0.07604483,\n",
      " 'Loss/regularization_loss': 0.24819703,\n",
      " 'Loss/total_loss': 0.4507516,\n",
      " 'learning_rate': 0.039849065}\n",
      "I1022 07:46:27.665149 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.12650973,\n",
      " 'Loss/localization_loss': 0.07604483,\n",
      " 'Loss/regularization_loss': 0.24819703,\n",
      " 'Loss/total_loss': 0.4507516,\n",
      " 'learning_rate': 0.039849065}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3000 per-step time 0.830s\n",
      "I1022 07:47:50.697926 139879681050496 model_lib_v2.py:707] Step 3000 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10897509,\n",
      " 'Loss/localization_loss': 0.071293965,\n",
      " 'Loss/regularization_loss': 0.24803473,\n",
      " 'Loss/total_loss': 0.42830378,\n",
      " 'learning_rate': 0.03981372}\n",
      "I1022 07:47:50.698230 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.10897509,\n",
      " 'Loss/localization_loss': 0.071293965,\n",
      " 'Loss/regularization_loss': 0.24803473,\n",
      " 'Loss/total_loss': 0.42830378,\n",
      " 'learning_rate': 0.03981372}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3100 per-step time 0.864s\n",
      "I1022 07:49:17.134488 139879681050496 model_lib_v2.py:707] Step 3100 per-step time 0.864s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12383219,\n",
      " 'Loss/localization_loss': 0.06266217,\n",
      " 'Loss/regularization_loss': 0.24485603,\n",
      " 'Loss/total_loss': 0.43135038,\n",
      " 'learning_rate': 0.03977467}\n",
      "I1022 07:49:17.134886 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.12383219,\n",
      " 'Loss/localization_loss': 0.06266217,\n",
      " 'Loss/regularization_loss': 0.24485603,\n",
      " 'Loss/total_loss': 0.43135038,\n",
      " 'learning_rate': 0.03977467}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3200 per-step time 0.829s\n",
      "I1022 07:50:40.062134 139879681050496 model_lib_v2.py:707] Step 3200 per-step time 0.829s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11662543,\n",
      " 'Loss/localization_loss': 0.059592925,\n",
      " 'Loss/regularization_loss': 0.2425488,\n",
      " 'Loss/total_loss': 0.41876715,\n",
      " 'learning_rate': 0.03973194}\n",
      "I1022 07:50:40.062471 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.11662543,\n",
      " 'Loss/localization_loss': 0.059592925,\n",
      " 'Loss/regularization_loss': 0.2425488,\n",
      " 'Loss/total_loss': 0.41876715,\n",
      " 'learning_rate': 0.03973194}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3300 per-step time 0.831s\n",
      "I1022 07:52:03.207960 139879681050496 model_lib_v2.py:707] Step 3300 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.115001336,\n",
      " 'Loss/localization_loss': 0.07273388,\n",
      " 'Loss/regularization_loss': 0.23981078,\n",
      " 'Loss/total_loss': 0.427546,\n",
      " 'learning_rate': 0.03968552}\n",
      "I1022 07:52:03.208272 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.115001336,\n",
      " 'Loss/localization_loss': 0.07273388,\n",
      " 'Loss/regularization_loss': 0.23981078,\n",
      " 'Loss/total_loss': 0.427546,\n",
      " 'learning_rate': 0.03968552}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3400 per-step time 0.831s\n",
      "I1022 07:53:26.315414 139879681050496 model_lib_v2.py:707] Step 3400 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11239237,\n",
      " 'Loss/localization_loss': 0.06790066,\n",
      " 'Loss/regularization_loss': 0.23668198,\n",
      " 'Loss/total_loss': 0.41697502,\n",
      " 'learning_rate': 0.039635435}\n",
      "I1022 07:53:26.315723 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.11239237,\n",
      " 'Loss/localization_loss': 0.06790066,\n",
      " 'Loss/regularization_loss': 0.23668198,\n",
      " 'Loss/total_loss': 0.41697502,\n",
      " 'learning_rate': 0.039635435}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3500 per-step time 0.831s\n",
      "I1022 07:54:49.406607 139879681050496 model_lib_v2.py:707] Step 3500 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14304635,\n",
      " 'Loss/localization_loss': 0.0787322,\n",
      " 'Loss/regularization_loss': 0.23337731,\n",
      " 'Loss/total_loss': 0.45515585,\n",
      " 'learning_rate': 0.03958168}\n",
      "I1022 07:54:49.406917 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.14304635,\n",
      " 'Loss/localization_loss': 0.0787322,\n",
      " 'Loss/regularization_loss': 0.23337731,\n",
      " 'Loss/total_loss': 0.45515585,\n",
      " 'learning_rate': 0.03958168}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3600 per-step time 0.830s\n",
      "I1022 07:56:12.361927 139879681050496 model_lib_v2.py:707] Step 3600 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12121208,\n",
      " 'Loss/localization_loss': 0.07389943,\n",
      " 'Loss/regularization_loss': 0.23367524,\n",
      " 'Loss/total_loss': 0.42878675,\n",
      " 'learning_rate': 0.039524276}\n",
      "I1022 07:56:12.362236 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.12121208,\n",
      " 'Loss/localization_loss': 0.07389943,\n",
      " 'Loss/regularization_loss': 0.23367524,\n",
      " 'Loss/total_loss': 0.42878675,\n",
      " 'learning_rate': 0.039524276}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3700 per-step time 0.830s\n",
      "I1022 07:57:35.401765 139879681050496 model_lib_v2.py:707] Step 3700 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1158313,\n",
      " 'Loss/localization_loss': 0.06560476,\n",
      " 'Loss/regularization_loss': 0.23124285,\n",
      " 'Loss/total_loss': 0.4126789,\n",
      " 'learning_rate': 0.03946323}\n",
      "I1022 07:57:35.402070 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.1158313,\n",
      " 'Loss/localization_loss': 0.06560476,\n",
      " 'Loss/regularization_loss': 0.23124285,\n",
      " 'Loss/total_loss': 0.4126789,\n",
      " 'learning_rate': 0.03946323}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3800 per-step time 0.830s\n",
      "I1022 07:58:58.428019 139879681050496 model_lib_v2.py:707] Step 3800 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09802219,\n",
      " 'Loss/localization_loss': 0.050235525,\n",
      " 'Loss/regularization_loss': 0.22819287,\n",
      " 'Loss/total_loss': 0.3764506,\n",
      " 'learning_rate': 0.039398547}\n",
      "I1022 07:58:58.428353 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.09802219,\n",
      " 'Loss/localization_loss': 0.050235525,\n",
      " 'Loss/regularization_loss': 0.22819287,\n",
      " 'Loss/total_loss': 0.3764506,\n",
      " 'learning_rate': 0.039398547}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3900 per-step time 0.831s\n",
      "I1022 08:00:21.554569 139879681050496 model_lib_v2.py:707] Step 3900 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13177182,\n",
      " 'Loss/localization_loss': 0.08326601,\n",
      " 'Loss/regularization_loss': 0.2265352,\n",
      " 'Loss/total_loss': 0.44157302,\n",
      " 'learning_rate': 0.039330248}\n",
      "I1022 08:00:21.554961 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.13177182,\n",
      " 'Loss/localization_loss': 0.08326601,\n",
      " 'Loss/regularization_loss': 0.2265352,\n",
      " 'Loss/total_loss': 0.44157302,\n",
      " 'learning_rate': 0.039330248}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4000 per-step time 0.830s\n",
      "I1022 08:01:44.580282 139879681050496 model_lib_v2.py:707] Step 4000 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14484939,\n",
      " 'Loss/localization_loss': 0.08458305,\n",
      " 'Loss/regularization_loss': 0.22519018,\n",
      " 'Loss/total_loss': 0.45462263,\n",
      " 'learning_rate': 0.039258346}\n",
      "I1022 08:01:44.580631 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.14484939,\n",
      " 'Loss/localization_loss': 0.08458305,\n",
      " 'Loss/regularization_loss': 0.22519018,\n",
      " 'Loss/total_loss': 0.45462263,\n",
      " 'learning_rate': 0.039258346}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4100 per-step time 0.868s\n",
      "I1022 08:03:11.396462 139879681050496 model_lib_v2.py:707] Step 4100 per-step time 0.868s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09288652,\n",
      " 'Loss/localization_loss': 0.039761636,\n",
      " 'Loss/regularization_loss': 0.22255816,\n",
      " 'Loss/total_loss': 0.3552063,\n",
      " 'learning_rate': 0.03918285}\n",
      "I1022 08:03:11.396773 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.09288652,\n",
      " 'Loss/localization_loss': 0.039761636,\n",
      " 'Loss/regularization_loss': 0.22255816,\n",
      " 'Loss/total_loss': 0.3552063,\n",
      " 'learning_rate': 0.03918285}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4200 per-step time 0.828s\n",
      "I1022 08:04:34.249456 139879681050496 model_lib_v2.py:707] Step 4200 per-step time 0.828s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09193174,\n",
      " 'Loss/localization_loss': 0.040900607,\n",
      " 'Loss/regularization_loss': 0.22034822,\n",
      " 'Loss/total_loss': 0.3531806,\n",
      " 'learning_rate': 0.03910377}\n",
      "I1022 08:04:34.249815 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.09193174,\n",
      " 'Loss/localization_loss': 0.040900607,\n",
      " 'Loss/regularization_loss': 0.22034822,\n",
      " 'Loss/total_loss': 0.3531806,\n",
      " 'learning_rate': 0.03910377}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4300 per-step time 0.834s\n",
      "I1022 08:05:57.619144 139879681050496 model_lib_v2.py:707] Step 4300 per-step time 0.834s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13346687,\n",
      " 'Loss/localization_loss': 0.070396334,\n",
      " 'Loss/regularization_loss': 0.21907604,\n",
      " 'Loss/total_loss': 0.42293924,\n",
      " 'learning_rate': 0.039021127}\n",
      "I1022 08:05:57.619460 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.13346687,\n",
      " 'Loss/localization_loss': 0.070396334,\n",
      " 'Loss/regularization_loss': 0.21907604,\n",
      " 'Loss/total_loss': 0.42293924,\n",
      " 'learning_rate': 0.039021127}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4400 per-step time 0.831s\n",
      "I1022 08:07:20.698074 139879681050496 model_lib_v2.py:707] Step 4400 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.08560679,\n",
      " 'Loss/localization_loss': 0.0419784,\n",
      " 'Loss/regularization_loss': 0.21642601,\n",
      " 'Loss/total_loss': 0.3440112,\n",
      " 'learning_rate': 0.03893494}\n",
      "I1022 08:07:20.698388 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.08560679,\n",
      " 'Loss/localization_loss': 0.0419784,\n",
      " 'Loss/regularization_loss': 0.21642601,\n",
      " 'Loss/total_loss': 0.3440112,\n",
      " 'learning_rate': 0.03893494}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4500 per-step time 0.830s\n",
      "I1022 08:08:43.718400 139879681050496 model_lib_v2.py:707] Step 4500 per-step time 0.830s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.09175523,\n",
      " 'Loss/localization_loss': 0.048504617,\n",
      " 'Loss/regularization_loss': 0.21354383,\n",
      " 'Loss/total_loss': 0.3538037,\n",
      " 'learning_rate': 0.03884522}\n",
      "I1022 08:08:43.718742 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.09175523,\n",
      " 'Loss/localization_loss': 0.048504617,\n",
      " 'Loss/regularization_loss': 0.21354383,\n",
      " 'Loss/total_loss': 0.3538037,\n",
      " 'learning_rate': 0.03884522}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4600 per-step time 0.832s\n",
      "I1022 08:10:06.878905 139879681050496 model_lib_v2.py:707] Step 4600 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11036381,\n",
      " 'Loss/localization_loss': 0.068062976,\n",
      " 'Loss/regularization_loss': 0.21070144,\n",
      " 'Loss/total_loss': 0.3891282,\n",
      " 'learning_rate': 0.03875198}\n",
      "I1022 08:10:06.879216 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.11036381,\n",
      " 'Loss/localization_loss': 0.068062976,\n",
      " 'Loss/regularization_loss': 0.21070144,\n",
      " 'Loss/total_loss': 0.3891282,\n",
      " 'learning_rate': 0.03875198}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4700 per-step time 0.831s\n",
      "I1022 08:11:30.045587 139879681050496 model_lib_v2.py:707] Step 4700 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.121919185,\n",
      " 'Loss/localization_loss': 0.08389178,\n",
      " 'Loss/regularization_loss': 0.20877494,\n",
      " 'Loss/total_loss': 0.4145859,\n",
      " 'learning_rate': 0.038655244}\n",
      "I1022 08:11:30.045999 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.121919185,\n",
      " 'Loss/localization_loss': 0.08389178,\n",
      " 'Loss/regularization_loss': 0.20877494,\n",
      " 'Loss/total_loss': 0.4145859,\n",
      " 'learning_rate': 0.038655244}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4800 per-step time 0.831s\n",
      "I1022 08:12:53.153850 139879681050496 model_lib_v2.py:707] Step 4800 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.092807606,\n",
      " 'Loss/localization_loss': 0.038678125,\n",
      " 'Loss/regularization_loss': 0.2071936,\n",
      " 'Loss/total_loss': 0.3386793,\n",
      " 'learning_rate': 0.038555026}\n",
      "I1022 08:12:53.154199 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.092807606,\n",
      " 'Loss/localization_loss': 0.038678125,\n",
      " 'Loss/regularization_loss': 0.2071936,\n",
      " 'Loss/total_loss': 0.3386793,\n",
      " 'learning_rate': 0.038555026}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4900 per-step time 0.832s\n",
      "I1022 08:14:16.380736 139879681050496 model_lib_v2.py:707] Step 4900 per-step time 0.832s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10224596,\n",
      " 'Loss/localization_loss': 0.03966514,\n",
      " 'Loss/regularization_loss': 0.2048985,\n",
      " 'Loss/total_loss': 0.3468096,\n",
      " 'learning_rate': 0.038451348}\n",
      "I1022 08:14:16.381047 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.10224596,\n",
      " 'Loss/localization_loss': 0.03966514,\n",
      " 'Loss/regularization_loss': 0.2048985,\n",
      " 'Loss/total_loss': 0.3468096,\n",
      " 'learning_rate': 0.038451348}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 5000 per-step time 0.831s\n",
      "I1022 08:15:39.533587 139879681050496 model_lib_v2.py:707] Step 5000 per-step time 0.831s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.07594406,\n",
      " 'Loss/localization_loss': 0.043222543,\n",
      " 'Loss/regularization_loss': 0.2028941,\n",
      " 'Loss/total_loss': 0.3220607,\n",
      " 'learning_rate': 0.038344227}\n",
      "I1022 08:15:39.533959 139879681050496 model_lib_v2.py:708] {'Loss/classification_loss': 0.07594406,\n",
      " 'Loss/localization_loss': 0.043222543,\n",
      " 'Loss/regularization_loss': 0.2028941,\n",
      " 'Loss/total_loss': 0.3220607,\n",
      " 'learning_rate': 0.038344227}\n"
     ]
    }
   ],
   "source": [
    "!{command2}#training model ssd_restnet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ULsRnGddd3Qp",
    "outputId": "5925c265-a5ae-4ee3-cee4-b5a9cfd55692"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 08:16:30.498083: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 08:16:32.315047: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 08:16:32.315893: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 08:16:32.315921: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "2022-10-22 08:16:40.174189: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I1022 08:16:40.204855 140525414066048 mirrored_strategy.py:374] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 5000\n",
      "I1022 08:16:40.211603 140525414066048 config_util.py:552] Maybe overwriting train_steps: 5000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 08:16:40.211765 140525414066048 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W1022 08:16:40.241138 140525414066048 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py:564: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 08:16:40.248225 140525414066048 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "I1022 08:16:40.248449 140525414066048 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/train.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 08:16:40.248543 140525414066048 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 08:16:40.248619 140525414066048 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 08:16:40.254668 140525414066048 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 08:16:40.271297 140525414066048 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 08:16:46.975223 140525414066048 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "W1022 08:16:49.804359 140525414066048 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sample_distorted_bounding_box (from tensorflow.python.ops.image_ops_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`seed2` arg is deprecated.Use sample_distorted_bounding_box_v2 instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 08:16:51.366430 140525414066048 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.680912 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.683967 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.686936 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.688158 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.691776 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.692904 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.696614 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.697721 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.700406 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I1022 08:17:22.701455 140525414066048 cross_device_ops.py:618] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "W1022 08:17:23.793449 140520961603328 deprecation.py:560] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/deprecation.py:629: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use fn_output_signature instead\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 100 per-step time 0.803s\n",
      "I1022 08:18:43.768594 140525414066048 model_lib_v2.py:707] Step 100 per-step time 0.803s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.3438223,\n",
      " 'Loss/localization_loss': 0.48876223,\n",
      " 'Loss/regularization_loss': 0.1513162,\n",
      " 'Loss/total_loss': 0.98390067,\n",
      " 'learning_rate': 0.0319994}\n",
      "I1022 08:18:43.769010 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.3438223,\n",
      " 'Loss/localization_loss': 0.48876223,\n",
      " 'Loss/regularization_loss': 0.1513162,\n",
      " 'Loss/total_loss': 0.98390067,\n",
      " 'learning_rate': 0.0319994}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 200 per-step time 0.385s\n",
      "I1022 08:19:22.196841 140525414066048 model_lib_v2.py:707] Step 200 per-step time 0.385s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.27512622,\n",
      " 'Loss/localization_loss': 0.32866278,\n",
      " 'Loss/regularization_loss': 0.15101817,\n",
      " 'Loss/total_loss': 0.7548071,\n",
      " 'learning_rate': 0.0373328}\n",
      "I1022 08:19:22.197210 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.27512622,\n",
      " 'Loss/localization_loss': 0.32866278,\n",
      " 'Loss/regularization_loss': 0.15101817,\n",
      " 'Loss/total_loss': 0.7548071,\n",
      " 'learning_rate': 0.0373328}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 300 per-step time 0.390s\n",
      "I1022 08:20:01.222112 140525414066048 model_lib_v2.py:707] Step 300 per-step time 0.390s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.23712069,\n",
      " 'Loss/localization_loss': 0.23779884,\n",
      " 'Loss/regularization_loss': 0.15070632,\n",
      " 'Loss/total_loss': 0.62562585,\n",
      " 'learning_rate': 0.0426662}\n",
      "I1022 08:20:01.222598 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.23712069,\n",
      " 'Loss/localization_loss': 0.23779884,\n",
      " 'Loss/regularization_loss': 0.15070632,\n",
      " 'Loss/total_loss': 0.62562585,\n",
      " 'learning_rate': 0.0426662}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 400 per-step time 0.434s\n",
      "I1022 08:20:44.611364 140525414066048 model_lib_v2.py:707] Step 400 per-step time 0.434s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21792588,\n",
      " 'Loss/localization_loss': 0.23698339,\n",
      " 'Loss/regularization_loss': 0.1503694,\n",
      " 'Loss/total_loss': 0.6052787,\n",
      " 'learning_rate': 0.047999598}\n",
      "I1022 08:20:44.611775 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.21792588,\n",
      " 'Loss/localization_loss': 0.23698339,\n",
      " 'Loss/regularization_loss': 0.1503694,\n",
      " 'Loss/total_loss': 0.6052787,\n",
      " 'learning_rate': 0.047999598}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 500 per-step time 0.401s\n",
      "I1022 08:21:24.702573 140525414066048 model_lib_v2.py:707] Step 500 per-step time 0.401s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21384913,\n",
      " 'Loss/localization_loss': 0.20985769,\n",
      " 'Loss/regularization_loss': 0.15001509,\n",
      " 'Loss/total_loss': 0.5737219,\n",
      " 'learning_rate': 0.053333}\n",
      "I1022 08:21:24.702936 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.21384913,\n",
      " 'Loss/localization_loss': 0.20985769,\n",
      " 'Loss/regularization_loss': 0.15001509,\n",
      " 'Loss/total_loss': 0.5737219,\n",
      " 'learning_rate': 0.053333}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 600 per-step time 0.387s\n",
      "I1022 08:22:03.437871 140525414066048 model_lib_v2.py:707] Step 600 per-step time 0.387s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21193102,\n",
      " 'Loss/localization_loss': 0.19041273,\n",
      " 'Loss/regularization_loss': 0.14963448,\n",
      " 'Loss/total_loss': 0.55197823,\n",
      " 'learning_rate': 0.0586664}\n",
      "I1022 08:22:03.438275 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.21193102,\n",
      " 'Loss/localization_loss': 0.19041273,\n",
      " 'Loss/regularization_loss': 0.14963448,\n",
      " 'Loss/total_loss': 0.55197823,\n",
      " 'learning_rate': 0.0586664}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 700 per-step time 0.436s\n",
      "I1022 08:22:47.010370 140525414066048 model_lib_v2.py:707] Step 700 per-step time 0.436s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22001687,\n",
      " 'Loss/localization_loss': 0.18140619,\n",
      " 'Loss/regularization_loss': 0.14926842,\n",
      " 'Loss/total_loss': 0.5506915,\n",
      " 'learning_rate': 0.0639998}\n",
      "I1022 08:22:47.010764 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.22001687,\n",
      " 'Loss/localization_loss': 0.18140619,\n",
      " 'Loss/regularization_loss': 0.14926842,\n",
      " 'Loss/total_loss': 0.5506915,\n",
      " 'learning_rate': 0.0639998}\n",
      "INFO:tensorflow:Step 800 per-step time 0.394s\n",
      "I1022 08:23:26.401469 140525414066048 model_lib_v2.py:707] Step 800 per-step time 0.394s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.22051013,\n",
      " 'Loss/localization_loss': 0.15678324,\n",
      " 'Loss/regularization_loss': 0.14888902,\n",
      " 'Loss/total_loss': 0.52618235,\n",
      " 'learning_rate': 0.069333196}\n",
      "I1022 08:23:26.401845 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.22051013,\n",
      " 'Loss/localization_loss': 0.15678324,\n",
      " 'Loss/regularization_loss': 0.14888902,\n",
      " 'Loss/total_loss': 0.52618235,\n",
      " 'learning_rate': 0.069333196}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 900 per-step time 0.393s\n",
      "I1022 08:24:05.708821 140525414066048 model_lib_v2.py:707] Step 900 per-step time 0.393s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1980735,\n",
      " 'Loss/localization_loss': 0.15877254,\n",
      " 'Loss/regularization_loss': 0.14852786,\n",
      " 'Loss/total_loss': 0.5053739,\n",
      " 'learning_rate': 0.074666604}\n",
      "I1022 08:24:05.709327 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.1980735,\n",
      " 'Loss/localization_loss': 0.15877254,\n",
      " 'Loss/regularization_loss': 0.14852786,\n",
      " 'Loss/total_loss': 0.5053739,\n",
      " 'learning_rate': 0.074666604}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1000 per-step time 0.429s\n",
      "I1022 08:24:48.635200 140525414066048 model_lib_v2.py:707] Step 1000 per-step time 0.429s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.2392923,\n",
      " 'Loss/localization_loss': 0.20119645,\n",
      " 'Loss/regularization_loss': 0.14808063,\n",
      " 'Loss/total_loss': 0.5885694,\n",
      " 'learning_rate': 0.08}\n",
      "I1022 08:24:48.636220 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.2392923,\n",
      " 'Loss/localization_loss': 0.20119645,\n",
      " 'Loss/regularization_loss': 0.14808063,\n",
      " 'Loss/total_loss': 0.5885694,\n",
      " 'learning_rate': 0.08}\n",
      "INFO:tensorflow:Step 1100 per-step time 0.405s\n",
      "I1022 08:25:29.144641 140525414066048 model_lib_v2.py:707] Step 1100 per-step time 0.405s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18097553,\n",
      " 'Loss/localization_loss': 0.14564691,\n",
      " 'Loss/regularization_loss': 0.1476527,\n",
      " 'Loss/total_loss': 0.4742751,\n",
      " 'learning_rate': 0.07999918}\n",
      "I1022 08:25:29.144994 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.18097553,\n",
      " 'Loss/localization_loss': 0.14564691,\n",
      " 'Loss/regularization_loss': 0.1476527,\n",
      " 'Loss/total_loss': 0.4742751,\n",
      " 'learning_rate': 0.07999918}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1200 per-step time 0.384s\n",
      "I1022 08:26:07.516452 140525414066048 model_lib_v2.py:707] Step 1200 per-step time 0.384s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.19227201,\n",
      " 'Loss/localization_loss': 0.1519817,\n",
      " 'Loss/regularization_loss': 0.14720266,\n",
      " 'Loss/total_loss': 0.4914564,\n",
      " 'learning_rate': 0.079996705}\n",
      "I1022 08:26:07.516825 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.19227201,\n",
      " 'Loss/localization_loss': 0.1519817,\n",
      " 'Loss/regularization_loss': 0.14720266,\n",
      " 'Loss/total_loss': 0.4914564,\n",
      " 'learning_rate': 0.079996705}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1300 per-step time 0.410s\n",
      "I1022 08:26:48.565726 140525414066048 model_lib_v2.py:707] Step 1300 per-step time 0.410s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17343895,\n",
      " 'Loss/localization_loss': 0.13916576,\n",
      " 'Loss/regularization_loss': 0.14675908,\n",
      " 'Loss/total_loss': 0.45936382,\n",
      " 'learning_rate': 0.0799926}\n",
      "I1022 08:26:48.566181 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.17343895,\n",
      " 'Loss/localization_loss': 0.13916576,\n",
      " 'Loss/regularization_loss': 0.14675908,\n",
      " 'Loss/total_loss': 0.45936382,\n",
      " 'learning_rate': 0.0799926}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1400 per-step time 0.426s\n",
      "I1022 08:27:31.168790 140525414066048 model_lib_v2.py:707] Step 1400 per-step time 0.426s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.17316994,\n",
      " 'Loss/localization_loss': 0.15125245,\n",
      " 'Loss/regularization_loss': 0.14628868,\n",
      " 'Loss/total_loss': 0.47071105,\n",
      " 'learning_rate': 0.07998685}\n",
      "I1022 08:27:31.169159 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.17316994,\n",
      " 'Loss/localization_loss': 0.15125245,\n",
      " 'Loss/regularization_loss': 0.14628868,\n",
      " 'Loss/total_loss': 0.47071105,\n",
      " 'learning_rate': 0.07998685}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1500 per-step time 0.405s\n",
      "I1022 08:28:11.695880 140525414066048 model_lib_v2.py:707] Step 1500 per-step time 0.405s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1930885,\n",
      " 'Loss/localization_loss': 0.14556152,\n",
      " 'Loss/regularization_loss': 0.14588512,\n",
      " 'Loss/total_loss': 0.48453516,\n",
      " 'learning_rate': 0.07997945}\n",
      "I1022 08:28:11.696369 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.1930885,\n",
      " 'Loss/localization_loss': 0.14556152,\n",
      " 'Loss/regularization_loss': 0.14588512,\n",
      " 'Loss/total_loss': 0.48453516,\n",
      " 'learning_rate': 0.07997945}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1600 per-step time 0.395s\n",
      "I1022 08:28:51.174097 140525414066048 model_lib_v2.py:707] Step 1600 per-step time 0.395s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14093411,\n",
      " 'Loss/localization_loss': 0.10598748,\n",
      " 'Loss/regularization_loss': 0.14543135,\n",
      " 'Loss/total_loss': 0.39235294,\n",
      " 'learning_rate': 0.079970405}\n",
      "I1022 08:28:51.174486 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.14093411,\n",
      " 'Loss/localization_loss': 0.10598748,\n",
      " 'Loss/regularization_loss': 0.14543135,\n",
      " 'Loss/total_loss': 0.39235294,\n",
      " 'learning_rate': 0.079970405}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1700 per-step time 0.445s\n",
      "I1022 08:29:35.636950 140525414066048 model_lib_v2.py:707] Step 1700 per-step time 0.445s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.18064375,\n",
      " 'Loss/localization_loss': 0.1452112,\n",
      " 'Loss/regularization_loss': 0.14501756,\n",
      " 'Loss/total_loss': 0.47087252,\n",
      " 'learning_rate': 0.07995972}\n",
      "I1022 08:29:35.637333 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.18064375,\n",
      " 'Loss/localization_loss': 0.1452112,\n",
      " 'Loss/regularization_loss': 0.14501756,\n",
      " 'Loss/total_loss': 0.47087252,\n",
      " 'learning_rate': 0.07995972}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1800 per-step time 0.397s\n",
      "I1022 08:30:15.335830 140525414066048 model_lib_v2.py:707] Step 1800 per-step time 0.397s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.21031162,\n",
      " 'Loss/localization_loss': 0.14690556,\n",
      " 'Loss/regularization_loss': 0.1445187,\n",
      " 'Loss/total_loss': 0.5017359,\n",
      " 'learning_rate': 0.0799474}\n",
      "I1022 08:30:15.336334 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.21031162,\n",
      " 'Loss/localization_loss': 0.14690556,\n",
      " 'Loss/regularization_loss': 0.1445187,\n",
      " 'Loss/total_loss': 0.5017359,\n",
      " 'learning_rate': 0.0799474}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 1900 per-step time 0.406s\n",
      "I1022 08:30:55.904014 140525414066048 model_lib_v2.py:707] Step 1900 per-step time 0.406s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.20601183,\n",
      " 'Loss/localization_loss': 0.1940493,\n",
      " 'Loss/regularization_loss': 0.14413789,\n",
      " 'Loss/total_loss': 0.544199,\n",
      " 'learning_rate': 0.07993342}\n",
      "I1022 08:30:55.904417 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.20601183,\n",
      " 'Loss/localization_loss': 0.1940493,\n",
      " 'Loss/regularization_loss': 0.14413789,\n",
      " 'Loss/total_loss': 0.544199,\n",
      " 'learning_rate': 0.07993342}\n",
      "INFO:tensorflow:Step 2000 per-step time 0.437s\n",
      "I1022 08:31:39.630940 140525414066048 model_lib_v2.py:707] Step 2000 per-step time 0.437s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1478098,\n",
      " 'Loss/localization_loss': 0.11282443,\n",
      " 'Loss/regularization_loss': 0.14367674,\n",
      " 'Loss/total_loss': 0.404311,\n",
      " 'learning_rate': 0.07991781}\n",
      "I1022 08:31:39.631298 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.1478098,\n",
      " 'Loss/localization_loss': 0.11282443,\n",
      " 'Loss/regularization_loss': 0.14367674,\n",
      " 'Loss/total_loss': 0.404311,\n",
      " 'learning_rate': 0.07991781}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2100 per-step time 0.408s\n",
      "I1022 08:32:20.454411 140525414066048 model_lib_v2.py:707] Step 2100 per-step time 0.408s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.16171753,\n",
      " 'Loss/localization_loss': 0.13802294,\n",
      " 'Loss/regularization_loss': 0.14314714,\n",
      " 'Loss/total_loss': 0.44288763,\n",
      " 'learning_rate': 0.07990056}\n",
      "I1022 08:32:20.454823 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.16171753,\n",
      " 'Loss/localization_loss': 0.13802294,\n",
      " 'Loss/regularization_loss': 0.14314714,\n",
      " 'Loss/total_loss': 0.44288763,\n",
      " 'learning_rate': 0.07990056}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2200 per-step time 0.392s\n",
      "I1022 08:32:59.687992 140525414066048 model_lib_v2.py:707] Step 2200 per-step time 0.392s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13764937,\n",
      " 'Loss/localization_loss': 0.08955069,\n",
      " 'Loss/regularization_loss': 0.14264598,\n",
      " 'Loss/total_loss': 0.36984605,\n",
      " 'learning_rate': 0.07988167}\n",
      "I1022 08:32:59.688430 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.13764937,\n",
      " 'Loss/localization_loss': 0.08955069,\n",
      " 'Loss/regularization_loss': 0.14264598,\n",
      " 'Loss/total_loss': 0.36984605,\n",
      " 'learning_rate': 0.07988167}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2300 per-step time 0.389s\n",
      "I1022 08:33:38.584336 140525414066048 model_lib_v2.py:707] Step 2300 per-step time 0.389s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13642833,\n",
      " 'Loss/localization_loss': 0.11173704,\n",
      " 'Loss/regularization_loss': 0.14214547,\n",
      " 'Loss/total_loss': 0.39031082,\n",
      " 'learning_rate': 0.07986114}\n",
      "I1022 08:33:38.584726 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.13642833,\n",
      " 'Loss/localization_loss': 0.11173704,\n",
      " 'Loss/regularization_loss': 0.14214547,\n",
      " 'Loss/total_loss': 0.39031082,\n",
      " 'learning_rate': 0.07986114}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2400 per-step time 0.461s\n",
      "I1022 08:34:24.720248 140525414066048 model_lib_v2.py:707] Step 2400 per-step time 0.461s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.15837803,\n",
      " 'Loss/localization_loss': 0.13044882,\n",
      " 'Loss/regularization_loss': 0.14159718,\n",
      " 'Loss/total_loss': 0.43042403,\n",
      " 'learning_rate': 0.07983897}\n",
      "I1022 08:34:24.720643 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.15837803,\n",
      " 'Loss/localization_loss': 0.13044882,\n",
      " 'Loss/regularization_loss': 0.14159718,\n",
      " 'Loss/total_loss': 0.43042403,\n",
      " 'learning_rate': 0.07983897}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2500 per-step time 0.399s\n",
      "I1022 08:35:04.609665 140525414066048 model_lib_v2.py:707] Step 2500 per-step time 0.399s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13694467,\n",
      " 'Loss/localization_loss': 0.11595314,\n",
      " 'Loss/regularization_loss': 0.1410631,\n",
      " 'Loss/total_loss': 0.3939609,\n",
      " 'learning_rate': 0.079815164}\n",
      "I1022 08:35:04.610328 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.13694467,\n",
      " 'Loss/localization_loss': 0.11595314,\n",
      " 'Loss/regularization_loss': 0.1410631,\n",
      " 'Loss/total_loss': 0.3939609,\n",
      " 'learning_rate': 0.079815164}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2600 per-step time 0.396s\n",
      "I1022 08:35:44.178110 140525414066048 model_lib_v2.py:707] Step 2600 per-step time 0.396s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14988247,\n",
      " 'Loss/localization_loss': 0.09409117,\n",
      " 'Loss/regularization_loss': 0.14052862,\n",
      " 'Loss/total_loss': 0.38450226,\n",
      " 'learning_rate': 0.07978972}\n",
      "I1022 08:35:44.178515 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.14988247,\n",
      " 'Loss/localization_loss': 0.09409117,\n",
      " 'Loss/regularization_loss': 0.14052862,\n",
      " 'Loss/total_loss': 0.38450226,\n",
      " 'learning_rate': 0.07978972}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2700 per-step time 0.438s\n",
      "I1022 08:36:27.962055 140525414066048 model_lib_v2.py:707] Step 2700 per-step time 0.438s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13587989,\n",
      " 'Loss/localization_loss': 0.104847826,\n",
      " 'Loss/regularization_loss': 0.14005439,\n",
      " 'Loss/total_loss': 0.38078213,\n",
      " 'learning_rate': 0.07976264}\n",
      "I1022 08:36:27.962528 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.13587989,\n",
      " 'Loss/localization_loss': 0.104847826,\n",
      " 'Loss/regularization_loss': 0.14005439,\n",
      " 'Loss/total_loss': 0.38078213,\n",
      " 'learning_rate': 0.07976264}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2800 per-step time 0.396s\n",
      "I1022 08:37:07.568414 140525414066048 model_lib_v2.py:707] Step 2800 per-step time 0.396s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1370515,\n",
      " 'Loss/localization_loss': 0.09958906,\n",
      " 'Loss/regularization_loss': 0.13958341,\n",
      " 'Loss/total_loss': 0.37622395,\n",
      " 'learning_rate': 0.07973392}\n",
      "I1022 08:37:07.568879 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.1370515,\n",
      " 'Loss/localization_loss': 0.09958906,\n",
      " 'Loss/regularization_loss': 0.13958341,\n",
      " 'Loss/total_loss': 0.37622395,\n",
      " 'learning_rate': 0.07973392}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 2900 per-step time 0.417s\n",
      "I1022 08:37:49.299717 140525414066048 model_lib_v2.py:707] Step 2900 per-step time 0.417s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12913522,\n",
      " 'Loss/localization_loss': 0.08833077,\n",
      " 'Loss/regularization_loss': 0.13907732,\n",
      " 'Loss/total_loss': 0.3565433,\n",
      " 'learning_rate': 0.07970358}\n",
      "I1022 08:37:49.300156 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12913522,\n",
      " 'Loss/localization_loss': 0.08833077,\n",
      " 'Loss/regularization_loss': 0.13907732,\n",
      " 'Loss/total_loss': 0.3565433,\n",
      " 'learning_rate': 0.07970358}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3000 per-step time 0.444s\n",
      "I1022 08:38:33.763848 140525414066048 model_lib_v2.py:707] Step 3000 per-step time 0.444s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14529026,\n",
      " 'Loss/localization_loss': 0.0975895,\n",
      " 'Loss/regularization_loss': 0.1385943,\n",
      " 'Loss/total_loss': 0.38147405,\n",
      " 'learning_rate': 0.0796716}\n",
      "I1022 08:38:33.764255 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.14529026,\n",
      " 'Loss/localization_loss': 0.0975895,\n",
      " 'Loss/regularization_loss': 0.1385943,\n",
      " 'Loss/total_loss': 0.38147405,\n",
      " 'learning_rate': 0.0796716}\n",
      "INFO:tensorflow:Step 3100 per-step time 0.393s\n",
      "I1022 08:39:13.052479 140525414066048 model_lib_v2.py:707] Step 3100 per-step time 0.393s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14999537,\n",
      " 'Loss/localization_loss': 0.09613367,\n",
      " 'Loss/regularization_loss': 0.1381027,\n",
      " 'Loss/total_loss': 0.38423175,\n",
      " 'learning_rate': 0.07963799}\n",
      "I1022 08:39:13.052859 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.14999537,\n",
      " 'Loss/localization_loss': 0.09613367,\n",
      " 'Loss/regularization_loss': 0.1381027,\n",
      " 'Loss/total_loss': 0.38423175,\n",
      " 'learning_rate': 0.07963799}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3200 per-step time 0.411s\n",
      "I1022 08:39:54.188051 140525414066048 model_lib_v2.py:707] Step 3200 per-step time 0.411s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11946576,\n",
      " 'Loss/localization_loss': 0.06680734,\n",
      " 'Loss/regularization_loss': 0.13764901,\n",
      " 'Loss/total_loss': 0.3239221,\n",
      " 'learning_rate': 0.07960275}\n",
      "I1022 08:39:54.188459 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.11946576,\n",
      " 'Loss/localization_loss': 0.06680734,\n",
      " 'Loss/regularization_loss': 0.13764901,\n",
      " 'Loss/total_loss': 0.3239221,\n",
      " 'learning_rate': 0.07960275}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3300 per-step time 0.425s\n",
      "I1022 08:40:36.728411 140525414066048 model_lib_v2.py:707] Step 3300 per-step time 0.425s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11813853,\n",
      " 'Loss/localization_loss': 0.07599521,\n",
      " 'Loss/regularization_loss': 0.13714638,\n",
      " 'Loss/total_loss': 0.3312801,\n",
      " 'learning_rate': 0.07956588}\n",
      "I1022 08:40:36.728806 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.11813853,\n",
      " 'Loss/localization_loss': 0.07599521,\n",
      " 'Loss/regularization_loss': 0.13714638,\n",
      " 'Loss/total_loss': 0.3312801,\n",
      " 'learning_rate': 0.07956588}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3400 per-step time 0.410s\n",
      "I1022 08:41:17.742395 140525414066048 model_lib_v2.py:707] Step 3400 per-step time 0.410s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13763309,\n",
      " 'Loss/localization_loss': 0.09047551,\n",
      " 'Loss/regularization_loss': 0.13662173,\n",
      " 'Loss/total_loss': 0.3647303,\n",
      " 'learning_rate': 0.079527386}\n",
      "I1022 08:41:17.749789 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.13763309,\n",
      " 'Loss/localization_loss': 0.09047551,\n",
      " 'Loss/regularization_loss': 0.13662173,\n",
      " 'Loss/total_loss': 0.3647303,\n",
      " 'learning_rate': 0.079527386}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3500 per-step time 0.385s\n",
      "I1022 08:41:56.209177 140525414066048 model_lib_v2.py:707] Step 3500 per-step time 0.385s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14120394,\n",
      " 'Loss/localization_loss': 0.09000268,\n",
      " 'Loss/regularization_loss': 0.13611539,\n",
      " 'Loss/total_loss': 0.36732203,\n",
      " 'learning_rate': 0.07948727}\n",
      "I1022 08:41:56.209602 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.14120394,\n",
      " 'Loss/localization_loss': 0.09000268,\n",
      " 'Loss/regularization_loss': 0.13611539,\n",
      " 'Loss/total_loss': 0.36732203,\n",
      " 'learning_rate': 0.07948727}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3600 per-step time 0.407s\n",
      "I1022 08:42:36.941426 140525414066048 model_lib_v2.py:707] Step 3600 per-step time 0.407s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12713811,\n",
      " 'Loss/localization_loss': 0.08550117,\n",
      " 'Loss/regularization_loss': 0.13558374,\n",
      " 'Loss/total_loss': 0.34822303,\n",
      " 'learning_rate': 0.079445526}\n",
      "I1022 08:42:36.941816 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12713811,\n",
      " 'Loss/localization_loss': 0.08550117,\n",
      " 'Loss/regularization_loss': 0.13558374,\n",
      " 'Loss/total_loss': 0.34822303,\n",
      " 'learning_rate': 0.079445526}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3700 per-step time 0.439s\n",
      "I1022 08:43:20.814078 140525414066048 model_lib_v2.py:707] Step 3700 per-step time 0.439s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10903574,\n",
      " 'Loss/localization_loss': 0.05859272,\n",
      " 'Loss/regularization_loss': 0.13505958,\n",
      " 'Loss/total_loss': 0.30268806,\n",
      " 'learning_rate': 0.07940216}\n",
      "I1022 08:43:20.814546 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.10903574,\n",
      " 'Loss/localization_loss': 0.05859272,\n",
      " 'Loss/regularization_loss': 0.13505958,\n",
      " 'Loss/total_loss': 0.30268806,\n",
      " 'learning_rate': 0.07940216}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3800 per-step time 0.400s\n",
      "I1022 08:44:00.823457 140525414066048 model_lib_v2.py:707] Step 3800 per-step time 0.400s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12217634,\n",
      " 'Loss/localization_loss': 0.07037391,\n",
      " 'Loss/regularization_loss': 0.13455956,\n",
      " 'Loss/total_loss': 0.3271098,\n",
      " 'learning_rate': 0.079357184}\n",
      "I1022 08:44:00.823873 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12217634,\n",
      " 'Loss/localization_loss': 0.07037391,\n",
      " 'Loss/regularization_loss': 0.13455956,\n",
      " 'Loss/total_loss': 0.3271098,\n",
      " 'learning_rate': 0.079357184}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 3900 per-step time 0.401s\n",
      "I1022 08:44:40.920809 140525414066048 model_lib_v2.py:707] Step 3900 per-step time 0.401s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.14481393,\n",
      " 'Loss/localization_loss': 0.09681995,\n",
      " 'Loss/regularization_loss': 0.13406794,\n",
      " 'Loss/total_loss': 0.3757018,\n",
      " 'learning_rate': 0.07931058}\n",
      "I1022 08:44:40.921190 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.14481393,\n",
      " 'Loss/localization_loss': 0.09681995,\n",
      " 'Loss/regularization_loss': 0.13406794,\n",
      " 'Loss/total_loss': 0.3757018,\n",
      " 'learning_rate': 0.07931058}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4000 per-step time 0.442s\n",
      "I1022 08:45:25.096124 140525414066048 model_lib_v2.py:707] Step 4000 per-step time 0.442s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.091286264,\n",
      " 'Loss/localization_loss': 0.052766953,\n",
      " 'Loss/regularization_loss': 0.13358371,\n",
      " 'Loss/total_loss': 0.27763695,\n",
      " 'learning_rate': 0.07926236}\n",
      "I1022 08:45:25.096596 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.091286264,\n",
      " 'Loss/localization_loss': 0.052766953,\n",
      " 'Loss/regularization_loss': 0.13358371,\n",
      " 'Loss/total_loss': 0.27763695,\n",
      " 'learning_rate': 0.07926236}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4100 per-step time 0.398s\n",
      "I1022 08:46:04.923230 140525414066048 model_lib_v2.py:707] Step 4100 per-step time 0.398s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12385262,\n",
      " 'Loss/localization_loss': 0.084478356,\n",
      " 'Loss/regularization_loss': 0.13308446,\n",
      " 'Loss/total_loss': 0.34141544,\n",
      " 'learning_rate': 0.07921253}\n",
      "I1022 08:46:04.923666 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12385262,\n",
      " 'Loss/localization_loss': 0.084478356,\n",
      " 'Loss/regularization_loss': 0.13308446,\n",
      " 'Loss/total_loss': 0.34141544,\n",
      " 'learning_rate': 0.07921253}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4200 per-step time 0.403s\n",
      "I1022 08:46:45.199124 140525414066048 model_lib_v2.py:707] Step 4200 per-step time 0.403s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12716748,\n",
      " 'Loss/localization_loss': 0.08877495,\n",
      " 'Loss/regularization_loss': 0.13262549,\n",
      " 'Loss/total_loss': 0.3485679,\n",
      " 'learning_rate': 0.07916109}\n",
      "I1022 08:46:45.199545 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12716748,\n",
      " 'Loss/localization_loss': 0.08877495,\n",
      " 'Loss/regularization_loss': 0.13262549,\n",
      " 'Loss/total_loss': 0.3485679,\n",
      " 'learning_rate': 0.07916109}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4300 per-step time 0.447s\n",
      "I1022 08:47:29.887127 140525414066048 model_lib_v2.py:707] Step 4300 per-step time 0.447s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1333708,\n",
      " 'Loss/localization_loss': 0.07785837,\n",
      " 'Loss/regularization_loss': 0.13213177,\n",
      " 'Loss/total_loss': 0.34336096,\n",
      " 'learning_rate': 0.07910804}\n",
      "I1022 08:47:29.887498 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.1333708,\n",
      " 'Loss/localization_loss': 0.07785837,\n",
      " 'Loss/regularization_loss': 0.13213177,\n",
      " 'Loss/total_loss': 0.34336096,\n",
      " 'learning_rate': 0.07910804}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4400 per-step time 0.407s\n",
      "I1022 08:48:10.585683 140525414066048 model_lib_v2.py:707] Step 4400 per-step time 0.407s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.10802802,\n",
      " 'Loss/localization_loss': 0.06383533,\n",
      " 'Loss/regularization_loss': 0.13174272,\n",
      " 'Loss/total_loss': 0.30360606,\n",
      " 'learning_rate': 0.07905338}\n",
      "I1022 08:48:10.586097 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.10802802,\n",
      " 'Loss/localization_loss': 0.06383533,\n",
      " 'Loss/regularization_loss': 0.13174272,\n",
      " 'Loss/total_loss': 0.30360606,\n",
      " 'learning_rate': 0.07905338}\n",
      "INFO:tensorflow:Step 4500 per-step time 0.402s\n",
      "I1022 08:48:50.766477 140525414066048 model_lib_v2.py:707] Step 4500 per-step time 0.402s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.13216874,\n",
      " 'Loss/localization_loss': 0.0925746,\n",
      " 'Loss/regularization_loss': 0.13125093,\n",
      " 'Loss/total_loss': 0.35599428,\n",
      " 'learning_rate': 0.07899711}\n",
      "I1022 08:48:50.766865 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.13216874,\n",
      " 'Loss/localization_loss': 0.0925746,\n",
      " 'Loss/regularization_loss': 0.13125093,\n",
      " 'Loss/total_loss': 0.35599428,\n",
      " 'learning_rate': 0.07899711}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4600 per-step time 0.439s\n",
      "I1022 08:49:34.684883 140525414066048 model_lib_v2.py:707] Step 4600 per-step time 0.439s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11730804,\n",
      " 'Loss/localization_loss': 0.06938836,\n",
      " 'Loss/regularization_loss': 0.13077572,\n",
      " 'Loss/total_loss': 0.31747213,\n",
      " 'learning_rate': 0.078939244}\n",
      "I1022 08:49:34.685268 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.11730804,\n",
      " 'Loss/localization_loss': 0.06938836,\n",
      " 'Loss/regularization_loss': 0.13077572,\n",
      " 'Loss/total_loss': 0.31747213,\n",
      " 'learning_rate': 0.078939244}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4700 per-step time 0.402s\n",
      "I1022 08:50:14.844967 140525414066048 model_lib_v2.py:707] Step 4700 per-step time 0.402s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12022225,\n",
      " 'Loss/localization_loss': 0.072994314,\n",
      " 'Loss/regularization_loss': 0.1302751,\n",
      " 'Loss/total_loss': 0.32349166,\n",
      " 'learning_rate': 0.07887978}\n",
      "I1022 08:50:14.845458 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12022225,\n",
      " 'Loss/localization_loss': 0.072994314,\n",
      " 'Loss/regularization_loss': 0.1302751,\n",
      " 'Loss/total_loss': 0.32349166,\n",
      " 'learning_rate': 0.07887978}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4800 per-step time 0.412s\n",
      "I1022 08:50:56.082613 140525414066048 model_lib_v2.py:707] Step 4800 per-step time 0.412s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.12228542,\n",
      " 'Loss/localization_loss': 0.083615534,\n",
      " 'Loss/regularization_loss': 0.12979692,\n",
      " 'Loss/total_loss': 0.3356979,\n",
      " 'learning_rate': 0.07881871}\n",
      "I1022 08:50:56.083038 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.12228542,\n",
      " 'Loss/localization_loss': 0.083615534,\n",
      " 'Loss/regularization_loss': 0.12979692,\n",
      " 'Loss/total_loss': 0.3356979,\n",
      " 'learning_rate': 0.07881871}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 4900 per-step time 0.406s\n",
      "I1022 08:51:36.719670 140525414066048 model_lib_v2.py:707] Step 4900 per-step time 0.406s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.1328084,\n",
      " 'Loss/localization_loss': 0.093810126,\n",
      " 'Loss/regularization_loss': 0.12930267,\n",
      " 'Loss/total_loss': 0.3559212,\n",
      " 'learning_rate': 0.07875605}\n",
      "I1022 08:51:36.720081 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.1328084,\n",
      " 'Loss/localization_loss': 0.093810126,\n",
      " 'Loss/regularization_loss': 0.12930267,\n",
      " 'Loss/total_loss': 0.3559212,\n",
      " 'learning_rate': 0.07875605}\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "Corrupt JPEG data: 12658 extraneous bytes before marker 0xd2\n",
      "INFO:tensorflow:Step 5000 per-step time 0.450s\n",
      "I1022 08:52:21.779984 140525414066048 model_lib_v2.py:707] Step 5000 per-step time 0.450s\n",
      "INFO:tensorflow:{'Loss/classification_loss': 0.11165063,\n",
      " 'Loss/localization_loss': 0.063766755,\n",
      " 'Loss/regularization_loss': 0.12881169,\n",
      " 'Loss/total_loss': 0.30422908,\n",
      " 'learning_rate': 0.078691795}\n",
      "I1022 08:52:21.780869 140525414066048 model_lib_v2.py:708] {'Loss/classification_loss': 0.11165063,\n",
      " 'Loss/localization_loss': 0.063766755,\n",
      " 'Loss/regularization_loss': 0.12881169,\n",
      " 'Loss/total_loss': 0.30422908,\n",
      " 'learning_rate': 0.078691795}\n"
     ]
    }
   ],
   "source": [
    "!{command3} #training model ssd_mobilenet_v2_fpnlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4_YRZu7npfDH"
   },
   "source": [
    "# Evaluate the Model\n",
    "Firstly, let’s start with a brief explanation of what the evaluation process does. While the training process runs, it will occasionally create checkpoint files inside the training_demo/training folder, which correspond to snapshots of the model at given steps. When a set of such new checkpoint files is generated, the evaluation process uses these files and evaluates how well the model performs in detecting objects in the test dataset. The results of this evaluation are summarised in the form of some metrics, which can be examined over time.# 7. Evaluate the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "80L7-fdPpfDH"
   },
   "outputs": [],
   "source": [
    "command = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH'],files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'])\n",
    "\n",
    "command2 = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH2'],files['PIPELINE_CONFIG2'], paths['CHECKPOINT_PATH2'])\n",
    "\n",
    "command3 = \"python {} --model_dir={} --pipeline_config_path={} --checkpoint_dir={}\".format(TRAINING_SCRIPT, paths['CHECKPOINT_PATH3'],files['PIPELINE_CONFIG3'], paths['CHECKPOINT_PATH3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lYsgEPx9pfDH",
    "outputId": "5224fa12-4a08-4c5b-9ffd-01d02e102c87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet_v1 --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet_v1/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/ssd_mobilenet_v1\n",
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_resnet101_v1 --pipeline_config_path=Tensorflow/workspace/models/ssd_resnet101_v1/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/ssd_resnet101_v1\n",
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/pipeline.config --checkpoint_dir=Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite\n"
     ]
    }
   ],
   "source": [
    "print(command)\n",
    "print(command2)\n",
    "print(command3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lqTV2jGBpfDH",
    "outputId": "a19a7651-22d8-4141-fc09-7af209a48653"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 08:52:28.991832: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 08:52:29.899650: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 08:52:29.899831: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 08:52:29.899855: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1022 08:52:32.532302 139779506169728 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I1022 08:52:32.532544 139779506169728 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 08:52:32.532632 139779506169728 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1022 08:52:32.532715 139779506169728 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1022 08:52:32.532831 139779506169728 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-10-22 08:52:33.357315: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "I1022 08:52:33.405523 139779506169728 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "I1022 08:52:33.405792 139779506169728 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 08:52:33.405896 139779506169728 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 08:52:33.405968 139779506169728 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 08:52:33.409167 139779506169728 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 08:52:33.426579 139779506169728 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 08:52:37.245789 139779506169728 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 08:52:38.346986 139779506169728 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v1\n",
      "I1022 08:52:40.785556 139779506169728 checkpoint_utils.py:142] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v1\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v1/ckpt-6\n",
      "I1022 08:52:40.787784 139779506169728 checkpoint_utils.py:151] Found new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v1/ckpt-6\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 08:53:04.833173 139779506169728 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I1022 08:53:04.860365 139779506169728 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W1022 08:53:05.232712 139779506169728 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 36 images.\n",
      "I1022 08:55:02.976320 139779506169728 coco_evaluation.py:293] Performing evaluation on 36 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1022 08:55:02.978391 139779506169728 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I1022 08:55:02.980286 139779506169728 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.66s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.213\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.419\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.194\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.038\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.240\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.348\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.076\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.392\n",
      "INFO:tensorflow:Eval metrics at step 5000\n",
      "I1022 08:55:09.700607 139779506169728 model_lib_v2.py:1015] Eval metrics at step 5000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.212816\n",
      "I1022 08:55:09.723646 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.212816\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.418929\n",
      "I1022 08:55:09.725456 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.418929\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.193583\n",
      "I1022 08:55:09.727020 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.193583\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "I1022 08:55:09.728473 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.038140\n",
      "I1022 08:55:09.729931 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.038140\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.240142\n",
      "I1022 08:55:09.731369 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.240142\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.005180\n",
      "I1022 08:55:09.732817 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.005180\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.048620\n",
      "I1022 08:55:09.734413 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.048620\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.347720\n",
      "I1022 08:55:09.735818 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.347720\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "I1022 08:55:09.737025 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.075703\n",
      "I1022 08:55:09.738480 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.075703\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.392204\n",
      "I1022 08:55:09.741117 139779506169728 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.392204\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.247106\n",
      "I1022 08:55:09.742219 139779506169728 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.247106\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.371656\n",
      "I1022 08:55:09.743361 139779506169728 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.371656\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.682506\n",
      "I1022 08:55:09.744552 139779506169728 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.682506\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 1.301268\n",
      "I1022 08:55:09.745680 139779506169728 model_lib_v2.py:1018] \t+ Loss/total_loss: 1.301268\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v1\n",
      "I1022 08:57:40.851524 139779506169728 checkpoint_utils.py:142] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v1\n",
      "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
      "I1022 09:57:40.625432 139779506169728 checkpoint_utils.py:205] Timed-out waiting for a checkpoint.\n"
     ]
    }
   ],
   "source": [
    "!{command} ##evaluating model ssd_mobilenet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MTD1bnijeb7B",
    "outputId": "cf989953-8471-4064-84d7-b6395097a165"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 10:30:57.220829: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 10:30:57.992227: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 10:30:57.992336: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 10:30:57.992356: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1022 10:31:00.273072 139923825096576 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I1022 10:31:00.273283 139923825096576 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 10:31:00.273369 139923825096576 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1022 10:31:00.273463 139923825096576 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1022 10:31:00.273574 139923825096576 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-10-22 10:31:01.110603: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "I1022 10:31:01.158862 139923825096576 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "I1022 10:31:01.159109 139923825096576 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 10:31:01.159218 139923825096576 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 10:31:01.159286 139923825096576 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 10:31:01.162654 139923825096576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 10:31:01.182459 139923825096576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 10:31:05.345580 139923825096576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 10:31:06.829797 139923825096576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_resnet101_v1\n",
      "I1022 10:31:09.346080 139923825096576 checkpoint_utils.py:142] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_resnet101_v1\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/ssd_resnet101_v1/ckpt-6\n",
      "I1022 10:31:09.347178 139923825096576 checkpoint_utils.py:151] Found new checkpoint at Tensorflow/workspace/models/ssd_resnet101_v1/ckpt-6\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 10:31:38.975689 139923825096576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I1022 10:31:39.002951 139923825096576 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W1022 10:31:39.373594 139923825096576 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 36 images.\n",
      "I1022 10:32:49.496429 139923825096576 coco_evaluation.py:293] Performing evaluation on 36 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1022 10:32:49.498231 139923825096576 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I1022 10:32:49.500089 139923825096576 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.94s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.03s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.204\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.387\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.200\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.045\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.228\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.047\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.326\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.077\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.366\n",
      "INFO:tensorflow:Eval metrics at step 5000\n",
      "I1022 10:32:56.491014 139923825096576 model_lib_v2.py:1015] Eval metrics at step 5000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.203593\n",
      "I1022 10:32:56.511962 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.203593\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.386503\n",
      "I1022 10:32:56.513658 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.386503\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.200488\n",
      "I1022 10:32:56.515456 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.200488\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "I1022 10:32:56.517020 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.045257\n",
      "I1022 10:32:56.518636 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.045257\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.228449\n",
      "I1022 10:32:56.520135 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.228449\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.005321\n",
      "I1022 10:32:56.521566 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.005321\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.046988\n",
      "I1022 10:32:56.522983 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.046988\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.325760\n",
      "I1022 10:32:56.524399 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.325760\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "I1022 10:32:56.525602 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.077108\n",
      "I1022 10:32:56.527001 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.077108\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.366426\n",
      "I1022 10:32:56.528494 139923825096576 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.366426\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.286287\n",
      "I1022 10:32:56.529662 139923825096576 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.286287\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.400071\n",
      "I1022 10:32:56.530766 139923825096576 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.400071\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.202867\n",
      "I1022 10:32:56.531869 139923825096576 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.202867\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.889225\n",
      "I1022 10:32:56.532963 139923825096576 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.889225\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_resnet101_v1\n",
      "I1022 10:36:09.435534 139923825096576 checkpoint_utils.py:142] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_resnet101_v1\n",
      "INFO:tensorflow:Timed-out waiting for a checkpoint.\n",
      "I1022 11:36:08.564286 139923825096576 checkpoint_utils.py:205] Timed-out waiting for a checkpoint.\n"
     ]
    }
   ],
   "source": [
    "!{command2}##evaluating model ssd_restnet_v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZhdxgWEneftW",
    "outputId": "f11d5c28-cfc1-4f9c-dd97-27294e610381"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-10-22 11:36:12.626666: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-22 11:36:13.407648: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 11:36:13.407762: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/lib64-nvidia\n",
      "2022-10-22 11:36:13.407782: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n",
      "WARNING:tensorflow:Forced number of epochs for all eval validations to be 1.\n",
      "W1022 11:36:15.666329 139755609384832 model_lib_v2.py:1090] Forced number of epochs for all eval validations to be 1.\n",
      "INFO:tensorflow:Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "I1022 11:36:15.666553 139755609384832 config_util.py:552] Maybe overwriting sample_1_of_n_eval_examples: None\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I1022 11:36:15.666643 139755609384832 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "INFO:tensorflow:Maybe overwriting eval_num_epochs: 1\n",
      "I1022 11:36:15.666728 139755609384832 config_util.py:552] Maybe overwriting eval_num_epochs: 1\n",
      "WARNING:tensorflow:Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "W1022 11:36:15.666835 139755609384832 model_lib_v2.py:1110] Expected number of evaluation epochs is 1, but instead encountered `eval_on_train_input_config.num_epochs` = 0. Overwriting `num_epochs` to 1.\n",
      "2022-10-22 11:36:16.472007: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:42] Overriding orig_value setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n",
      "INFO:tensorflow:Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "I1022 11:36:16.520730 139755609384832 dataset_builder.py:162] Reading unweighted datasets: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "I1022 11:36:16.520965 139755609384832 dataset_builder.py:79] Reading record datasets for input file: ['Tensorflow/workspace/annotations/test.record']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I1022 11:36:16.521100 139755609384832 dataset_builder.py:80] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W1022 11:36:16.521189 139755609384832 dataset_builder.py:87] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "W1022 11:36:16.524707 139755609384832 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:104: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W1022 11:36:16.541275 139755609384832 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/object_detection/builders/dataset_builder.py:236: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "W1022 11:36:20.282835 139755609384832 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: sparse_to_dense (from tensorflow.python.ops.sparse_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Create a `tf.sparse.SparseTensor` and use `tf.sparse.to_dense` instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 11:36:21.356650 139755609384832 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite\n",
      "I1022 11:36:23.790139 139755609384832 checkpoint_utils.py:142] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite\n",
      "INFO:tensorflow:Found new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/ckpt-6\n",
      "I1022 11:36:23.791151 139755609384832 checkpoint_utils.py:151] Found new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/ckpt-6\n",
      "/usr/local/lib/python3.7/dist-packages/keras/backend.py:452: UserWarning: `tf.keras.backend.set_learning_phase` is deprecated and will be removed after 2020-10-11. To update it, simply pass a True/False value to the `training` argument of the `__call__` method of your layer or model.\n",
      "  \"`tf.keras.backend.set_learning_phase` is deprecated and \"\n",
      "Corrupt JPEG data: premature end of data segment\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "W1022 11:36:48.169528 139755609384832 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1176: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "INFO:tensorflow:Finished eval step 0\n",
      "I1022 11:36:48.196060 139755609384832 model_lib_v2.py:966] Finished eval step 0\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "W1022 11:36:48.574201 139755609384832 deprecation.py:356] From /usr/local/lib/python3.7/dist-packages/tensorflow/python/autograph/impl/api.py:459: py_func (from tensorflow.python.ops.script_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "tf.py_func is deprecated in TF V2. Instead, there are two\n",
      "    options available in V2.\n",
      "    - tf.py_function takes a python function which manipulates tf eager\n",
      "    tensors instead of numpy arrays. It's easy to convert a tf eager tensor to\n",
      "    an ndarray (just call tensor.numpy()) but having access to eager tensors\n",
      "    means `tf.py_function`s can use accelerators such as GPUs as well as\n",
      "    being differentiable using a gradient tape.\n",
      "    - tf.numpy_function maintains the semantics of the deprecated tf.py_func\n",
      "    (it is not differentiable, and manipulates numpy arrays). It drops the\n",
      "    stateful argument making all functions stateful.\n",
      "    \n",
      "INFO:tensorflow:Performing evaluation on 36 images.\n",
      "I1022 11:37:59.200906 139755609384832 coco_evaluation.py:293] Performing evaluation on 36 images.\n",
      "creating index...\n",
      "index created!\n",
      "INFO:tensorflow:Loading and preparing annotation results...\n",
      "I1022 11:37:59.202660 139755609384832 coco_tools.py:116] Loading and preparing annotation results...\n",
      "INFO:tensorflow:DONE (t=0.00s)\n",
      "I1022 11:37:59.204531 139755609384832 coco_tools.py:138] DONE (t=0.00s)\n",
      "creating index...\n",
      "index created!\n",
      "Running per image evaluation...\n",
      "Evaluate annotation type *bbox*\n",
      "DONE (t=6.96s).\n",
      "Accumulating evaluation results...\n",
      "DONE (t=0.04s).\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.233\n",
      " Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.429\n",
      " Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.230\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.032\n",
      " Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.268\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.005\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.049\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.370\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.040\n",
      " Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.424\n",
      "INFO:tensorflow:Eval metrics at step 5000\n",
      "I1022 11:38:06.219757 139755609384832 model_lib_v2.py:1015] Eval metrics at step 5000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP: 0.233455\n",
      "I1022 11:38:06.243093 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP: 0.233455\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.50IOU: 0.428991\n",
      "I1022 11:38:06.244912 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.50IOU: 0.428991\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP@.75IOU: 0.229563\n",
      "I1022 11:38:06.246533 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP@.75IOU: 0.229563\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "I1022 11:38:06.248064 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (medium): 0.032379\n",
      "I1022 11:38:06.249546 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (medium): 0.032379\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Precision/mAP (large): 0.267660\n",
      "I1022 11:38:06.251029 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Precision/mAP (large): 0.267660\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@1: 0.004955\n",
      "I1022 11:38:06.252563 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@1: 0.004955\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@10: 0.049352\n",
      "I1022 11:38:06.254050 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@10: 0.049352\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100: 0.370327\n",
      "I1022 11:38:06.255517 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100: 0.370327\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "I1022 11:38:06.256740 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (small): 0.000000\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (medium): 0.039759\n",
      "I1022 11:38:06.258131 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (medium): 0.039759\n",
      "INFO:tensorflow:\t+ DetectionBoxes_Recall/AR@100 (large): 0.424369\n",
      "I1022 11:38:06.259571 139755609384832 model_lib_v2.py:1018] \t+ DetectionBoxes_Recall/AR@100 (large): 0.424369\n",
      "INFO:tensorflow:\t+ Loss/localization_loss: 0.256235\n",
      "I1022 11:38:06.260674 139755609384832 model_lib_v2.py:1018] \t+ Loss/localization_loss: 0.256235\n",
      "INFO:tensorflow:\t+ Loss/classification_loss: 0.361994\n",
      "I1022 11:38:06.261816 139755609384832 model_lib_v2.py:1018] \t+ Loss/classification_loss: 0.361994\n",
      "INFO:tensorflow:\t+ Loss/regularization_loss: 0.128807\n",
      "I1022 11:38:06.262946 139755609384832 model_lib_v2.py:1018] \t+ Loss/regularization_loss: 0.128807\n",
      "INFO:tensorflow:\t+ Loss/total_loss: 0.747035\n",
      "I1022 11:38:06.264039 139755609384832 model_lib_v2.py:1018] \t+ Loss/total_loss: 0.747035\n",
      "INFO:tensorflow:Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite\n",
      "I1022 11:41:23.873974 139755609384832 checkpoint_utils.py:142] Waiting for new checkpoint at Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 308, in run\n",
      "    _run_main(main, args)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 254, in _run_main\n",
      "    sys.exit(main(argv))\n",
      "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 89, in main\n",
      "    wait_interval=300, timeout=FLAGS.eval_timeout)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/object_detection/model_lib_v2.py\", line 1136, in eval_continuously\n",
      "    checkpoint_dir, timeout=timeout, min_interval_secs=wait_interval):\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 201, in checkpoints_iterator\n",
      "    checkpoint_dir, checkpoint_path, timeout=timeout)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/checkpoint_utils.py\", line 149, in wait_for_new_checkpoint\n",
      "    time.sleep(seconds_to_sleep)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"Tensorflow/models/research/object_detection/model_main_tf2.py\", line 114, in <module>\n",
      "    tf.compat.v1.app.run()\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/tensorflow/python/platform/app.py\", line 36, in run\n",
      "    _run(main=main, argv=argv, flags_parser=_parse_flags_tolerate_undef)\n",
      "  File \"/usr/local/lib/python3.7/dist-packages/absl/app.py\", line 316, in run\n",
      "    if isinstance(exc, SystemExit) and not exc.code:\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "!{command3}##evaluating model ssd_mobilenet_v2_fpnlite"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "orvRk02UpfDI"
   },
   "source": [
    "# Loading Train Model From Checkpoint\n",
    "\n",
    "\n",
    "*   Here we are loading our checkpoint files for model detections. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8TYk4_oIpfDI"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wn1MHRE35pyC"
   },
   "outputs": [],
   "source": [
    "# Prevent GPU complete consumption\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try: \n",
    "        tf.config.experimental.set_virtual_device_configuration(\n",
    "            gpus[0], [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=5120)])\n",
    "    except RunTimeError as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tDnQg-cYpfDI"
   },
   "outputs": [],
   "source": [
    "# Load pipeline config and build a detection model\n",
    "configs = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "detection_model = model_builder.build(model_config=configs['model'], is_training=False)\n",
    "\n",
    "configs2 = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG2'])\n",
    "detection_model2 = model_builder.build(model_config=configs2['model'], is_training=False)\n",
    "\n",
    "configs3 = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG3'])\n",
    "detection_model3 = model_builder.build(model_config=configs3['model'], is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-6')).expect_partial()\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH2'], 'ckpt-6')).expect_partial()\n",
    "ckpt.restore(os.path.join(paths['CHECKPOINT_PATH3'], 'ckpt-6')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image, shapes)\n",
    "    detections = detection_model.postprocess(prediction_dict, shapes)\n",
    "    return detections\n",
    "\n",
    "\n",
    "def detect_fn2(image):\n",
    "    image, shapes = detection_model2.preprocess(image)\n",
    "    prediction_dict2 = detection_model2.predict(image, shapes)\n",
    "    detections2 = detection_model2.postprocess(prediction_dict2, shapes)\n",
    "    return detections2\n",
    "\n",
    "def detect_fn3(image):\n",
    "    image, shapes = detection_model3.preprocess(image)\n",
    "    prediction_dict3 = detection_model3.predict(image, shapes)\n",
    "    detections3 = detection_model3.postprocess(prediction_dict3, shapes)\n",
    "    return detections3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nnfDIiIilRok"
   },
   "source": [
    "## **Freeze Graph**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wA8dwxNPlP8A"
   },
   "outputs": [],
   "source": [
    "FREEZE_SCRIPT = os.path.join(paths['APIMODEL_PATH'], 'research', 'object_detection', 'exporter_main_v2.py ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VUgveTEYk18M"
   },
   "outputs": [],
   "source": [
    "\n",
    "command = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG'], paths['CHECKPOINT_PATH'], paths['OUTPUT_PATH'])\n",
    "\n",
    "command2 = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG2'], paths['CHECKPOINT_PATH2'], paths['OUTPUT_PATH2'])\n",
    "\n",
    "\n",
    "command3 = \"python {} --input_type=image_tensor --pipeline_config_path={} --trained_checkpoint_dir={} --output_directory={}\".format(FREEZE_SCRIPT ,files['PIPELINE_CONFIG3'], paths['CHECKPOINT_PATH3'], paths['OUTPUT_PATH3'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-ILgwgAqlOdZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "print(command)\n",
    "print(command2)\n",
    "print(command3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "niJ1Siwhk1uz"
   },
   "outputs": [],
   "source": [
    "!{command}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kivPou4Kk1W-"
   },
   "outputs": [],
   "source": [
    "!{command2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "my_MI3ljk1Cu"
   },
   "outputs": [],
   "source": [
    "!{command3}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SEyCLcJ6ppx7"
   },
   "source": [
    "# Exporting Train Model From Checkpoint to Drive\n",
    "\n",
    "\n",
    "*   Here we are saving our model for future use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O7Rao_puk0c6"
   },
   "outputs": [],
   "source": [
    "!zip -r '/content/drive/MyDrive/All_ssd_mobilenet_v1.zip' '/content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/'\n",
    "!zip -r '/content/drive/MyDrive/All_ssd_resnet101_v1.zip' '/content/Tensorflow/workspace/models/ssd_resnet101_v1/export/'\n",
    "!zip -r '/content/drive/MyDrive/All_ssd_mobilenet_v2_fpnlite.zip' '/content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UvyRWMOlmmtL"
   },
   "source": [
    "### **Unzipping and Loading TF models**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fYjvpjA6mipX",
    "outputId": "fdb671fe-0d28-4043-db27-98120a7a5b34"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sjxy7o7Umhkx",
    "outputId": "766761ba-ec63-45fa-f670-82ffe7f02da0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /content/drive/MyDrive/models/ssd_mobileNet_v1.zip\n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/\n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model/saved_model.pb  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model/assets/\n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model/variables/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model/variables/variables.index  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model/variables/variables.data-00000-of-00001  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/checkpoint/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/checkpoint/ckpt-0.index  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/checkpoint/checkpoint  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/checkpoint/ckpt-0.data-00000-of-00001  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/pipeline.config  \n",
      "Archive:  /content/drive/MyDrive/models/ssd_mobilenet_v2_fpnlite.zip\n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/\n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/checkpoint/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/checkpoint/checkpoint  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/checkpoint/ckpt-0.data-00000-of-00001  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/checkpoint/ckpt-0.index  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/pipeline.config  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model/saved_model.pb  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model/assets/\n",
      "   creating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model/variables/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model/variables/variables.data-00000-of-00001  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model/variables/variables.index  \n",
      "Archive:  /content/drive/MyDrive/models/ssd_resnet101_v1_fpn.zip\n",
      "   creating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/pipeline.config  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/checkpoint/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/checkpoint/checkpoint  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/checkpoint/ckpt-0.index  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/checkpoint/ckpt-0.data-00000-of-00001  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model/saved_model.pb  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model/variables/\n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model/variables/variables.data-00000-of-00001  \n",
      "  inflating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model/variables/variables.index  \n",
      "   creating: content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model/assets/\n"
     ]
    }
   ],
   "source": [
    "!unzip '/content/drive/MyDrive/models/ssd_mobileNet_v1.zip'\n",
    "!unzip '/content/drive/MyDrive/models/ssd_mobilenet_v2_fpnlite.zip'\n",
    "!unzip '/content/drive/MyDrive/models/ssd_resnet101_v1_fpn.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8WF-WvV6kuQP"
   },
   "outputs": [],
   "source": [
    "# LOAD THE MODEL\n",
    "#MobileNet MODEL Directory\n",
    "MOBILENET_V1_PATH_TO_SAVED_MODEL = \"/content/content/Tensorflow/workspace/models/ssd_mobilenet_v1/export/saved_model\"\n",
    "#MobileNet MODEL Directory\n",
    "MOBILENET_V2_FPNLITE_PATH_TO_SAVED_MODEL = \"/content/content/Tensorflow/workspace/models/ssd_mobilenet_v2_fpnlite/export/saved_model\"\n",
    "#MobileNet MODEL Directory\n",
    "RESNET_V2_PATH_TO_SAVED_MODEL = \"/content/content/Tensorflow/workspace/models/ssd_resnet101_v1/export/saved_model\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0EmsmbBZpfDI"
   },
   "source": [
    "# Detect from an Image\n",
    "\n",
    "\n",
    "*   Now we are testing our trained model for detecting objects from shelves. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "har7AI6Tlo-h",
    "outputId": "34279976-d0d9-49a6-9dfc-371b026fc4e9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model...Done! Took 40.347718238830566 seconds\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Object Detection (On Image) From TF2 Saved Model\n",
    "=====================================\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'    # Suppress TensorFlow logging (1)\n",
    "import pathlib\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "import argparse\n",
    "from google.colab.patches import cv2_imshow\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as vis_util\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "# Enable GPU dynamic memory allocation\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus:\n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n",
    "# PROVIDE PATH TO IMAGE DIRECTORY\n",
    "IMAGE_PATHS = '/content/inventory_images/test/test_10.jpg'\n",
    "\n",
    "\n",
    "# PROVIDE PATH TO LABEL MAP\n",
    "PATH_TO_LABELS = '/content/label_map.pbtxt'\n",
    "\n",
    "# PROVIDE THE MINIMUM CONFIDENCE THRESHOLD\n",
    "MIN_CONF_THRESH = float(0.60)\n",
    "\n",
    "# LOAD THE MODEL\n",
    "\n",
    "import time\n",
    "\n",
    "print('Loading model...', end='')\n",
    "start_time = time.time()\n",
    "\n",
    "# LOAD SAVED MODEL AND BUILD DETECTION FUNCTION\n",
    "mobilenet_v1_detect_fn = tf.saved_model.load(MOBILENET_V1_PATH_TO_SAVED_MODEL)\n",
    "mobilenet_v2_fpnlite_detect_fn = tf.saved_model.load(MOBILENET_V2_FPNLITE_PATH_TO_SAVED_MODEL)\n",
    "resnet_v2_detect_fn = tf.saved_model.load(RESNET_V2_PATH_TO_SAVED_MODEL)\n",
    "\n",
    "end_time = time.time()\n",
    "elapsed_time = end_time - start_time\n",
    "print('Done! Took {} seconds'.format(elapsed_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OU8HJO6mln8x"
   },
   "outputs": [],
   "source": [
    "# PROVIDE PATH TO IMAGE DIRECTORY\n",
    "IMAGE_PATHS = \"/content/inventory_images/test/test_10.jpg\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyQ0O8MZmIE5"
   },
   "source": [
    "## **Qualitative Analysis**\n",
    "We have investigated the performance of current state-of-the-art object detection algorithms on\n",
    "the SKU-110k dataset. The idea is to draw an analysis that explains how well object detection\n",
    "algorithms can perform under harsh conditions. We employed SSD_Mobilenet_V2_Fpnlite, SSD\n",
    "ResNet101 v1 FPN, SSD_Mobilenet_v1_FPN to benchmark their performance on the SKU-\n",
    "110K dataset. We have leveraged the capabilities of transfer learning in our experiments. All the\n",
    "object detection networks are incorporated with a backbone of ResNet50 pre-trained on COCO\n",
    "dataset. We fine-tuned all the models for 5000 epochs and used Adam as an optimizer. We\n",
    "resized images to 640 × 640 during the training and testing phases.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "NgAcqmBCmKSM",
    "outputId": "9cc3ec7e-67c3-440c-f448-d53459ca36f8"
   },
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "    Args:\n",
    "      path: the file path to the image\n",
    "    Returns:\n",
    "      uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    return np.array(Image.open(path))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print('Running inference for {}... '.format(IMAGE_PATHS), end='')\n",
    "\n",
    "image = cv2.imread(IMAGE_PATHS)\n",
    "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "image_expanded = np.expand_dims(image_rgb, axis=0)\n",
    "\n",
    "# The input needs to be a tensor, convert it using `tf.convert_to_tensor`.\n",
    "input_tensor = tf.convert_to_tensor(image)\n",
    "# The model expects a batch of images, so add an axis with `tf.newaxis`.\n",
    "input_tensor = input_tensor[tf.newaxis, ...]\n",
    "\n",
    "# detection for mobileNetv1fpn\n",
    "mobilenet_v1_detections = mobilenet_v1_detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(mobilenet_v1_detections.pop('num_detections'))\n",
    "mobilenet_v1_detections = {key: value[0, :num_detections].numpy()\n",
    "               for key, value in mobilenet_v1_detections.items()}\n",
    "mobilenet_v1_detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "mobilenet_v1_detections['detection_classes'] = mobilenet_v1_detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "mobilenet_v1_image_with_detections = image.copy()\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            mobilenet_v1_image_with_detections,\n",
    "            mobilenet_v1_detections['detection_boxes'],\n",
    "            mobilenet_v1_detections['detection_classes'],\n",
    "            mobilenet_v1_detections['detection_scores'],\n",
    "            {'object':1},\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.1,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "#detection via resnet_v2 \n",
    "resnet_v2_detections = resnet_v2_detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(resnet_v2_detections.pop('num_detections'))\n",
    "resnet_v2_detections = {key: value[0, :num_detections].numpy()\n",
    "               for key, value in resnet_v2_detections.items()}\n",
    "resnet_v2_detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "resnet_v2_detections['detection_classes'] = resnet_v2_detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "resnet_v2_image_with_detections = image.copy()\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            resnet_v2_image_with_detections,\n",
    "            resnet_v2_detections['detection_boxes'],\n",
    "            resnet_v2_detections['detection_classes'],\n",
    "            resnet_v2_detections['detection_scores'],\n",
    "            {'object':1},\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.1,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "#detection via fpnlite\n",
    "mobilenet_v2_fpnlite_detections = mobilenet_v2_fpnlite_detect_fn(input_tensor)\n",
    "\n",
    "# All outputs are batches tensors.\n",
    "# Convert to numpy arrays, and take index [0] to remove the batch dimension.\n",
    "# We're only interested in the first num_detections.\n",
    "num_detections = int(mobilenet_v2_fpnlite_detections.pop('num_detections'))\n",
    "mobilenet_v2_fpnlite_detections = {key: value[0, :num_detections].numpy()\n",
    "               for key, value in mobilenet_v2_fpnlite_detections.items()}\n",
    "mobilenet_v2_fpnlite_detections['num_detections'] = num_detections\n",
    "\n",
    "# detection_classes should be ints.\n",
    "mobilenet_v2_fpnlite_detections['detection_classes'] = mobilenet_v2_fpnlite_detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "mobilenet_v2_fpnlite_image_with_detections = image.copy()\n",
    "vis_util.visualize_boxes_and_labels_on_image_array(\n",
    "            mobilenet_v2_fpnlite_image_with_detections,\n",
    "            mobilenet_v2_fpnlite_detections['detection_boxes'],\n",
    "            mobilenet_v2_fpnlite_detections['detection_classes'],\n",
    "            mobilenet_v2_fpnlite_detections['detection_scores'],\n",
    "            {'object':1},\n",
    "            use_normalized_coordinates=True,\n",
    "            max_boxes_to_draw=200,\n",
    "            min_score_thresh=.1,\n",
    "            agnostic_mode=False)\n",
    "\n",
    "print(\"MobileNet_v1\")\n",
    "cv2_imshow(cv2.cvtColor(mobilenet_v1_image_with_detections, cv2.COLOR_BGR2RGB))\n",
    "print(\"ResNet_v2\")\n",
    "cv2_imshow(cv2.cvtColor(resnet_v2_image_with_detections, cv2.COLOR_BGR2RGB))\n",
    "print(\"MobileNet_v2_FPNLite\")\n",
    "cv2_imshow(cv2.cvtColor(mobilenet_v2_fpnlite_image_with_detections, cv2.COLOR_BGR2RGB))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pqGK4Rguo6UR"
   },
   "source": [
    "Here we will now get to show the images in a single plot to compare results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 809
    },
    "id": "UoZg10yMmMR7",
    "outputId": "73496ecd-5ed1-423e-a962-7675d95b7107"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"MobileNet_v1\")\n",
    "plt.imshow(cv2.cvtColor(mobilenet_v1_image_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "plt.title(\"ResNet\")\n",
    "plt.imshow(cv2.cvtColor(resnet_v2_image_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()\n",
    "plt.title(\"MobileNet_v2_FPNLite\")\n",
    "plt.imshow(cv2.cvtColor(mobilenet_v2_fpnlite_image_with_detections, cv2.COLOR_BGR2RGB))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "abV91yObmRyP"
   },
   "source": [
    "## **Quantitative Analysis**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "u8lgVI2rmPKf"
   },
   "outputs": [],
   "source": [
    "def get_scores_detections(image,detections,detection_threshold):\n",
    "  scores = list(filter(lambda x: x> detection_threshold, detections['detection_scores']))\n",
    "  boxes = detections['detection_boxes'][:len(scores)]\n",
    "  return np.array(scores).mean(),len(boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9WaFXNwcpGBx"
   },
   "source": [
    "### **Evaluation Matrix**\n",
    "The quantitative analysis demonstrates that the proposed approach achieved a minimum loss on\n",
    "the provided dataset SKU-110k, whereas the qualitative evaluation indicates increase in sales\n",
    "and customers’ satisfaction level. This section discusses the well-known evaluation criteria\n",
    "essential to standardize state-of-the-art results for object detection in difficult situations. Finally,\n",
    "we will present the outcome of our experiments on the SKU-110k dataset. Evaluation Criteria\n",
    "The standardization of how to assess the performance of approaches on unified datasets is\n",
    "imperative. Since object detection in a challenging environment is identical to generic object\n",
    "detection, the approaches appraise similar evaluation metrics.\n",
    "\n",
    "#### **Precision** \n",
    "Precision tells in what ratio the object detection model found the correct objects in the image. Or in other words, how many of the positive results are positive.\n",
    "\n",
    "#### **Recall** \n",
    "Recall tells in what ratio the model managed to identify those cases that are positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "clci1cGQmUbg",
    "outputId": "14243044-83f2-46dd-86f3-84664721f9b8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.70863265 34\n",
      "0.6454833 30\n",
      "0.65181357 52\n"
     ]
    }
   ],
   "source": [
    "#MobileNet_v1\n",
    "MobileNet_V1_AP, MobileNet_V1_detections = get_scores_detections(mobilenet_v1_image_with_detections,mobilenet_v1_detections,0.5)\n",
    "print(MobileNet_V1_AP,MobileNet_V1_detections)\n",
    "#ResNet_v2\n",
    "ResNet_V2_AP, ResNet_V2_detections = get_scores_detections(resnet_v2_image_with_detections,resnet_v2_detections,0.5)\n",
    "print(ResNet_V2_AP,ResNet_V2_detections)\n",
    "#MobileNet_v2_FPNLite\n",
    "MobileNet_V2_FPNLite_AP, MobileNet_V2_FPNLite_detections = get_scores_detections(mobilenet_v2_fpnlite_image_with_detections,mobilenet_v2_fpnlite_detections,0.5)\n",
    "print(MobileNet_V2_FPNLite_AP, MobileNet_V2_FPNLite_detections)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wrl5F3VPpM8Z"
   },
   "source": [
    "\n",
    "\n",
    "### **The losses for the Final Classifier**\n",
    "**Loss/classification_loss:** Loss for the classification of detected objects into various classes:\n",
    "object, empty shelves etc.\n",
    "\n",
    "**Loss/ Localization_loss:** Localization Loss or the Loss of the Bounding Box regressor.\n",
    "\n",
    "**Loss/ Regularlization_loss:** Regularization refers to the act of modifying a learning algorithm to\n",
    "favor “simpler” prediction rules to avoid overfitting. Most commonly, regularization refers to\n",
    "modifying the loss function to penalize certain values of the weights you are learning.\n",
    "\n",
    "**Loss/ total_loss:** Sum of classification_loss, localization_loss and regularlization_loss and\n",
    "total_loss.\n",
    "\n",
    "**Learning Rate:** The learning rate is a tuning parameter in an optimization algorithm that\n",
    "determines the step size at each iteration while moving toward a minimum of a loss function.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "VWYznPdEmXAJ",
    "outputId": "76065258-43c6-4b3a-d935-b10225a81e91"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = {\"MobileNet_V1\":MobileNet_V1_AP,\"ResNet_V2\":ResNet_V2_AP,\"MobileNet_V2_FPNLite\":MobileNet_V2_FPNLite_AP}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values, tick_label=names)\n",
    "plt.title(\"Average Precision\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QQRRLZT_pT5b"
   },
   "source": [
    "#### **Intersection Over Union**\n",
    "Intersection Over Union (IOU) is one of the most important evaluation metrics that is regularly\n",
    "employed to determine the performance of object detection algorithms. It is the measure of how\n",
    "much the predicted region is overlapping with the actual ground truth region. \n",
    "Intersection over Union (IoU) is the name of the calculation which gives “the overlap divided by the union” of 2 bounding boxes: ground truth bounding box and detection (prediction) bounding\n",
    "box.\n",
    "\n",
    "For most evaluation cases like competitions, an IoU threshold of 0.5 is sufficient. This number\n",
    "means that there is most likely an object inside the ground truth box. IoU is used to determine\n",
    "whether a prediction is positive or negative. For example, if mAP is being calculated for IoU\n",
    "value of 0.5.\n",
    "\n",
    "- IoU >= 0.5, then true positive (TP): ground truth object is detected with the correct class.\n",
    "- IoU < 0.5, then false positive (FP): ground truth object is detected with a wrong class.\n",
    "- False negative (FN): ground truth object is not detected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "fb5_szwBmY9F",
    "outputId": "4f61a288-a0ce-4281-8860-e8e8a3874bb3"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "data = {\"MobileNet_V1\":MobileNet_V1_detections,\"ResNet_V2\":ResNet_V2_detections,\"MobileNet_V2_FPNLite\":MobileNet_V2_FPNLite_detections}\n",
    "names = list(data.keys())\n",
    "values = list(data.values())\n",
    "\n",
    "plt.bar(range(len(data)), values, tick_label=names)\n",
    "plt.title(\"Number of Detections Over threshold 0.5\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
